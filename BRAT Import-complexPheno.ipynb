{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge BRAT Labels w/ Snorkel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook automates the process of merging BRAT labeled candidates with Snorkel extracted candidates to create a set of gold labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 1\n",
    "import os\n",
    "# os.environ['SNORKELDB'] = 'sqlite:///brat-import.db'\n",
    "from set_env import *\n",
    "set_env()\n",
    "from snorkel import SnorkelSession\n",
    "import snorkel.contrib.brat as brt\n",
    "from snorkel.parsers import StanfordCoreNLPServer\n",
    "\n",
    "from snorkel.models import Candidate, Document, candidate_subclass, GoldLabel\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corenlp_server = StanfordCoreNLPServer(version='3.6.0', split_newline=False, num_threads=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brat = brt.Brat(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Optional cell. Populate the documents and sentences db with these brat documents.\n",
    "\n",
    "# from snorkel.parser import TextDocPreprocessor, CorpusParser\n",
    "# import multiprocessing\n",
    "# doc_preprocessor = TextDocPreprocessor(\"brat_data/test_labeled_docs/*.txt\", encoding=\"utf-8\")\n",
    "# corpus_parser = CorpusParser()\n",
    "# corpus_parser.apply(doc_preprocessor, parralelism=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the BRAT labeled data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"brat_data/try_2/\"\n",
    "brat.import_project(input_dir, annotations_only=False, annotator_name='brat', num_threads=1, parser=corenlp_server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pheno_spans = brat.explore()\n",
    "print 'Total BRAT labeled phenotypes:', len(pheno_spans)\n",
    "print 'Total disjoint BRAT phenotypes:', len([pheno_span for pheno_span in pheno_spans if len(pheno_span) > 1])\n",
    "print 'Example BRAT phenotype spans:'\n",
    "for p in pheno_spans[:5]:\n",
    "    print p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map BRAT labels to Snorkel candidates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import Document, Sentence, Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PhenoPairComplex = candidate_subclass('ComplexPhenotypes', ['descriptor', 'entity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from sqlalchemy import and_\n",
    "from snorkel.models import StableLabel, GoldLabel, GoldLabelKey\n",
    "import math\n",
    "from progressbar import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "\n",
    "jaccard_cutoff = 0.3\n",
    "\n",
    "ak = session.query(GoldLabelKey).filter(GoldLabelKey.name == 'gold_complex').first()\n",
    "print \"Existing number of labeled candidates:\", session.query(GoldLabel).filter(GoldLabel.key == ak).count()\n",
    "if ak is None:\n",
    "    ak = GoldLabelKey(name='gold_complex')\n",
    "    session.add(ak)\n",
    "    session.commit()\n",
    "else:\n",
    "    # Clear the labels (oh boy)\n",
    "    session.query(GoldLabel).filter(GoldLabel.key == ak).delete()\n",
    "    print \"Number of labeled candidates (should be 0 now):\", session.query(GoldLabel).filter(GoldLabel.key == ak).count()\n",
    "print '================================================'\n",
    "candidates = session.query(PhenoPairComplex).filter(or_(PhenoPairComplex.split == 3, PhenoPairComplex.split == 4, PhenoPairComplex.split == 5)).all()\n",
    "print \"Total Snorkel candidates:\", len(candidates)\n",
    "\n",
    "sentence_to_pheno = collections.defaultdict(list)\n",
    "\n",
    "for pheno_span in pheno_spans:\n",
    "    # pheno_span is a list of fragments, where each fragment is a temporary span\n",
    "    if pheno_span:\n",
    "        sent_id = pheno_span[0].sentence.id\n",
    "        sentence_to_pheno[sent_id].append(pheno_span)\n",
    "\n",
    "num = 0\n",
    "num_matches = 0\n",
    "num_sentences = 0\n",
    "num_gold_phenos = 0\n",
    "num_zero_matches = 0\n",
    "avg = 0\n",
    "num_skipped = 0\n",
    "overlap = 0\n",
    "num_skipped_gap = 0\n",
    "\n",
    "labeled = {}\n",
    "j=0\n",
    "for sentence_id, gold_phenos in pbar(sentence_to_pheno.items()):\n",
    "    sentence_match = False\n",
    "    results = session.query(Span, PhenoPairComplex).filter(and_(Span.sentence_id == sentence_id, PhenoPairComplex.descriptor_id == Span.id)).all()\n",
    "    if (len(results) == 0):\n",
    "        num_zero_matches += 1\n",
    "        \n",
    "    for gold_pheno_fragments in gold_phenos:\n",
    "        matched = False\n",
    "        pheno_best_jaccard = 0.0\n",
    "        num_matched_for_pheno = 0\n",
    "        for span, cand_pheno in results:\n",
    "            # Build word indice set for each of the gold phenotype, and the candiate phenotype\n",
    "            cand_words = set()\n",
    "            gold_words = set()\n",
    "            # combine both entities (modifier and attribute) into one \"phenotype\"\n",
    "            [cand_words.update(xrange(span.get_word_start(), span.get_word_end()+1)) for span in cand_pheno.get_contexts()]\n",
    "             \n",
    "            for gold_pheno in gold_pheno_fragments:\n",
    "                gold_words.update(xrange(gold_pheno.get_word_start(), gold_pheno.get_word_end()+1))\n",
    "            \n",
    "            # Compute distance for each candidate word\n",
    "            distances = []\n",
    "            for word_idx in cand_words:\n",
    "                if word_idx in gold_words:\n",
    "                    distance = 0\n",
    "                else:\n",
    "                    frag_distances = []\n",
    "                    for gold_pheno in gold_pheno_fragments:\n",
    "                        frag_min = gold_pheno.get_word_start()\n",
    "                        frag_max = gold_pheno.get_word_end()\n",
    "                        if word_idx < frag_min:\n",
    "                            frag_distances.append(frag_min - word_idx)\n",
    "                        elif word_idx > frag_max:\n",
    "                            frag_distances.append(word_idx - frag_max)\n",
    "                    \n",
    "                    word_distance = min(frag_distances)\n",
    "                    distances.append(word_distance)\n",
    "            \n",
    "            total_distance = sum([word_distance ** 2 for word_distance in distances])\n",
    "            \n",
    "            \n",
    "            intersect = gold_words.intersection(cand_words)\n",
    "            jaccard_score = float(len(intersect)) / len(cand_words.union(gold_words))\n",
    "            \n",
    "            \n",
    "            val = -1\n",
    "                \n",
    "            if jaccard_score > jaccard_cutoff:\n",
    "                cont = False\n",
    "                cont2 = False\n",
    "                cont3 = False\n",
    "#                 if jaccard_score > pheno_best_jaccard:\n",
    "#                     pheno_best_jaccard = jaccard_score\n",
    "#                 elif num_matched_for_pheno >= 2:\n",
    "#                     cont3 = True\n",
    "                num_words_between_gold = max(gold_words) - min(gold_words) - len(gold_words)\n",
    "                num_words_between_cand = max(cand_words)-min(cand_words) - len(cand_words)\n",
    "                \n",
    "                if num_words_between_gold <= 1 and num_words_between_cand > 3 and total_distance > 20:\n",
    "                    num_skipped_gap += 1\n",
    "                    cont2 = True\n",
    "                \n",
    "                if total_distance > 100:\n",
    "                    num_skipped += 1\n",
    "                    cont = True\n",
    "                \n",
    "                if cont and cont2:\n",
    "                    overlap +=1\n",
    "                \n",
    "                if not (cont or cont2 or cont3):\n",
    "                    matched = True\n",
    "                    sentence_match = True\n",
    "                    avg += jaccard_score\n",
    "                    num += 1\n",
    "                    num_matched_for_pheno += 1\n",
    "                    val = 1\n",
    "            \n",
    "            label = session.query(GoldLabel).filter(GoldLabel.key == ak).filter(GoldLabel.candidate == cand_pheno).first()\n",
    "            if label is None:\n",
    "                session.add(GoldLabel(candidate=cand_pheno, key=ak, value=val))\n",
    "            elif label.value == -1 and val == 1:\n",
    "                label.value = val\n",
    "            \n",
    "        num_gold_phenos += 1\n",
    "        if matched:\n",
    "            num_matches += 1\n",
    "    if sentence_match:\n",
    "        num_sentences += 1\n",
    "session.commit()\n",
    "\n",
    "num_sentences_tagged = len(sentence_to_pheno.keys())\n",
    "print \"Total number of BRAT tagged sentences\", num_sentences_tagged\n",
    "print \"Total number of BRAT phenotypes\", num_gold_phenos\n",
    "\n",
    "print \"overlap\", overlap\n",
    "print \"num skipped\", num_skipped\n",
    "print \"num_skipped_gap\", num_skipped_gap\n",
    "print \"avg\", avg / num\n",
    "print \"num matched\", num_matches\n",
    "print \"num candidates labeled +1\", num\n",
    "recall = float(num_matches) / num_gold_phenos\n",
    "print \"sentences\", float(num_sentences) / num_sentences_tagged\n",
    "print \"num sents missed\", float(num_zero_matches) / num_sentences_tagged\n",
    "print \"recall\", recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each entity/relation type is assigned to a different split\n",
    "\n",
    "print len(candidates)\n",
    "for i,c in enumerate(candidates):\n",
    "    #label = session.query(GoldLabel).filter(GoldLabel.key == ak).filter(GoldLabel.candidate == c).first()\n",
    "    #if label is not None and label.value == 1: print c, label\n",
    "    print type(c).type, c\n",
    "    if i > 5:\n",
    "        break\n",
    "print\n",
    "    \n",
    "sents = list(set([pheno_span[0].sentence.id for pheno_span in pheno_spans if pheno_span]))\n",
    "candidates = [c for c in candidates if c[0].sentence.id in sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### split the dataset into train, dev, and test sets if not already done\n",
    "#### Train - split 3; dev - split 4; test - split 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = set([pheno_span[0].sentence.id for pheno_span in pheno_spans if pheno_span])\n",
    "c = [p for p in session.query(PhenoPairComplex).filter(or_(PhenoPairComplex.split == 3, PhenoPairComplex.split == 4, PhenoPairComplex.split == 5)).all() if p and p[0].sentence.id in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "doc_ids = list(set([p[0].sentence.document.id for p in session.query(PhenoPairComplex).filter(or_(PhenoPairComplex.split == 3, PhenoPairComplex.split == 4, PhenoPairComplex.split == 5)).all() if p[0].sentence.id in sents]))\n",
    "print 'Total BRAT labeled documents:', len(doc_ids)\n",
    "print '=============================='\n",
    "\n",
    "#randomly select the documents to be added to the dev and tests sets\n",
    "#half of the BRAT labeled documents will be the dev set and the other half will be the test set\n",
    "np.random.seed(742)\n",
    "split_size = len(doc_ids)/2\n",
    "split_1 = np.random.choice(doc_ids, split_size, replace=False)\n",
    "\n",
    "num_c = 0\n",
    "for cand in c:\n",
    "    cand.split = 4\n",
    "    if cand.get_contexts()[0].sentence.document.id in split_1:\n",
    "        cand.split = 5\n",
    "        num_c += 1\n",
    "session.commit()\n",
    "\n",
    "print 'Total BRAT labeled phenotypes:', len(c)\n",
    "print 'Total train phenotypes:', len(session.query(PhenoPairComplex).filter(PhenoPairComplex.split == 3).all())\n",
    "print 'Total dev phenotypes:', len(c) - num_c\n",
    "print 'Total test phenotypes:', num_c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View gold labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "from sqlalchemy import or_\n",
    "\n",
    "candidates = session.query(PhenoPairComplex).filter(or_(PhenoPairComplex.split == 4, PhenoPairComplex.split == 5)).all()\n",
    "\n",
    "sv = SentenceNgramViewer(candidates, session=session, n_per_page=6, height=400,\n",
    "                         annotator_name='gold_complex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
