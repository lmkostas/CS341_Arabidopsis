{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging genes with ddlite: learning and labeling function iteration\n",
    "\n",
    "## Introduction\n",
    "In this example **ddlite** app, we'll build a gene tagger from scratch. Domain-specific tagging systems take months or years to develop. They use hand-crafted model circuitry and accurate, hand-labeled training data. We'll start to build a pretty good one in a few minutes with none of those things. The generalized extraction and learning utilities provided by ddlite will allow us to turn a sampling of article abstracts and some basic domain knowledge into an automated tagging system. Specifically, we want an accurate tagger for genes in academic articles. We have comprehensive dictionaries of genes, but applying a simple matching rule might yield a lot of false positives. For example, \"p53\" might get tagged as a gene if it refers to a page number. Our goal is to use distant supervision to improve precision.\n",
    "\n",
    "Here's the pipeline we'll follow:\n",
    "\n",
    "1. Obtain and parse input data (relevant article abstracts from PubMed)\n",
    "2. Extract candidates for tagging\n",
    "3. Generate features\n",
    "4. Create a test set\n",
    "5. Write labeling functions\n",
    "6. Learn the tagging model\n",
    "7. Iterate on labeling functions\n",
    "\n",
    "Parts 3 through 7 are covered in this notebook. It requires candidates extracted from `GeneTaggerExample_Extraction.ipynb`, which covers parts 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import cPickle\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# print(os.environ['SNORKELDB'])\n",
    "# Use production DB\n",
    "from set_env import set_env\n",
    "set_env() \n",
    "sys.path.insert(1, '../snorkel')\n",
    "\n",
    "# Must set SNORKELDB before importing SnorkelSession\n",
    "from snorkel import SnorkelSession\n",
    "from snorkel.parser import TextDocPreprocessor\n",
    "from snorkel.parser import CorpusParser\n",
    "from snorkel.models import Document, Sentence, candidate_subclass\n",
    "from snorkel.viewer import SentenceNgramViewer\n",
    "session = SnorkelSession()\n",
    "\n",
    "#np.random.seed(seed=1701)\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (18,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading candidate extractions\n",
    "First, we'll load in the candidates that we created in the last notebook. We can construct an docs object with the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/ext/declarative/clsregistry.py:120: SAWarning: This declarative base already contains a class with the same class name and module name as snorkel.models.candidate.GenePhenoPair, and will be replaced in the string-lookup table.\n",
      "  item.__name__\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "Table 'gene_pheno_pair' is already defined for this MetaData instance.  Specify 'extend_existing=True' to redefine options and columns on an existing Table object.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fed0eb4f8ef3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGenePhenoPair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcandidate_subclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GenePhenoPair'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'gene'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pheno'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGenePhenoPair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGenePhenoPair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#should edit split to be 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Documents:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/snorkel/snorkel/models/candidate.pyc\u001b[0m in \u001b[0;36mcandidate_subclass\u001b[0;34m(class_name, args, table_name)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# Create class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCandidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_attribs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# Create table in DB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/ext/declarative/api.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(cls, classname, bases, dict_)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_decl_class_registry'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0m_as_declarative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/ext/declarative/base.pyc\u001b[0m in \u001b[0;36m_as_declarative\u001b[0;34m(cls, classname, dict_)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0m_MapperConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/ext/declarative/base.pyc\u001b[0m in \u001b[0;36msetup_mapping\u001b[0;34m(cls, cls_, classname, dict_)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mcfg_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MapperConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mcfg_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/ext/declarative/base.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cls_, classname, dict_)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_declared_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_inheritance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/ext/declarative/base.pyc\u001b[0m in \u001b[0;36m_setup_table\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m                     \u001b[0mtablename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                     \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeclared_columns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                     **table_kw)\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__table__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/sql/schema.pyc\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, *args, **kw)\u001b[0m\n\u001b[1;32m    419\u001b[0m                     \u001b[0;34m\"to redefine \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                     \u001b[0;34m\"options and columns on an \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                     \"existing Table object.\" % key)\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextend_existing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: Table 'gene_pheno_pair' is already defined for this MetaData instance.  Specify 'extend_existing=True' to redefine options and columns on an existing Table object."
     ]
    }
   ],
   "source": [
    "GenePhenoPair = candidate_subclass('GenePhenoPair', ['gene', 'pheno'])\n",
    "\n",
    "docs = session.query(GenePhenoPair).filter(GenePhenoPair.split == 0).all()  #should edit split to be 1. \n",
    "\n",
    "print \"Documents:\", session.query(Document).count()\n",
    "print \"Sentences:\", session.query(Sentence).count()\n",
    "\n",
    "##Once we get all the labels, for loop through all docs and split into train, dev, test. \n",
    "\n",
    "print 'Document set:\\t{0} candidates'.format(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Labeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from snorkel.lf_helpers import (\n",
    "    get_left_tokens,\n",
    "    get_between_tokens,\n",
    "    get_right_tokens,\n",
    "    contains_token,\n",
    "    get_doc_candidate_spans,\n",
    "    get_sent_candidate_spans,\n",
    "    get_text_between,\n",
    "    get_text_splits,\n",
    "    get_tagged_text,\n",
    "    is_inverted,\n",
    "    get_tagged_text,\n",
    "    rule_regex_search_tagged_text,\n",
    "    rule_regex_search_btw_AB,\n",
    "    rule_regex_search_btw_BA,\n",
    "    rule_regex_search_before_A,\n",
    "    rule_regex_search_before_B,\n",
    "    \n",
    ")\n",
    "\n",
    "def LF_gene(c):\n",
    "    return 1 if ('gene' in get_right_tokens(c, attrib='lemmas')) or ('gene' in get_left_tokens(c, attrib='lemmas')) else 0\n",
    "def LF_mutant(c):\n",
    "    return 1 if ('mutant' in get_right_tokens(c, attrib='lemmas')) or ('mutant' in get_left_tokens(c, attrib='lemmas')) else 0\n",
    "def LF_variant(c):\n",
    "    return 1 if ('variant' in get_right_tokens(c, attrib='lemmas')) or ('variant' in get_left_tokens(c, attrib='lemmas')) else 0\n",
    "def LF_express(c):\n",
    "    return 1 if ('express' in get_right_tokens(c, attrib='lemmas')) or ('express' in get_left_tokens(c, attrib='lemmas')) else 0  \n",
    "def LF_JJ(c):\n",
    "    return 1 if 'JJ' in get_right_tokens(c, attrib='pos_tags') else 0\n",
    "def LF_IN(c):\n",
    "    return 1 if 'IN' in get_right_tokens(c, window=1, attrib='pos_tags') else 0\n",
    "def LF_dna(c):\n",
    "    return -1 if contains_token(c, 'DNA', attrib='words') else 0\n",
    "def LF_rna(c):\n",
    "    return -1 if contains_token(c, 'RNA', attrib='words') else 0\n",
    "def LF_snp(c):\n",
    "    return -1 if contains_token(c, 'SNP', attrib='words') else 0\n",
    "def LF_protein(c):\n",
    "    return -1 if 'protein' in get_left_tokens(c, attrib='lemmas') else 0\n",
    "def LF_LRB(c):\n",
    "    return -1 if '-LRB-' in get_right_tokens(c, window=1, attrib='pos_tags') else 0\n",
    "def LF_RRB(c):\n",
    "    return -1 if '-RRB-' in get_right_tokens(c, window=1, attrib='pos_tags') else 0    \n",
    "def LF_NNP(c):\n",
    "    return -1 if contains_token(c, 'NNP', attrib='pos_tags') else 0\n",
    "\n",
    "action_link_words = set(['affect', 'lead', 'led', 'show', 'display', 'exhibit', 'cause', 'result in'])\n",
    "mutant_words = set(['mutant', 'mutation', 'plant', 'line', 'phenotype', 'seedlings', 'variant'])\n",
    "helper_vbs = set(['is', 'was', 'are', 'were', 'become', 'became'])\n",
    "tester_words = set(['sequence', 'published', 'diagram', 'hypothesis', 'hypothesize', 'aim', 'goal', 'understand', 'examine', 'we', 'our', 'experiment', 'test', 'study', 'design', 'analyze', 'analysis', 'results', 'research'])\n",
    "\n",
    "def lf1(c):\n",
    "    return 1 if 'in' in get_between_tokens(c, attrib='words') else 0\n",
    "\n",
    "def lf2(c):\n",
    "    return 1 if len(action_link_words.intersection(set(get_between_tokens(c, attrib='lemmas')))) > 0 else 0\n",
    "\n",
    "def lf2a(c):\n",
    "    for aw in action_link_words:\n",
    "        if contains_token(c[1], aw, attrib='lemmas'): return 1\n",
    "    return 0\n",
    "\n",
    "def lf3(c):\n",
    "    return 1 if contains_token(c[1], 'JJR', attrib='pos_tags') else 0\n",
    "\n",
    "def lf4(c):\n",
    "    return 1 if contains_token(c[1], r'fold') or contains_token(c[1], r'\\d+(\\.\\d+_)?%') or contains_token(c[1], 'percent') else 0\n",
    "\n",
    "def lf5(c):\n",
    "    return 1 if len(mutant_words.intersection(set(get_left_tokens(c[0], attrib='lemmas')))) > 0 or len(mutant_words.intersection(set(get_right_tokens(c[0], attrib='lemmas')))) > 0 else 0\n",
    "\n",
    "def lf6(c):\n",
    "    return 1 if len(helper_vbs.intersection(set(get_between_tokens(c, attrib='lemmas', n_max=3)))) > 0 else 0\n",
    "\n",
    "def lf7(c):\n",
    "    return -1 if 'not' in get_between_tokens(c) else 0\n",
    "\n",
    "def lf8(c):\n",
    "    return -1 if 'not' in get_left_tokens(c[0]) or 'not' in get_left_tokens(c[1]) else 0\n",
    "\n",
    "def lf9(c):\n",
    "    return -1 if 'level' in get_left_tokens(c[0], attrib='lemmas', n_max=2) or 'level' in get_right_tokens(c[0], attrib='lemmas', n_max=2) else 0\n",
    "\n",
    "def lf10(c):\n",
    "    return -1 if 'transcript' in get_left_tokens(c[0], attrib='lemmas', n_max=3) or 'transcript' in get_right_tokens(c[0], attrib='lemmas', n_max=2) else 0\n",
    "\n",
    "def lf11(c):\n",
    "    return -1 if not contains_token(c[1], 'JJR', attrib='pos_tags') and not contains_token(c[1], 'JJ', attrib='pos_tags') and not contains_token(c[1], 'VBN', attrib='pos_tags') else 0\n",
    "\n",
    "def inverted(c):\n",
    "    return 1 if is_inverted(c) else 0\n",
    "\n",
    "def lf12(c):\n",
    "    return 1 if inverted(c) and lf1(c) else 0\n",
    "\n",
    "def lf13(c):\n",
    "    return 1 if inverted(c) and 'IN' in get_between_tokens(c, attrib='pos_tags', n_max=4) else 0\n",
    "\n",
    "def lf14(c):\n",
    "    return 1 if contains_token(c[1], 'phenotype', attrib='lemmas') else 0\n",
    "\n",
    "def lf15(c):\n",
    "    return -1 if 'protein' in get_left_tokens(c[0], attrib='lemmas') or 'protein' in get_right_tokens(c[0], attrib='lemmas') else 0\n",
    "\n",
    "def lf16(c):\n",
    "    return -1 if 'activity' in get_left_tokens(c[0], attrib='lemmas', n_max=2) or 'level' in get_right_tokens(c[0], attrib='lemmas', n_max=1) else 0\n",
    "\n",
    "def lf17(c):\n",
    "    return -1 if len(tester_words.intersection(set(get_tagged_text(c).split()))) > 0 else 0\n",
    "\n",
    "def LF_gene_dp(c):\n",
    "    return 1 if 'gene' in get_left_tokens(c[0], window=2, attrib='lemmas') else 0\n",
    "def LF_genotype_dp(c):\n",
    "    return 1 if 'genotype' in get_left_tokens(c[0], window=2, attrib='lemmas') else 0\n",
    "def LF_phenotype_dp(c):\n",
    "    return 1 if 'phenotype' in get_right_tokens(c[1], window=2, attrib='lemmas') else 0\n",
    "def LF_mutation(c):\n",
    "    return 1 if ('mutation' in get_right_tokens(c[0], window=2, attrib='lemmas') or 'mutant' in get_right_tokens(c[0], window=2, attrib='lemmas') or 'mutations' in get_right_tokens(c[0], window=2, attrib='lemmas')) else 0\n",
    "\n",
    "def LF_pheno(c):\n",
    "    return 1 if contains_token(c, 'phenotype', attrib='words') else 0\n",
    "\n",
    "def LF_dev_dp(c):\n",
    "    return -1 if 'development' in get_right_tokens(c[1], window=2, attrib='lemmas')  else 0\n",
    "def LF_protein_dp(c):\n",
    "    return -1 if 'protein' in get_right_tokens(c[1], window=2, attrib='lemmas') else 0\n",
    "def LF_network_dp(c):\n",
    "    return -1 if 'network' in get_right_tokens(c[1], window=2, attrib='lemmas') else 0\n",
    "def LF_JJ_dp(c):\n",
    "    return -1 if 'JJ' in get_right_tokens(c[1], window=2, attrib='pos_tags') else 0\n",
    "\n",
    "def lf_helpers(c):\n",
    "    return 1 if any(word in get_left_tokens(c[1], window=2, attrib='words') for word in ['had', 'has', 'was', 'have']) else 0\n",
    "\n",
    "adj_words = set(['increase', 'lower', 'reduce', 'higher', 'less', 'more', 'elevate', 'decrease', 'insensitive', 'absence'])\n",
    "def lf_adjwords(c):\n",
    "    for aw in adj_words:\n",
    "        if contains_token(c[1], aw, attrib='lemmas'): return 1\n",
    "    return 0\n",
    "    \n",
    "stats_words = set(['statistically', 'quantitative', 'real-time', 'generated', 'exposed', 'stratified'])\n",
    "def lf_statswords(c):\n",
    "    for aw in adj_words:\n",
    "        if contains_token(c[1], aw, attrib='lemmas'): return -1\n",
    "    return 0\n",
    "\n",
    "def lfj_1(c):\n",
    "     return 1 if any([word in get_left_tokens(c[1], window=2, attrib='words') for word in ['is', 'are']]) else 0\n",
    "        \n",
    "def lfj_2(c):\n",
    "    return 1 if any([word in get_left_tokens(c[1], window=2, attrib='words') for word in ['showed', 'were', 'results']]) else 0\n",
    "    \n",
    "def lfj_3(c):\n",
    "    return 1 if any([contains_token(c[1], word, attrib='lemmas') for word in ['affected',]]) else 0\n",
    "\n",
    "def lfj_4(c):\n",
    "    return -1 if any([contains_token(c, word, attrib='words') for word in ['brassica', 'rapeseed']]) else 0\n",
    "\n",
    "def lfj_5(c):\n",
    "    return -1 if any([contains_token(span, 'brassica', attrib='words') for span in get_doc_candidate_spans(c)]) else 0\n",
    "\n",
    "def lfj_6(c):\n",
    "    return -1 if 'table' in get_right_tokens(c[1], window=3, attrib='lemmas') else 0\n",
    "\n",
    "def lfj_7(c):\n",
    "    return 1 if 'mutation' in get_right_tokens(c[1], window=7, attrib='lemmas') else 0\n",
    "\n",
    "def lfj_8(c):\n",
    "    return 1 if 'mutants' in get_right_tokens(c[0], window=1, attrib='words') else 0\n",
    "\n",
    "def lfj_9(c):\n",
    "    return -1 if len(get_sent_candidate_spans(c)) > 6 else 0\n",
    "\n",
    "def lfj_10(c):\n",
    "    return -1 if 'we' in get_left_tokens(c[0], window=10, attrib='words') else 0\n",
    "    \n",
    "# tablex\n",
    "# www.\n",
    "# rna\n",
    "\n",
    "## before phenotype\n",
    "# mutant\n",
    "# results\n",
    "# had\n",
    "# has\n",
    "# was\n",
    "# have\n",
    "# showed\n",
    "# were\n",
    "# is\n",
    "# are\n",
    "\n",
    "\n",
    "# dependency parents test. \n",
    "# def LF_gene_dp(c):\n",
    "#     return 1 if 'gene' in [c.get_parent()[i] for i in (c[0]).get_attrib_tokens('dep_parents')] else 0\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lf18(c):\n",
    "    return 1 if 'mutant' in get_tagged_text(c).split() or 'mutation' in get_text_splits(c) else 0\n",
    "\n",
    "def lf19(c):\n",
    "    lemmas = c[1].get_attrib_tokens('lemmas')\n",
    "    poses = c[1].get_attrib_tokens('pos_tags')\n",
    "    for i, w in enumerate(poses):\n",
    "        if w in ['NN', 'NNS', 'NNP', 'NNPS'] and not re.match(r'\\w+(ion|ment|vity)', lemmas[i]):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def lf20(c):\n",
    "    lemmas = c[1].get_attrib_tokens('lemmas')\n",
    "    poses = c[1].get_attrib_tokens('pos_tags')\n",
    "    result = 0\n",
    "    for i, w in enumerate(lemmas):\n",
    "        if w in ['NN', 'NNS', 'NNP', 'NNPS'] and not re.match(r'\\w+(ion|ment|vity)', lemmas[i]):\n",
    "            result = 0\n",
    "        elif re.match(r'\\w+(ion|ment|vity)', lemmas[i]):\n",
    "            result = -1\n",
    "    return result\n",
    "\n",
    "def lf21(c):\n",
    "    return rule_regex_search_btw_BA(c, '.* in .*', 1)\n",
    "\n",
    "def lf22(c):\n",
    "    return -1 if 'expression' in get_right_tokens(c[0], attrib='lemmas', window=2) or 'expression' in get_left_tokens(c[0], attrib='lemmas', window=2) else 0\n",
    "    \n",
    "def lf23(c):\n",
    "    return -1 if not inverted(c) and len(helper_vbs.intersection(set(get_left_tokens(c[1], window = 1, attrib='lemmas')))) > 0 and ('VBN' == c[1].get_attrib_tokens('pos_tags')[0] or ('VBN' == c[1].get_attrib_tokens('pos_tags')[1] and 'RB' == c[1].get_attrib_tokens('pos_tags')[0])) else 0\n",
    "\n",
    "def lf24(c):\n",
    "    return -1 if not contains_token(c[1], 'VB', attrib='pos_tags') and not contains_token(c[1], 'VBZ', attrib='pos_tags') and not contains_token(c[1], 'VBD', attrib='pos_tags') else 0\n",
    "\n",
    "def lf25(c):\n",
    "    return -1 if 'IN' == c[1].get_attrib_tokens('pos_tags')[0] or 'TO' == c[1].get_attrib_tokens('pos_tags')[0] else 0\n",
    "\n",
    "def lf26(c):\n",
    "    return -1 if 'JJR' == c[1].get_attrib_tokens('pos_tags')[0] and len(set(['NN', 'NNS', 'NNP', 'NNPS']).intersection(set(c[1].get_attrib_tokens('pos_tags')[1]))) == 0 else 0\n",
    "\n",
    "def lf27(c):\n",
    "    hasNoNoun = len(set(['NN', 'NNS', 'NNP', 'NNPS']).intersection(set(c[1].get_attrib_tokens('pos_tags')[1]))) == 0\n",
    "    return -1 if len(c[1]) < 3 and hasNoNoun else 0\n",
    "                  \n",
    "def lf28(c):\n",
    "    lastWordAdj = True if c[1].get_attrib_tokens('pos_tags')[-1] in set(['JJ', 'JJR']) else False\n",
    "    nextLastVerb = True if c[1].get_attrib_tokens('lemmas')[-2] in helper_vbs else False\n",
    "    return -1 if not nextLastVerb and lastWordAdj else 0              \n",
    "    \n",
    "def lf29(c):                  #if pheno ends in VBG, its bad\n",
    "    return -1 if c[1].get_attrib_tokens('pos_tags')[-1] == 'VBG' else 0\n",
    "\n",
    "def lf30(c):                #if ends in prep, its bad\n",
    "    return -1 if c[1].get_attrib_tokens('pos_tags')[-1] == 'IN' else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Skipping over dependency parent LFs. \n",
    "''' Dependency Parents \n",
    "def LF_gene_dp(m):\n",
    "    return 1 if 'gene' in [m.lemmas[m.dep_parents[i] - 1] for i in m.idxs] else 0\n",
    "def LF_genotype_dp(m):\n",
    "    return 1 if 'genotype' in [m.lemmas[m.dep_parents[i] - 1] for i in m.idxs] else 0\n",
    "def LF_mutation(m):\n",
    "    return 1 if 'mutation' in [m.lemmas[m.dep_parents[i] - 1] for i in m.idxs] else 0\n",
    "\n",
    "\n",
    "def LF_dev_dp(m):\n",
    "    return -1 if 'development' in [m.lemmas[m.dep_parents[i] - 1] for i in m.idxs] else 0\n",
    "def LF_protein_dp(m):\n",
    "    return -1 if 'protein' in [m.lemmas[m.dep_parents[i] - 1] for i in m.idxs] else 0\n",
    "def LF_network_dp(m):\n",
    "    return -1 if 'network' in [m.lemmas[m.dep_parents[i] - 1] for i in m.idxs] else 0\n",
    "def LF_JJ_dp(m):\n",
    "    return -1 if 'JJ' in [m.poses[m.dep_parents[i] - 1] for i in m.idxs] else 0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenePhenoPair2(Span(\"srfr1-4\", sentence=1167385, chars=[164,170], words=[26,26]), Span(\"Because the transgenic copy of\", sentence=1167385, chars=[0,29], words=[0,4]))\n",
      "Sentence(Document PMC2973837,29,Because the transgenic copy of SRFR1 prevented us from determining whether these T3 lines were homozygous or heterozygous for the srfr1-4 allele, we tested whether srfr1-4 segregated in the next generation by genotyping 15 progeny for each line. )\n",
      "[u'Because', u'the', u'transgenic', u'copy', u'of', u'SRFR1', u'prevented', u'us', u'from', u'determining', u'whether', u'these', u'T3', u'lines', u'were', u'homozygous', u'or', u'heterozygous', u'for', u'the', u'srfr1-4', u'allele,', u'we', u'tested', u'whether', u'srfr1-4', u'segregated', u'in', u'the', u'next', u'generation', u'by', u'genotyping', u'15', u'progeny', u'for', u'each', u'line.']\n",
      "[u'of']\n",
      "\n",
      "\n",
      "REGEX VERSION: \n",
      "[u'Because', u'the', u'transgenic', u'copy', u'of', u'SRFR1', u'prevented', u'us', u'from', u'determining', u'whether', u'these', u'T3', u'lines', u'were', u'homozygous', u'or', u'heterozygous', u'for', u'the', u'srfr1-4', u'allele,', u'we', u'tested', u'whether', u'srfr1-4', u'segregated', u'in', u'the', u'next', u'generation', u'by', u'genotyping', u'15', u'progeny', u'for', u'each', u'line.', u'']\n",
      "[u'of']\n",
      "\n",
      "\n",
      "(Span(\"srfr1-4\", sentence=1167385, chars=[164,170], words=[26,26]), Span(\"Because the transgenic copy of\", sentence=1167385, chars=[0,29], words=[0,4]))\n",
      "[u'srfr1-4']\n",
      "[u'', '{{B}}', u' SRFR1 prevented us from determining whether these T3 lines were homozygous or heterozygous for the srfr1-4 allele, we tested whether ', '{{A}}', u' segregated in the next generation by genotyping 15 progeny for each line. ']\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models.context import TemporaryContext\n",
    "import re\n",
    "\n",
    "\n",
    "print docs[15]\n",
    "sent = docs[15].get_parent()\n",
    "print sent\n",
    "text = sent._asdict()['text']\n",
    "splt = text.split()\n",
    "print splt\n",
    "print splt[4:5]\n",
    "print \"\\n\"\n",
    "print \"REGEX VERSION: \"\n",
    "\n",
    "resplit = re.split(' ',text)\n",
    "print resplit\n",
    "print resplit[4:5]\n",
    "print \"\\n\"\n",
    "\n",
    "print docs[15].get_contexts()\n",
    "print (docs[15][0]).get_attrib_tokens('words')\n",
    "# print (docs[15][0]).get_attrib_tokens('dep_parents')\n",
    "\n",
    "#print LF_DP(docs[0])\n",
    "print get_text_splits(docs[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running LFs on the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LFs = [\n",
    "    LF_gene,\n",
    "    LF_mutant,\n",
    "    LF_variant,\n",
    "    LF_express,\n",
    "    LF_JJ,\n",
    "    LF_IN,\n",
    "    LF_dna,\n",
    "    LF_rna,\n",
    "    LF_snp,\n",
    "    LF_protein,\n",
    "    LF_LRB,\n",
    "    LF_RRB,\n",
    "    LF_NNP,\n",
    "    lf1,\n",
    "    lf2,\n",
    "    lf3,\n",
    "    lf4,\n",
    "    lf5,\n",
    "    lf6,\n",
    "    lf7,\n",
    "    lf8,\n",
    "    lf9,\n",
    "    lf10,\n",
    "    lf11,\n",
    "    lf2a,\n",
    "    lf12,\n",
    "    lf13,\n",
    "    lf14,\n",
    "    lf15,\n",
    "    lf16,\n",
    "    lf17,\n",
    "    lf18,\n",
    "    lf19,\n",
    "    lf20,\n",
    "    lf21,\n",
    "    lf22,\n",
    "    lf23,\n",
    "    lf24,\n",
    "    lf25,\n",
    "    lf26,\n",
    "    lf27,\n",
    "    lf28,\n",
    "    lf29,\n",
    "    lf30,\n",
    "    LF_gene_dp,\n",
    "    LF_genotype_dp,\n",
    "    LF_phenotype_dp,\n",
    "    LF_mutation,\n",
    "    LF_pheno,\n",
    "    LF_dev_dp,\n",
    "    LF_protein_dp,\n",
    "    LF_network_dp,\n",
    "    LF_JJ_dp,\n",
    "    lf_helpers,\n",
    "    lf_adjwords,\n",
    "    lf_statswords,\n",
    "    lfj_1,\n",
    "    lfj_2,\n",
    "    lfj_3,\n",
    "    lfj_4,\n",
    "    lfj_5,\n",
    "    lfj_6,\n",
    "    lfj_7,\n",
    "    lfj_8,\n",
    "#     lfj_9,\n",
    "    lfj_10,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelAnnotator\n",
    "import multiprocessing\n",
    "labeler = LabelAnnotator(f=LFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 268, in _feed\n",
      "    send(obj)\n",
      "IOError: [Errno 32] Broken pipe\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 268, in _feed\n",
      "    send(obj)\n",
      "IOError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.8 s, sys: 444 ms, total: 6.25 s\n",
      "Wall time: 3min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1073x66 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 5974 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train = labeler.apply(split=0, parallelism=multiprocessing.cpu_count())\n",
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_gene</th>\n",
       "      <td>0</td>\n",
       "      <td>0.018639</td>\n",
       "      <td>0.018639</td>\n",
       "      <td>0.017707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_mutant</th>\n",
       "      <td>1</td>\n",
       "      <td>0.016775</td>\n",
       "      <td>0.016775</td>\n",
       "      <td>0.016775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_variant</th>\n",
       "      <td>2</td>\n",
       "      <td>0.005592</td>\n",
       "      <td>0.005592</td>\n",
       "      <td>0.005592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_express</th>\n",
       "      <td>3</td>\n",
       "      <td>0.018639</td>\n",
       "      <td>0.018639</td>\n",
       "      <td>0.018639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_JJ</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_IN</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_dna</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_rna</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_snp</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_protein</th>\n",
       "      <td>9</td>\n",
       "      <td>0.007456</td>\n",
       "      <td>0.007456</td>\n",
       "      <td>0.007456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_LRB</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_RRB</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_NNP</th>\n",
       "      <td>12</td>\n",
       "      <td>0.117428</td>\n",
       "      <td>0.117428</td>\n",
       "      <td>0.116496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf1</th>\n",
       "      <td>13</td>\n",
       "      <td>0.219944</td>\n",
       "      <td>0.219944</td>\n",
       "      <td>0.218080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf2</th>\n",
       "      <td>14</td>\n",
       "      <td>0.112768</td>\n",
       "      <td>0.112768</td>\n",
       "      <td>0.112768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf3</th>\n",
       "      <td>15</td>\n",
       "      <td>0.111836</td>\n",
       "      <td>0.111836</td>\n",
       "      <td>0.111836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf4</th>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf5</th>\n",
       "      <td>17</td>\n",
       "      <td>0.234856</td>\n",
       "      <td>0.234856</td>\n",
       "      <td>0.232060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf6</th>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf7</th>\n",
       "      <td>19</td>\n",
       "      <td>0.047530</td>\n",
       "      <td>0.047530</td>\n",
       "      <td>0.046598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf8</th>\n",
       "      <td>20</td>\n",
       "      <td>0.027959</td>\n",
       "      <td>0.027959</td>\n",
       "      <td>0.025163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf9</th>\n",
       "      <td>21</td>\n",
       "      <td>0.015843</td>\n",
       "      <td>0.015843</td>\n",
       "      <td>0.013979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf10</th>\n",
       "      <td>22</td>\n",
       "      <td>0.012116</td>\n",
       "      <td>0.012116</td>\n",
       "      <td>0.011184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf11</th>\n",
       "      <td>23</td>\n",
       "      <td>0.037279</td>\n",
       "      <td>0.037279</td>\n",
       "      <td>0.037279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf2a</th>\n",
       "      <td>24</td>\n",
       "      <td>0.036347</td>\n",
       "      <td>0.036347</td>\n",
       "      <td>0.028891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf12</th>\n",
       "      <td>25</td>\n",
       "      <td>0.107176</td>\n",
       "      <td>0.107176</td>\n",
       "      <td>0.105312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf13</th>\n",
       "      <td>26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf14</th>\n",
       "      <td>27</td>\n",
       "      <td>0.069897</td>\n",
       "      <td>0.069897</td>\n",
       "      <td>0.066170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf15</th>\n",
       "      <td>28</td>\n",
       "      <td>0.049394</td>\n",
       "      <td>0.049394</td>\n",
       "      <td>0.044734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf16</th>\n",
       "      <td>29</td>\n",
       "      <td>0.009320</td>\n",
       "      <td>0.009320</td>\n",
       "      <td>0.009320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf23</th>\n",
       "      <td>36</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf24</th>\n",
       "      <td>37</td>\n",
       "      <td>0.848089</td>\n",
       "      <td>0.848089</td>\n",
       "      <td>0.809879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf25</th>\n",
       "      <td>38</td>\n",
       "      <td>0.169618</td>\n",
       "      <td>0.169618</td>\n",
       "      <td>0.162162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf26</th>\n",
       "      <td>39</td>\n",
       "      <td>0.077353</td>\n",
       "      <td>0.077353</td>\n",
       "      <td>0.077353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf27</th>\n",
       "      <td>40</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf28</th>\n",
       "      <td>41</td>\n",
       "      <td>0.175210</td>\n",
       "      <td>0.174278</td>\n",
       "      <td>0.145387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf29</th>\n",
       "      <td>42</td>\n",
       "      <td>0.021435</td>\n",
       "      <td>0.021435</td>\n",
       "      <td>0.021435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf30</th>\n",
       "      <td>43</td>\n",
       "      <td>0.146319</td>\n",
       "      <td>0.146319</td>\n",
       "      <td>0.135135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_gene_dp</th>\n",
       "      <td>44</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.003728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_genotype_dp</th>\n",
       "      <td>45</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_phenotype_dp</th>\n",
       "      <td>46</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_mutation</th>\n",
       "      <td>47</td>\n",
       "      <td>0.076421</td>\n",
       "      <td>0.076421</td>\n",
       "      <td>0.074557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_pheno</th>\n",
       "      <td>48</td>\n",
       "      <td>0.058714</td>\n",
       "      <td>0.058714</td>\n",
       "      <td>0.054986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_dev_dp</th>\n",
       "      <td>49</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.001864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_protein_dp</th>\n",
       "      <td>50</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.001864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_network_dp</th>\n",
       "      <td>51</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_JJ_dp</th>\n",
       "      <td>52</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_helpers</th>\n",
       "      <td>53</td>\n",
       "      <td>0.082013</td>\n",
       "      <td>0.082013</td>\n",
       "      <td>0.082013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_adjwords</th>\n",
       "      <td>54</td>\n",
       "      <td>0.131407</td>\n",
       "      <td>0.131407</td>\n",
       "      <td>0.131407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_statswords</th>\n",
       "      <td>55</td>\n",
       "      <td>0.131407</td>\n",
       "      <td>0.131407</td>\n",
       "      <td>0.131407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfj_1</th>\n",
       "      <td>56</td>\n",
       "      <td>0.057782</td>\n",
       "      <td>0.057782</td>\n",
       "      <td>0.056850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfj_2</th>\n",
       "      <td>57</td>\n",
       "      <td>0.053122</td>\n",
       "      <td>0.053122</td>\n",
       "      <td>0.053122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfj_3</th>\n",
       "      <td>58</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfj_4</th>\n",
       "      <td>59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfj_5</th>\n",
       "      <td>60</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfj_6</th>\n",
       "      <td>61</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>0.002796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfj_7</th>\n",
       "      <td>62</td>\n",
       "      <td>0.012116</td>\n",
       "      <td>0.012116</td>\n",
       "      <td>0.012116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfj_8</th>\n",
       "      <td>63</td>\n",
       "      <td>0.023299</td>\n",
       "      <td>0.023299</td>\n",
       "      <td>0.022367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfj_9</th>\n",
       "      <td>64</td>\n",
       "      <td>0.630009</td>\n",
       "      <td>0.630009</td>\n",
       "      <td>0.604846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfj_10</th>\n",
       "      <td>65</td>\n",
       "      <td>0.027959</td>\n",
       "      <td>0.027959</td>\n",
       "      <td>0.026095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  j  Coverage  Overlaps  Conflicts\n",
       "LF_gene           0  0.018639  0.018639   0.017707\n",
       "LF_mutant         1  0.016775  0.016775   0.016775\n",
       "LF_variant        2  0.005592  0.005592   0.005592\n",
       "LF_express        3  0.018639  0.018639   0.018639\n",
       "LF_JJ             4  0.000000  0.000000   0.000000\n",
       "LF_IN             5  0.000000  0.000000   0.000000\n",
       "LF_dna            6  0.000000  0.000000   0.000000\n",
       "LF_rna            7  0.000000  0.000000   0.000000\n",
       "LF_snp            8  0.000000  0.000000   0.000000\n",
       "LF_protein        9  0.007456  0.007456   0.007456\n",
       "LF_LRB           10  0.000000  0.000000   0.000000\n",
       "LF_RRB           11  0.000000  0.000000   0.000000\n",
       "LF_NNP           12  0.117428  0.117428   0.116496\n",
       "lf1              13  0.219944  0.219944   0.218080\n",
       "lf2              14  0.112768  0.112768   0.112768\n",
       "lf3              15  0.111836  0.111836   0.111836\n",
       "lf4              16  0.000000  0.000000   0.000000\n",
       "lf5              17  0.234856  0.234856   0.232060\n",
       "lf6              18  0.000000  0.000000   0.000000\n",
       "lf7              19  0.047530  0.047530   0.046598\n",
       "lf8              20  0.027959  0.027959   0.025163\n",
       "lf9              21  0.015843  0.015843   0.013979\n",
       "lf10             22  0.012116  0.012116   0.011184\n",
       "lf11             23  0.037279  0.037279   0.037279\n",
       "lf2a             24  0.036347  0.036347   0.028891\n",
       "lf12             25  0.107176  0.107176   0.105312\n",
       "lf13             26  0.000000  0.000000   0.000000\n",
       "lf14             27  0.069897  0.069897   0.066170\n",
       "lf15             28  0.049394  0.049394   0.044734\n",
       "lf16             29  0.009320  0.009320   0.009320\n",
       "...              ..       ...       ...        ...\n",
       "lf23             36  0.000000  0.000000   0.000000\n",
       "lf24             37  0.848089  0.848089   0.809879\n",
       "lf25             38  0.169618  0.169618   0.162162\n",
       "lf26             39  0.077353  0.077353   0.077353\n",
       "lf27             40  0.000000  0.000000   0.000000\n",
       "lf28             41  0.175210  0.174278   0.145387\n",
       "lf29             42  0.021435  0.021435   0.021435\n",
       "lf30             43  0.146319  0.146319   0.135135\n",
       "LF_gene_dp       44  0.003728  0.003728   0.003728\n",
       "LF_genotype_dp   45  0.000000  0.000000   0.000000\n",
       "LF_phenotype_dp  46  0.000000  0.000000   0.000000\n",
       "LF_mutation      47  0.076421  0.076421   0.074557\n",
       "LF_pheno         48  0.058714  0.058714   0.054986\n",
       "LF_dev_dp        49  0.001864  0.001864   0.001864\n",
       "LF_protein_dp    50  0.003728  0.003728   0.001864\n",
       "LF_network_dp    51  0.000000  0.000000   0.000000\n",
       "LF_JJ_dp         52  0.000000  0.000000   0.000000\n",
       "lf_helpers       53  0.082013  0.082013   0.082013\n",
       "lf_adjwords      54  0.131407  0.131407   0.131407\n",
       "lf_statswords    55  0.131407  0.131407   0.131407\n",
       "lfj_1            56  0.057782  0.057782   0.056850\n",
       "lfj_2            57  0.053122  0.053122   0.053122\n",
       "lfj_3            58  0.000000  0.000000   0.000000\n",
       "lfj_4            59  0.000000  0.000000   0.000000\n",
       "lfj_5            60  0.000000  0.000000   0.000000\n",
       "lfj_6            61  0.002796  0.002796   0.002796\n",
       "lfj_7            62  0.012116  0.012116   0.012116\n",
       "lfj_8            63  0.023299  0.023299   0.022367\n",
       "lfj_9            64  0.630009  0.630009   0.604846\n",
       "lfj_10           65  0.027959  0.027959   0.026095\n",
       "\n",
       "[66 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train.lf_stats(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>Coverage</b> is the fraction of candidates that the labeling function emits a non-zero label for.\n",
    "* <b>Overlap</b> is the fraction candidates that the labeling function emits a non-zero label for and that another labeling function emits a non-zero label for.\n",
    "* <b>Conflict</b> is the fraction candidates that the labeling function emits a non-zero label for and that another labeling function emits a conflicting non-zero label for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.learning.structure import DependencySelector\n",
    "ds = DependencySelector()\n",
    "deps = ds.select(L_train, threshold=0.1)\n",
    "len(deps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 4, 0),\n",
       " (0, 5, 0),\n",
       " (0, 6, 0),\n",
       " (0, 7, 0),\n",
       " (0, 8, 0),\n",
       " (0, 10, 0),\n",
       " (0, 11, 0),\n",
       " (0, 16, 0),\n",
       " (0, 18, 0),\n",
       " (0, 22, 0),\n",
       " (0, 26, 0),\n",
       " (0, 30, 0),\n",
       " (0, 31, 0),\n",
       " (0, 32, 0),\n",
       " (0, 33, 0),\n",
       " (0, 38, 0),\n",
       " (0, 39, 0),\n",
       " (1, 4, 0),\n",
       " (1, 5, 0),\n",
       " (1, 6, 0),\n",
       " (1, 7, 0),\n",
       " (1, 8, 0),\n",
       " (1, 10, 0),\n",
       " (1, 11, 0),\n",
       " (1, 16, 0),\n",
       " (1, 17, 0),\n",
       " (1, 18, 0),\n",
       " (1, 26, 0),\n",
       " (1, 30, 0),\n",
       " (1, 32, 0),\n",
       " (1, 33, 0),\n",
       " (1, 34, 0),\n",
       " (1, 36, 0),\n",
       " (1, 37, 0),\n",
       " (1, 38, 0),\n",
       " (1, 39, 0),\n",
       " (2, 3, 0),\n",
       " (2, 4, 0),\n",
       " (2, 5, 0),\n",
       " (2, 6, 0),\n",
       " (2, 7, 0),\n",
       " (2, 8, 0),\n",
       " (2, 10, 0),\n",
       " (2, 11, 0),\n",
       " (2, 16, 0),\n",
       " (2, 18, 0),\n",
       " (2, 26, 0),\n",
       " (2, 30, 0),\n",
       " (2, 31, 0),\n",
       " (2, 32, 0),\n",
       " (2, 33, 0),\n",
       " (2, 34, 0),\n",
       " (2, 36, 0),\n",
       " (2, 37, 0),\n",
       " (2, 38, 0),\n",
       " (2, 39, 0),\n",
       " (3, 4, 0),\n",
       " (3, 5, 0),\n",
       " (3, 6, 0),\n",
       " (3, 7, 0),\n",
       " (3, 8, 0),\n",
       " (3, 10, 0),\n",
       " (3, 11, 0),\n",
       " (3, 16, 0),\n",
       " (3, 18, 0),\n",
       " (3, 26, 0),\n",
       " (3, 30, 0),\n",
       " (3, 32, 0),\n",
       " (3, 33, 0),\n",
       " (3, 36, 0),\n",
       " (3, 38, 0),\n",
       " (3, 39, 0),\n",
       " (4, 5, 0),\n",
       " (4, 6, 0),\n",
       " (4, 7, 0),\n",
       " (4, 8, 0),\n",
       " (4, 9, 0),\n",
       " (4, 10, 0),\n",
       " (4, 11, 0),\n",
       " (4, 16, 0),\n",
       " (4, 18, 0),\n",
       " (4, 22, 0),\n",
       " (4, 26, 0),\n",
       " (4, 29, 0),\n",
       " (4, 30, 0),\n",
       " (4, 31, 0),\n",
       " (4, 32, 0),\n",
       " (4, 33, 0),\n",
       " (4, 34, 0),\n",
       " (4, 36, 0),\n",
       " (4, 37, 0),\n",
       " (4, 38, 0),\n",
       " (4, 39, 0),\n",
       " (5, 6, 0),\n",
       " (5, 7, 0),\n",
       " (5, 8, 0),\n",
       " (5, 9, 0),\n",
       " (5, 10, 0),\n",
       " (5, 11, 0),\n",
       " (5, 16, 0),\n",
       " (5, 18, 0),\n",
       " (5, 22, 0),\n",
       " (5, 26, 0),\n",
       " (5, 29, 0),\n",
       " (5, 30, 0),\n",
       " (5, 31, 0),\n",
       " (5, 32, 0),\n",
       " (5, 33, 0),\n",
       " (5, 34, 0),\n",
       " (5, 36, 0),\n",
       " (5, 37, 0),\n",
       " (5, 38, 0),\n",
       " (5, 39, 0),\n",
       " (6, 7, 0),\n",
       " (6, 8, 0),\n",
       " (6, 9, 0),\n",
       " (6, 10, 0),\n",
       " (6, 11, 0),\n",
       " (6, 16, 0),\n",
       " (6, 18, 0),\n",
       " (6, 22, 0),\n",
       " (6, 26, 0),\n",
       " (6, 29, 0),\n",
       " (6, 30, 0),\n",
       " (6, 31, 0),\n",
       " (6, 32, 0),\n",
       " (6, 33, 0),\n",
       " (6, 34, 0),\n",
       " (6, 36, 0),\n",
       " (6, 37, 0),\n",
       " (6, 38, 0),\n",
       " (6, 39, 0),\n",
       " (7, 8, 0),\n",
       " (7, 9, 0),\n",
       " (7, 10, 0),\n",
       " (7, 11, 0),\n",
       " (7, 16, 0),\n",
       " (7, 18, 0),\n",
       " (7, 22, 0),\n",
       " (7, 26, 0),\n",
       " (7, 29, 0),\n",
       " (7, 30, 0),\n",
       " (7, 31, 0),\n",
       " (7, 32, 0),\n",
       " (7, 33, 0),\n",
       " (7, 34, 0),\n",
       " (7, 36, 0),\n",
       " (7, 37, 0),\n",
       " (7, 38, 0),\n",
       " (7, 39, 0),\n",
       " (8, 9, 0),\n",
       " (8, 10, 0),\n",
       " (8, 11, 0),\n",
       " (8, 16, 0),\n",
       " (8, 18, 0),\n",
       " (8, 22, 0),\n",
       " (8, 26, 0),\n",
       " (8, 29, 0),\n",
       " (8, 30, 0),\n",
       " (8, 31, 0),\n",
       " (8, 32, 0),\n",
       " (8, 33, 0),\n",
       " (8, 34, 0),\n",
       " (8, 36, 0),\n",
       " (8, 37, 0),\n",
       " (8, 38, 0),\n",
       " (8, 39, 0),\n",
       " (9, 10, 0),\n",
       " (9, 11, 0),\n",
       " (9, 16, 0),\n",
       " (9, 18, 0),\n",
       " (9, 26, 0),\n",
       " (9, 28, 0),\n",
       " (9, 30, 0),\n",
       " (9, 32, 0),\n",
       " (9, 33, 0),\n",
       " (9, 34, 0),\n",
       " (9, 36, 0),\n",
       " (9, 38, 0),\n",
       " (9, 39, 0),\n",
       " (10, 11, 0),\n",
       " (10, 16, 0),\n",
       " (10, 18, 0),\n",
       " (10, 22, 0),\n",
       " (10, 26, 0),\n",
       " (10, 29, 0),\n",
       " (10, 30, 0),\n",
       " (10, 31, 0),\n",
       " (10, 32, 0),\n",
       " (10, 33, 0),\n",
       " (10, 34, 0),\n",
       " (10, 36, 0),\n",
       " (10, 37, 0),\n",
       " (10, 38, 0),\n",
       " (10, 39, 0),\n",
       " (11, 16, 0),\n",
       " (11, 18, 0),\n",
       " (11, 22, 0),\n",
       " (11, 26, 0),\n",
       " (11, 29, 0),\n",
       " (11, 30, 0),\n",
       " (11, 31, 0),\n",
       " (11, 32, 0),\n",
       " (11, 33, 0),\n",
       " (11, 34, 0),\n",
       " (11, 36, 0),\n",
       " (11, 37, 0),\n",
       " (11, 38, 0),\n",
       " (11, 39, 0),\n",
       " (12, 34, 0),\n",
       " (13, 14, 0),\n",
       " (13, 25, 0),\n",
       " (14, 15, 0),\n",
       " (14, 17, 0),\n",
       " (15, 40, 0),\n",
       " (16, 18, 0),\n",
       " (16, 22, 0),\n",
       " (16, 26, 0),\n",
       " (16, 29, 0),\n",
       " (16, 30, 0),\n",
       " (16, 31, 0),\n",
       " (16, 32, 0),\n",
       " (16, 33, 0),\n",
       " (16, 34, 0),\n",
       " (16, 36, 0),\n",
       " (16, 37, 0),\n",
       " (16, 38, 0),\n",
       " (16, 39, 0),\n",
       " (18, 22, 0),\n",
       " (18, 26, 0),\n",
       " (18, 29, 0),\n",
       " (18, 30, 0),\n",
       " (18, 31, 0),\n",
       " (18, 32, 0),\n",
       " (18, 33, 0),\n",
       " (18, 34, 0),\n",
       " (18, 36, 0),\n",
       " (18, 37, 0),\n",
       " (18, 38, 0),\n",
       " (18, 39, 0),\n",
       " (19, 20, 0),\n",
       " (21, 22, 0),\n",
       " (21, 29, 0),\n",
       " (22, 26, 0),\n",
       " (22, 29, 0),\n",
       " (22, 30, 0),\n",
       " (22, 32, 0),\n",
       " (22, 33, 0),\n",
       " (22, 36, 0),\n",
       " (22, 38, 0),\n",
       " (22, 39, 0),\n",
       " (24, 27, 0),\n",
       " (24, 35, 0),\n",
       " (26, 29, 0),\n",
       " (26, 30, 0),\n",
       " (26, 31, 0),\n",
       " (26, 32, 0),\n",
       " (26, 33, 0),\n",
       " (26, 34, 0),\n",
       " (26, 36, 0),\n",
       " (26, 37, 0),\n",
       " (26, 38, 0),\n",
       " (26, 39, 0),\n",
       " (27, 35, 0),\n",
       " (28, 37, 0),\n",
       " (29, 30, 0),\n",
       " (29, 32, 0),\n",
       " (29, 33, 0),\n",
       " (29, 36, 0),\n",
       " (29, 38, 0),\n",
       " (29, 39, 0),\n",
       " (30, 31, 0),\n",
       " (30, 32, 0),\n",
       " (30, 33, 0),\n",
       " (30, 34, 0),\n",
       " (30, 36, 0),\n",
       " (30, 37, 0),\n",
       " (30, 38, 0),\n",
       " (30, 39, 0),\n",
       " (31, 32, 0),\n",
       " (31, 33, 0),\n",
       " (31, 34, 0),\n",
       " (31, 36, 0),\n",
       " (31, 37, 0),\n",
       " (31, 38, 0),\n",
       " (31, 39, 0),\n",
       " (32, 33, 0),\n",
       " (32, 34, 0),\n",
       " (32, 36, 0),\n",
       " (32, 37, 0),\n",
       " (32, 38, 0),\n",
       " (32, 39, 0),\n",
       " (33, 34, 0),\n",
       " (33, 36, 0),\n",
       " (33, 37, 0),\n",
       " (33, 38, 0),\n",
       " (33, 39, 0),\n",
       " (34, 36, 0),\n",
       " (34, 37, 0),\n",
       " (34, 38, 0),\n",
       " (34, 39, 0),\n",
       " (36, 37, 0),\n",
       " (36, 38, 0),\n",
       " (36, 39, 0),\n",
       " (37, 38, 0),\n",
       " (37, 39, 0),\n",
       " (38, 39, 0)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deps # (lf, lf, relationship_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FACTOR 0: STARTED BURN-IN...\n",
      "FACTOR 0: DONE WITH BURN-IN\n",
      "FACTOR 0: STARTED LEARNING\n",
      "FACTOR 0: EPOCH #0\n",
      "Current stepsize = 9.31966449208e-05\n",
      "Learning epoch took 0.000 sec.\n",
      "Weights:\n",
      "    weightId: 0\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 1\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 2\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 3\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 4\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 5\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 6\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 7\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 8\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 9\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 10\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 11\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 12\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 13\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 14\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 15\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 16\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 17\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 18\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 19\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 20\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 21\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 22\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 23\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 24\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 25\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 26\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 27\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 28\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 29\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 30\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 31\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 32\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 33\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 34\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 35\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 36\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 37\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 38\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 39\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 40\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 41\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 42\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 43\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 44\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 45\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 46\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 47\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 48\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 49\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 50\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 51\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 52\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 53\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 54\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 55\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 56\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 57\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 58\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 59\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 60\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 61\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 62\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 63\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 64\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 65\n",
      "        isFixed: False\n",
      "        weight:  2.0\n",
      "\n",
      "    weightId: 66\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 67\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 68\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 69\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 70\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 71\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 72\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 73\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 74\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 75\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 76\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 77\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 78\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 79\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 80\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 81\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 82\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 83\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 84\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 85\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 86\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 87\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 88\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 89\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 90\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 91\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 92\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 93\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 94\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 95\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 96\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 97\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 98\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 99\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 100\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 101\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 102\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 103\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 104\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 105\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 106\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 107\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 108\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 109\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 110\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 111\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 112\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 113\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 114\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 115\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 116\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 117\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 118\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 119\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 120\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 121\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 122\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 123\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 124\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 125\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 126\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 127\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 128\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 129\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 130\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 131\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 132\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 133\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 134\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 135\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 136\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 137\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 138\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 139\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 140\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 141\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 142\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 143\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 144\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 145\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 146\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 147\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 148\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 149\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 150\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 151\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 152\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 153\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 154\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 155\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 156\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 157\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 158\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 159\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 160\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 161\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 162\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 163\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 164\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 165\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 166\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 167\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 168\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 169\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 170\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 171\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 172\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n",
      "    weightId: 173\n",
      "        isFixed: False\n",
      "        weight:  1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FACTOR 0: EPOCH #1\n",
      "Current stepsize = 8.85368126747e-05\n",
      "Learning epoch took 0.258 sec.\n",
      "Weights:\n",
      "    weightId: 0\n",
      "        isFixed: False\n",
      "        weight:  1.80326188257\n",
      "\n",
      "    weightId: 1\n",
      "        isFixed: False\n",
      "        weight:  1.80438024231\n",
      "\n",
      "    weightId: 2\n",
      "        isFixed: False\n",
      "        weight:  1.81817334576\n",
      "\n",
      "    weightId: 3\n",
      "        isFixed: False\n",
      "        weight:  1.81621621622\n",
      "\n",
      "    weightId: 4\n",
      "        isFixed: False\n",
      "        weight:  1.81975768872\n",
      "\n",
      "    weightId: 5\n",
      "        isFixed: False\n",
      "        weight:  1.81835973905\n",
      "\n",
      "    weightId: 6\n",
      "        isFixed: False\n",
      "        weight:  1.81994408201\n",
      "\n",
      "    weightId: 7\n",
      "        isFixed: False\n",
      "        weight:  1.81901211556\n",
      "\n",
      "    weightId: 8\n",
      "        isFixed: False\n",
      "        weight:  1.82068965517\n",
      "\n",
      "    weightId: 9\n",
      "        isFixed: False\n",
      "        weight:  1.80838769804\n",
      "\n",
      "    weightId: 10\n",
      "        isFixed: False\n",
      "        weight:  1.81519105312\n",
      "\n",
      "    weightId: 11\n",
      "        isFixed: False\n",
      "        weight:  1.81798695247\n",
      "\n",
      "    weightId: 12\n",
      "        isFixed: False\n",
      "        weight:  1.82134203169\n",
      "\n",
      "    weightId: 13\n",
      "        isFixed: False\n",
      "        weight:  1.80438024231\n",
      "\n",
      "    weightId: 14\n",
      "        isFixed: False\n",
      "        weight:  1.80503261883\n",
      "\n",
      "    weightId: 15\n",
      "        isFixed: False\n",
      "        weight:  1.80121155638\n",
      "\n",
      "    weightId: 16\n",
      "        isFixed: False\n",
      "        weight:  1.81649580615\n",
      "\n",
      "    weightId: 17\n",
      "        isFixed: False\n",
      "        weight:  1.81360671016\n",
      "\n",
      "    weightId: 18\n",
      "        isFixed: False\n",
      "        weight:  1.81770736254\n",
      "\n",
      "    weightId: 19\n",
      "        isFixed: False\n",
      "        weight:  1.81025163094\n",
      "\n",
      "    weightId: 20\n",
      "        isFixed: False\n",
      "        weight:  1.81164958062\n",
      "\n",
      "    weightId: 21\n",
      "        isFixed: False\n",
      "        weight:  1.80754892824\n",
      "\n",
      "    weightId: 22\n",
      "        isFixed: False\n",
      "        weight:  1.80876048462\n",
      "\n",
      "    weightId: 23\n",
      "        isFixed: False\n",
      "        weight:  1.80316868593\n",
      "\n",
      "    weightId: 24\n",
      "        isFixed: False\n",
      "        weight:  1.80978564772\n",
      "\n",
      "    weightId: 25\n",
      "        isFixed: False\n",
      "        weight:  1.81127679404\n",
      "\n",
      "    weightId: 26\n",
      "        isFixed: False\n",
      "        weight:  1.81845293569\n",
      "\n",
      "    weightId: 27\n",
      "        isFixed: False\n",
      "        weight:  1.81351351351\n",
      "\n",
      "    weightId: 28\n",
      "        isFixed: False\n",
      "        weight:  1.81537744641\n",
      "\n",
      "    weightId: 29\n",
      "        isFixed: False\n",
      "        weight:  1.80736253495\n",
      "\n",
      "    weightId: 30\n",
      "        isFixed: False\n",
      "        weight:  1.82423112768\n",
      "\n",
      "    weightId: 31\n",
      "        isFixed: False\n",
      "        weight:  1.80950605778\n",
      "\n",
      "    weightId: 32\n",
      "        isFixed: False\n",
      "        weight:  1.76551724138\n",
      "\n",
      "    weightId: 33\n",
      "        isFixed: False\n",
      "        weight:  1.84193849021\n",
      "\n",
      "    weightId: 34\n",
      "        isFixed: False\n",
      "        weight:  1.81267474371\n",
      "\n",
      "    weightId: 35\n",
      "        isFixed: False\n",
      "        weight:  1.80922646785\n",
      "\n",
      "    weightId: 36\n",
      "        isFixed: False\n",
      "        weight:  1.81761416589\n",
      "\n",
      "    weightId: 37\n",
      "        isFixed: False\n",
      "        weight:  1.86253494874\n",
      "\n",
      "    weightId: 38\n",
      "        isFixed: False\n",
      "        weight:  1.83830382106\n",
      "\n",
      "    weightId: 39\n",
      "        isFixed: False\n",
      "        weight:  1.80214352283\n",
      "\n",
      "    weightId: 40\n",
      "        isFixed: False\n",
      "        weight:  1.81640260951\n",
      "\n",
      "    weightId: 41\n",
      "        isFixed: False\n",
      "        weight:  1.82600186393\n",
      "\n",
      "    weightId: 42\n",
      "        isFixed: False\n",
      "        weight:  1.82339235788\n",
      "\n",
      "    weightId: 43\n",
      "        isFixed: False\n",
      "        weight:  1.82050326188\n",
      "\n",
      "    weightId: 44\n",
      "        isFixed: False\n",
      "        weight:  1.80661696179\n",
      "\n",
      "    weightId: 45\n",
      "        isFixed: False\n",
      "        weight:  1.8201304753\n",
      "\n",
      "    weightId: 46\n",
      "        isFixed: False\n",
      "        weight:  1.8211556384\n",
      "\n",
      "    weightId: 47\n",
      "        isFixed: False\n",
      "        weight:  1.81230195713\n",
      "\n",
      "    weightId: 48\n",
      "        isFixed: False\n",
      "        weight:  1.81202236719\n",
      "\n",
      "    weightId: 49\n",
      "        isFixed: False\n",
      "        weight:  1.80698974837\n",
      "\n",
      "    weightId: 50\n",
      "        isFixed: False\n",
      "        weight:  1.80689655172\n",
      "\n",
      "    weightId: 51\n",
      "        isFixed: False\n",
      "        weight:  1.81966449208\n",
      "\n",
      "    weightId: 52\n",
      "        isFixed: False\n",
      "        weight:  1.81808014911\n",
      "\n",
      "    weightId: 53\n",
      "        isFixed: False\n",
      "        weight:  1.80335507922\n",
      "\n",
      "    weightId: 54\n",
      "        isFixed: False\n",
      "        weight:  1.80223671948\n",
      "\n",
      "    weightId: 55\n",
      "        isFixed: False\n",
      "        weight:  1.80205032619\n",
      "\n",
      "    weightId: 56\n",
      "        isFixed: False\n",
      "        weight:  1.81668219944\n",
      "\n",
      "    weightId: 57\n",
      "        isFixed: False\n",
      "        weight:  1.82041006524\n",
      "\n",
      "    weightId: 58\n",
      "        isFixed: False\n",
      "        weight:  1.81966449208\n",
      "\n",
      "    weightId: 59\n",
      "        isFixed: False\n",
      "        weight:  1.81686859273\n",
      "\n",
      "    weightId: 60\n",
      "        isFixed: False\n",
      "        weight:  1.8192917055\n",
      "\n",
      "    weightId: 61\n",
      "        isFixed: False\n",
      "        weight:  1.81780055918\n",
      "\n",
      "    weightId: 62\n",
      "        isFixed: False\n",
      "        weight:  1.80661696179\n",
      "\n",
      "    weightId: 63\n",
      "        isFixed: False\n",
      "        weight:  1.80587138863\n",
      "\n",
      "    weightId: 64\n",
      "        isFixed: False\n",
      "        weight:  1.84939422181\n",
      "\n",
      "    weightId: 65\n",
      "        isFixed: False\n",
      "        weight:  1.80764212488\n",
      "\n",
      "    weightId: 66\n",
      "        isFixed: False\n",
      "        weight:  0.902795899348\n",
      "\n",
      "    weightId: 67\n",
      "        isFixed: False\n",
      "        weight:  0.902423112768\n",
      "\n",
      "    weightId: 68\n",
      "        isFixed: False\n",
      "        weight:  0.90605778192\n",
      "\n",
      "    weightId: 69\n",
      "        isFixed: False\n",
      "        weight:  0.906896551724\n",
      "\n",
      "    weightId: 70\n",
      "        isFixed: False\n",
      "        weight:  0.907082945014\n",
      "\n",
      "    weightId: 71\n",
      "        isFixed: False\n",
      "        weight:  0.906989748369\n",
      "\n",
      "    weightId: 72\n",
      "        isFixed: False\n",
      "        weight:  0.905964585275\n",
      "\n",
      "    weightId: 73\n",
      "        isFixed: False\n",
      "        weight:  0.905778191985\n",
      "\n",
      "    weightId: 74\n",
      "        isFixed: False\n",
      "        weight:  0.90549860205\n",
      "\n",
      "    weightId: 75\n",
      "        isFixed: False\n",
      "        weight:  0.903261882572\n",
      "\n",
      "    weightId: 76\n",
      "        isFixed: False\n",
      "        weight:  0.904566635601\n",
      "\n",
      "    weightId: 77\n",
      "        isFixed: False\n",
      "        weight:  0.906616961789\n",
      "\n",
      "    weightId: 78\n",
      "        isFixed: False\n",
      "        weight:  0.913979496738\n",
      "\n",
      "    weightId: 79\n",
      "        isFixed: False\n",
      "        weight:  0.922739981361\n",
      "\n",
      "    weightId: 80\n",
      "        isFixed: False\n",
      "        weight:  0.911649580615\n",
      "\n",
      "    weightId: 81\n",
      "        isFixed: False\n",
      "        weight:  0.911276794035\n",
      "\n",
      "    weightId: 82\n",
      "        isFixed: False\n",
      "        weight:  0.904566635601\n",
      "\n",
      "    weightId: 83\n",
      "        isFixed: False\n",
      "        weight:  0.92348555452\n",
      "\n",
      "    weightId: 84\n",
      "        isFixed: False\n",
      "        weight:  0.90531220876\n",
      "\n",
      "    weightId: 85\n",
      "        isFixed: False\n",
      "        weight:  0.907362534949\n",
      "\n",
      "    weightId: 86\n",
      "        isFixed: False\n",
      "        weight:  0.904939422181\n",
      "\n",
      "    weightId: 87\n",
      "        isFixed: False\n",
      "        weight:  0.903168685927\n",
      "\n",
      "    weightId: 88\n",
      "        isFixed: False\n",
      "        weight:  0.904100652376\n",
      "\n",
      "    weightId: 89\n",
      "        isFixed: False\n",
      "        weight:  0.904939422181\n",
      "\n",
      "    weightId: 90\n",
      "        isFixed: False\n",
      "        weight:  0.90587138863\n",
      "\n",
      "    weightId: 91\n",
      "        isFixed: False\n",
      "        weight:  0.91155638397\n",
      "\n",
      "    weightId: 92\n",
      "        isFixed: False\n",
      "        weight:  0.905219012116\n",
      "\n",
      "    weightId: 93\n",
      "        isFixed: False\n",
      "        weight:  0.907921714818\n",
      "\n",
      "    weightId: 94\n",
      "        isFixed: False\n",
      "        weight:  0.906803355079\n",
      "\n",
      "    weightId: 95\n",
      "        isFixed: False\n",
      "        weight:  0.901957129543\n",
      "\n",
      "    weightId: 96\n",
      "        isFixed: False\n",
      "        weight:  0.919291705499\n",
      "\n",
      "    weightId: 97\n",
      "        isFixed: False\n",
      "        weight:  0.907828518173\n",
      "\n",
      "    weightId: 98\n",
      "        isFixed: False\n",
      "        weight:  0.984342963653\n",
      "\n",
      "    weightId: 99\n",
      "        isFixed: False\n",
      "        weight:  0.933084808947\n",
      "\n",
      "    weightId: 100\n",
      "        isFixed: False\n",
      "        weight:  0.91211556384\n",
      "\n",
      "    weightId: 101\n",
      "        isFixed: False\n",
      "        weight:  0.904566635601\n",
      "\n",
      "    weightId: 102\n",
      "        isFixed: False\n",
      "        weight:  0.90568499534\n",
      "\n",
      "    weightId: 103\n",
      "        isFixed: False\n",
      "        weight:  0.985461323392\n",
      "\n",
      "    weightId: 104\n",
      "        isFixed: False\n",
      "        weight:  0.922180801491\n",
      "\n",
      "    weightId: 105\n",
      "        isFixed: False\n",
      "        weight:  0.908946877912\n",
      "\n",
      "    weightId: 106\n",
      "        isFixed: False\n",
      "        weight:  0.904473438956\n",
      "\n",
      "    weightId: 107\n",
      "        isFixed: False\n",
      "        weight:  0.918732525629\n",
      "\n",
      "    weightId: 108\n",
      "        isFixed: False\n",
      "        weight:  0.908014911463\n",
      "\n",
      "    weightId: 109\n",
      "        isFixed: False\n",
      "        weight:  0.915470643057\n",
      "\n",
      "    weightId: 110\n",
      "        isFixed: False\n",
      "        weight:  0.902423112768\n",
      "\n",
      "    weightId: 111\n",
      "        isFixed: False\n",
      "        weight:  0.905125815471\n",
      "\n",
      "    weightId: 112\n",
      "        isFixed: False\n",
      "        weight:  0.906616961789\n",
      "\n",
      "    weightId: 113\n",
      "        isFixed: False\n",
      "        weight:  0.907828518173\n",
      "\n",
      "    weightId: 114\n",
      "        isFixed: False\n",
      "        weight:  0.906803355079\n",
      "\n",
      "    weightId: 115\n",
      "        isFixed: False\n",
      "        weight:  0.902609506058\n",
      "\n",
      "    weightId: 116\n",
      "        isFixed: False\n",
      "        weight:  0.902889095993\n",
      "\n",
      "    weightId: 117\n",
      "        isFixed: False\n",
      "        weight:  0.906337371855\n",
      "\n",
      "    weightId: 118\n",
      "        isFixed: False\n",
      "        weight:  0.905591798695\n",
      "\n",
      "    weightId: 119\n",
      "        isFixed: False\n",
      "        weight:  0.909226467847\n",
      "\n",
      "    weightId: 120\n",
      "        isFixed: False\n",
      "        weight:  0.913793103448\n",
      "\n",
      "    weightId: 121\n",
      "        isFixed: False\n",
      "        weight:  0.913979496738\n",
      "\n",
      "    weightId: 122\n",
      "        isFixed: False\n",
      "        weight:  0.911276794035\n",
      "\n",
      "    weightId: 123\n",
      "        isFixed: False\n",
      "        weight:  0.911463187325\n",
      "\n",
      "    weightId: 124\n",
      "        isFixed: False\n",
      "        weight:  0.905778191985\n",
      "\n",
      "    weightId: 125\n",
      "        isFixed: False\n",
      "        weight:  0.905778191985\n",
      "\n",
      "    weightId: 126\n",
      "        isFixed: False\n",
      "        weight:  0.90549860205\n",
      "\n",
      "    weightId: 127\n",
      "        isFixed: False\n",
      "        weight:  0.90624417521\n",
      "\n",
      "    weightId: 128\n",
      "        isFixed: False\n",
      "        weight:  0.904007455732\n",
      "\n",
      "    weightId: 129\n",
      "        isFixed: False\n",
      "        weight:  0.902609506058\n",
      "\n",
      "    weightId: 130\n",
      "        isFixed: False\n",
      "        weight:  0.964305684995\n",
      "\n",
      "    weightId: 131\n",
      "        isFixed: False\n",
      "        weight:  0.904100652376\n",
      "\n",
      "    weightId: 132\n",
      "        isFixed: False\n",
      "        weight:  1.00391425909\n",
      "\n",
      "    weightId: 133\n",
      "        isFixed: False\n",
      "        weight:  1.00382106244\n",
      "\n",
      "    weightId: 134\n",
      "        isFixed: False\n",
      "        weight:  0.958434296365\n",
      "\n",
      "    weightId: 135\n",
      "        isFixed: False\n",
      "        weight:  0.987977632805\n",
      "\n",
      "    weightId: 136\n",
      "        isFixed: False\n",
      "        weight:  1.00195712954\n",
      "\n",
      "    weightId: 137\n",
      "        isFixed: False\n",
      "        weight:  0.937651444548\n",
      "\n",
      "    weightId: 138\n",
      "        isFixed: False\n",
      "        weight:  0.980708294501\n",
      "\n",
      "    weightId: 139\n",
      "        isFixed: False\n",
      "        weight:  0.98182665424\n",
      "\n",
      "    weightId: 140\n",
      "        isFixed: False\n",
      "        weight:  0.824603914259\n",
      "\n",
      "    weightId: 141\n",
      "        isFixed: False\n",
      "        weight:  0.966169617894\n",
      "\n",
      "    weightId: 142\n",
      "        isFixed: False\n",
      "        weight:  0.97064305685\n",
      "\n",
      "    weightId: 143\n",
      "        isFixed: False\n",
      "        weight:  0.972227399814\n",
      "\n",
      "    weightId: 144\n",
      "        isFixed: False\n",
      "        weight:  0.964119291705\n",
      "\n",
      "    weightId: 145\n",
      "        isFixed: False\n",
      "        weight:  0.980242311277\n",
      "\n",
      "    weightId: 146\n",
      "        isFixed: False\n",
      "        weight:  0.973438956198\n",
      "\n",
      "    weightId: 147\n",
      "        isFixed: False\n",
      "        weight:  0.978098788444\n",
      "\n",
      "    weightId: 148\n",
      "        isFixed: False\n",
      "        weight:  0.957781919851\n",
      "\n",
      "    weightId: 149\n",
      "        isFixed: False\n",
      "        weight:  0.968685927307\n",
      "\n",
      "    weightId: 150\n",
      "        isFixed: False\n",
      "        weight:  0.958620689655\n",
      "\n",
      "    weightId: 151\n",
      "        isFixed: False\n",
      "        weight:  1.00363466915\n",
      "\n",
      "    weightId: 152\n",
      "        isFixed: False\n",
      "        weight:  1.00549860205\n",
      "\n",
      "    weightId: 153\n",
      "        isFixed: False\n",
      "        weight:  1.00503261883\n",
      "\n",
      "    weightId: 154\n",
      "        isFixed: False\n",
      "        weight:  0.968033550792\n",
      "\n",
      "    weightId: 155\n",
      "        isFixed: False\n",
      "        weight:  0.973066169618\n",
      "\n",
      "    weightId: 156\n",
      "        isFixed: False\n",
      "        weight:  0.990773532153\n",
      "\n",
      "    weightId: 157\n",
      "        isFixed: False\n",
      "        weight:  1.00475302889\n",
      "\n",
      "    weightId: 158\n",
      "        isFixed: False\n",
      "        weight:  1.00195712954\n",
      "\n",
      "    weightId: 159\n",
      "        isFixed: False\n",
      "        weight:  0.972693383038\n",
      "\n",
      "    weightId: 160\n",
      "        isFixed: False\n",
      "        weight:  0.984715750233\n",
      "\n",
      "    weightId: 161\n",
      "        isFixed: False\n",
      "        weight:  0.818732525629\n",
      "\n",
      "    weightId: 162\n",
      "        isFixed: False\n",
      "        weight:  0.805405405405\n",
      "\n",
      "    weightId: 163\n",
      "        isFixed: False\n",
      "        weight:  0.815750232992\n",
      "\n",
      "    weightId: 164\n",
      "        isFixed: False\n",
      "        weight:  0.816309412861\n",
      "\n",
      "    weightId: 165\n",
      "        isFixed: False\n",
      "        weight:  0.932432432432\n",
      "\n",
      "    weightId: 166\n",
      "        isFixed: False\n",
      "        weight:  1.00577819199\n",
      "\n",
      "    weightId: 167\n",
      "        isFixed: False\n",
      "        weight:  0.925908667288\n",
      "\n",
      "    weightId: 168\n",
      "        isFixed: False\n",
      "        weight:  0.984715750233\n",
      "\n",
      "    weightId: 169\n",
      "        isFixed: False\n",
      "        weight:  0.973252562908\n",
      "\n",
      "    weightId: 170\n",
      "        isFixed: False\n",
      "        weight:  0.973438956198\n",
      "\n",
      "    weightId: 171\n",
      "        isFixed: False\n",
      "        weight:  0.990680335508\n",
      "\n",
      "    weightId: 172\n",
      "        isFixed: False\n",
      "        weight:  0.989748369059\n",
      "\n",
      "    weightId: 173\n",
      "        isFixed: False\n",
      "        weight:  0.977539608574\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FACTOR 0: DONE WITH LEARNING\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "gen_model = GenerativeModel(lf_propensity=True)\n",
    "gen_model.train(\n",
    "    L_train, deps=deps, epochs=2, decay=0.95, step_size=0.1/L_train.shape[0],\n",
    "    init_acc=2.0, reg_param=0.0,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the generative model to the training candidates to get the noise-aware training label set. We'll refer to these as the training marginals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABBgAAAFpCAYAAAA2p5uqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhgkMAAAAwLD/C/aNj5Hhw+bPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f828159f4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.83459839,  0.83482597,  0.83908808,  0.83812818,  0.83952863,\n",
       "        0.83905347,  0.83901634,  0.83933267,  0.83946334,  0.83597357,\n",
       "        0.83816927,  0.83887153,  0.83952738,  0.83455721,  0.83450059,\n",
       "        0.83370231,  0.83872976,  0.83721956,  0.83897731,  0.83654401,\n",
       "        0.83688016,  0.83553029,  0.83608536,  0.83445103,  0.83656503,\n",
       "        0.83663574,  0.83917363,  0.837436  ,  0.83774977,  0.83585725,\n",
       "        0.83998763,  0.83592053,  0.82296425,  0.8445395 ,  0.8368388 ,\n",
       "        0.83630684,  0.83873732,  0.85049579,  0.84420148,  0.83411344,\n",
       "        0.83857338,  0.84093735,  0.84023175,  0.83916356,  0.83570631,\n",
       "        0.8391491 ,  0.8392277 ,  0.83670324,  0.83690687,  0.83579394,\n",
       "        0.83585405,  0.83930125,  0.83908745,  0.834489  ,  0.83389346,\n",
       "        0.83429648,  0.83819139,  0.83930628,  0.83956379,  0.83869635,\n",
       "        0.83929874,  0.83873858,  0.83551172,  0.83509246,  0.84656532,\n",
       "        0.83553093])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model.weights.lf_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1073 training marginals\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import save_marginals\n",
    "save_marginals(session, L_train, train_marginals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_marginals\n",
    "train_marginals = load_marginals(session, split=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Model to Iterate on Labeling Functions\n",
    "Now that we have learned the generative model, we can stop here and use this to potentially debug and/or improve our labeling function set. First, we apply the LFs to our development set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    }
   ],
   "source": [
    "L_dev = labeler.apply_existing(split=1, parallelism=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.508\n",
      "Neg. class accuracy: 0.696\n",
      "Precision            0.217\n",
      "Recall               0.508\n",
      "F1                   0.304\n",
      "----------------------------------------\n",
      "TP: 96 | FP: 347 | TN: 796 | FN: 93\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = gen_model.score(session, L_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{GenePhenoPair(Span(\"etr2-3\", sentence=447956, chars=[13,18], words=[4,4]), Span(\"higher number of branched root hairs than the wild type\", sentence=447956, chars=[26,80], words=[7,16])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=450191, chars=[59,62], words=[10,10]), Span(\"more than two times the number of mature conidiophores\", sentence=450191, chars=[107,160], words=[20,28])),\n",
       " GenePhenoPair(Span(\"atl9-3\", sentence=450195, chars=[23,28], words=[5,5]), Span(\"in a more pronounced susceptibility phenotype than observed in wild\", sentence=450195, chars=[53,119], words=[9,18])),\n",
       " GenePhenoPair(Span(\"atl9-1, atl9-2\", sentence=450195, chars=[4,17], words=[1,3]), Span(\"more pronounced susceptibility phenotype than observed in wild type plants\", sentence=450195, chars=[58,131], words=[11,20])),\n",
       " GenePhenoPair(Span(\"ALG10\", sentence=388187, chars=[51,55], words=[12,12]), Span(\"reduced number of faster-migrating CPY-forms\", sentence=388187, chars=[85,128], words=[18,22])),\n",
       " GenePhenoPair(Span(\"etr2-2\", sentence=447695, chars=[4,9], words=[1,1]), Span(\"a higher number of two-branched trichomes (\", sentence=447695, chars=[22,64], words=[4,10])),\n",
       " GenePhenoPair(Span(\"ashh2-1\", sentence=422597, chars=[0,6], words=[0,0]), Span(\"shorter than wt stamens (bottom middle).\", sentence=422597, chars=[26,65], words=[4,12])),\n",
       " GenePhenoPair(Span(\"atl9-1, atl9-2\", sentence=450195, chars=[4,17], words=[1,3]), Span(\"all resulted in a more pronounced susceptibility phenotype than observed\", sentence=450195, chars=[40,111], words=[7,16])),\n",
       " GenePhenoPair(Span(\"alg10-1\", sentence=388672, chars=[93,99], words=[16,16]), Span(\"smaller than the wild type and displayed alterations in leaf\", sentence=388672, chars=[113,172], words=[19,28])),\n",
       " GenePhenoPair(Span(\"alg10-1\", sentence=388672, chars=[4,10], words=[1,1]), Span(\"indistinguishable from the wild type\", sentence=388672, chars=[27,62], words=[4,8])),\n",
       " GenePhenoPair(Span(\"tir1-1\", sentence=446983, chars=[81,86], words=[13,13]), Span(\"No significant salt-mediated reduction in average LR length\", sentence=446983, chars=[0,58], words=[0,7])),\n",
       " GenePhenoPair(Span(\"atl9-3\", sentence=450195, chars=[23,28], words=[5,5]), Span(\"resulted in a more pronounced susceptibility phenotype than observed in\", sentence=450195, chars=[44,114], words=[8,17])),\n",
       " GenePhenoPair(Span(\"ATL9\", sentence=450205, chars=[62,65], words=[7,7]), Span(\"more resistant to G. cichoracearum and showed a 2-fold decrease\", sentence=450205, chars=[86,148], words=[10,19])),\n",
       " GenePhenoPair(Span(\"atl9-3\", sentence=450195, chars=[23,28], words=[5,5]), Span(\"pronounced susceptibility phenotype than observed in wild type plants.\", sentence=450195, chars=[63,132], words=[12,21])),\n",
       " GenePhenoPair(Span(\"atl9-1, atl9-2\", sentence=450195, chars=[4,17], words=[1,3]), Span(\"a more pronounced susceptibility phenotype than observed in wild type\", sentence=450195, chars=[56,124], words=[10,19])),\n",
       " GenePhenoPair(Span(\"atl9-3\", sentence=450195, chars=[23,28], words=[5,5]), Span(\"more pronounced susceptibility phenotype than observed in wild type plants\", sentence=450195, chars=[58,131], words=[11,20])),\n",
       " GenePhenoPair(Span(\"atl9-3\", sentence=450195, chars=[23,28], words=[5,5]), Span(\"mutations all resulted in a more pronounced susceptibility phenotype than\", sentence=450195, chars=[30,102], words=[6,15])),\n",
       " GenePhenoPair(Span(\"sti\", sentence=447928, chars=[140,142], words=[21,21]), Span(\"blunt-ended branch\", sentence=447928, chars=[46,63], words=[7,8])),\n",
       " GenePhenoPair(Span(\"R1\", sentence=428215, chars=[46,47], words=[8,8]), Span(\"late flowering\", sentence=428215, chars=[152,165], words=[28,29])),\n",
       " GenePhenoPair(Span(\"aba3-1\", sentence=447068, chars=[20,25], words=[3,3]), Span(\"no significant difference in first order LR number between unstressed\", sentence=447068, chars=[82,150], words=[14,23])),\n",
       " GenePhenoPair(Span(\"S1P-9,\", sentence=449925, chars=[107,112], words=[19,20]), Span(\"responsible for the salt-sensitive phenotype (Fig.\", sentence=449925, chars=[139,188], words=[25,32])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=450835, chars=[130,133], words=[23,23]), Span(\"Hierarchical cluster of ratio values (relative to the water\", sentence=450835, chars=[3,61], words=[2,11])),\n",
       " GenePhenoPair(Span(\"FKF1\", sentence=428218, chars=[337,340], words=[57,57]), Span(\"late flowering\", sentence=428218, chars=[365,378], words=[62,63])),\n",
       " GenePhenoPair(Span(\"MET1\", sentence=414945, chars=[38,41], words=[4,4]), Span(\"HDA6-mediated gene silencing requires\", sentence=414945, chars=[0,36], words=[0,3])),\n",
       " GenePhenoPair(Span(\"35S:MAP4-GFP\", sentence=447868, chars=[3,14], words=[1,3]), Span(\"artefacts such as bulging hypocotyl cells, thickened trichomes or\", sentence=447868, chars=[39,103], words=[9,18])),\n",
       " GenePhenoPair(Span(\"FKF1\", sentence=428218, chars=[337,340], words=[57,57]), Span(\"late flowering\", sentence=428218, chars=[156,169], words=[24,25])),\n",
       " GenePhenoPair(Span(\"aba2-1\", sentence=447060, chars=[4,9], words=[1,1]), Span(\"greater number of first order LRs than the wild type\", sentence=447060, chars=[29,80], words=[5,14])),\n",
       " GenePhenoPair(Span(\"35S:MAP4-GFP\", sentence=447868, chars=[3,14], words=[1,3]), Span(\"such as bulging hypocotyl cells, thickened trichomes or induced\", sentence=447868, chars=[49,111], words=[10,19])),\n",
       " GenePhenoPair(Span(\"35S:MAP4-GFP\", sentence=447868, chars=[3,14], words=[1,3]), Span(\"lead to artefacts such as bulging hypocotyl cells, thickened\", sentence=447868, chars=[31,90], words=[7,16])),\n",
       " GenePhenoPair(Span(\"fasciata1 (fas1),\", sentence=448016, chars=[27,43], words=[5,9]), Span(\"unbranched trichomes\", sentence=448016, chars=[173,192], words=[33,34])),\n",
       " GenePhenoPair(Span(\"AtrbohD/F\", sentence=450311, chars=[4,12], words=[1,1]), Span(\"susceptible to powdery mildew\", sentence=450311, chars=[41,69], words=[7,10])),\n",
       " GenePhenoPair(Span(\"R1\", sentence=428215, chars=[46,47], words=[8,8]), Span(\"and a late-flowering phenotype\", sentence=428215, chars=[174,203], words=[35,38])),\n",
       " GenePhenoPair(Span(\"sti\", sentence=447928, chars=[140,142], words=[21,21]), Span(\"The two-branched trichomes in these lines\", sentence=447928, chars=[0,40], words=[0,5])),\n",
       " GenePhenoPair(Span(\"deltaalg10\", sentence=388262, chars=[125,134], words=[18,18]), Span(\"smaller amounts of Glc1Man9GlcNAc2 and Man9GlcNAc2 (data\", sentence=388262, chars=[211,266], words=[31,38])),\n",
       " GenePhenoPair(Span(\"ashh2\", sentence=423447, chars=[42,46], words=[8,8]), Span(\"reduced number of pollen grains\", sentence=423447, chars=[7,37], words=[2,6])),\n",
       " GenePhenoPair(Span(\"s1p-3,\", sentence=449888, chars=[11,16], words=[2,3]), Span(\"considered a knockout mutation as\", sentence=449888, chars=[62,94], words=[14,18])),\n",
       " GenePhenoPair(Span(\"etr2-3\", sentence=447896, chars=[18,23], words=[4,4]), Span(\"showed evidence of depolymerization\", sentence=447896, chars=[186,220], words=[27,30])),\n",
       " GenePhenoPair(Span(\"HY1\", sentence=428218, chars=[277,279], words=[44,44]), Span(\"long hypocotyl\", sentence=428218, chars=[97,110], words=[11,12])),\n",
       " GenePhenoPair(Span(\"glabra3 (gl3),\", sentence=447986, chars=[18,31], words=[3,7]), Span(\"puddle-like, unbranched trichomes\", sentence=447986, chars=[99,131], words=[21,24])),\n",
       " GenePhenoPair(Span(\"glabra3 (gl3),\", sentence=447986, chars=[18,31], words=[3,7]), Span(\"two-branched trichomes (Fig.\", sentence=447986, chars=[43,70], words=[10,13])),\n",
       " GenePhenoPair(Span(\"s1p-3\", sentence=449903, chars=[11,15], words=[2,2]), Span(\"sensitive to other monovalent salts, such as KCl and\", sentence=449903, chars=[26,77], words=[5,14])),\n",
       " GenePhenoPair(Span(\"sid2-1\", sentence=450307, chars=[40,45], words=[6,6]), Span(\"comparable numbers of conidiophores per colony and\", sentence=450307, chars=[61,110], words=[9,15])),\n",
       " GenePhenoPair(Span(\"sid2-1\", sentence=450307, chars=[40,45], words=[6,6]), Span(\"more susceptible than atl9, the 35S:ATL9 line\", sentence=450307, chars=[131,175], words=[18,27])),\n",
       " GenePhenoPair(Span(\"AtrbohF\", sentence=450307, chars=[9,15], words=[2,2]), Span(\"more susceptible than atl9, the 35S:ATL9 line\", sentence=450307, chars=[131,175], words=[18,27])),\n",
       " GenePhenoPair(Span(\"AtrbohF\", sentence=450307, chars=[9,15], words=[2,2]), Span(\"comparable numbers of conidiophores per colony and\", sentence=450307, chars=[61,110], words=[9,15])),\n",
       " GenePhenoPair(Span(\"AtrbohD\", sentence=450307, chars=[0,6], words=[0,0]), Span(\"more susceptible than atl9, the 35S:ATL9 line\", sentence=450307, chars=[131,175], words=[18,27])),\n",
       " GenePhenoPair(Span(\"AtrbohD\", sentence=450307, chars=[0,6], words=[0,0]), Span(\"comparable numbers of conidiophores per colony and\", sentence=450307, chars=[61,110], words=[9,15])),\n",
       " GenePhenoPair(Span(\"alg10-1\", sentence=388755, chars=[4,10], words=[1,1]), Span(\"more sensitive towards the treatment with tunicamycin than wild-type seedlings\", sentence=388755, chars=[28,105], words=[5,14])),\n",
       " GenePhenoPair(Span(\"s1p-3\", sentence=449905, chars=[6,10], words=[2,2]), Span(\"sensitive to salt-induced osmotic stress.\", sentence=449905, chars=[15,55], words=[4,9])),\n",
       " GenePhenoPair(Span(\"ein2-1\", sentence=447072, chars=[4,9], words=[1,1]), Span(\"with greater numbers of first order LRs in unstressed and\", sentence=447072, chars=[69,125], words=[11,20])),\n",
       " GenePhenoPair(Span(\"ein2-1\", sentence=447072, chars=[4,9], words=[1,1]), Span(\"mutant with greater numbers of first order LRs in unstressed\", sentence=447072, chars=[62,121], words=[10,19])),\n",
       " GenePhenoPair(Span(\"etr2-3\", sentence=447655, chars=[58,63], words=[10,10]), Span(\"unbranched trichomes\", sentence=447655, chars=[91,110], words=[20,21])),\n",
       " GenePhenoPair(Span(\"ein2-1\", sentence=447072, chars=[4,9], words=[1,1]), Span(\"greater numbers of first order LRs in unstressed and stressed\", sentence=447072, chars=[74,134], words=[12,21])),\n",
       " GenePhenoPair(Span(\"alg10-1\", sentence=388664, chars=[10,16], words=[2,2]), Span(\"more sensitive to salt stress\", sentence=388664, chars=[56,84], words=[9,13])),\n",
       " GenePhenoPair(Span(\"ATL9p:ATL9:GFP\", sentence=450770, chars=[97,110], words=[13,17]), Span(\"localization changed after elicitor treatment, transgenic plants expressing\", sentence=450770, chars=[21,95], words=[4,12])),\n",
       " GenePhenoPair(Span(\"ATL9p:ATL9:GFP\", sentence=450733, chars=[45,58], words=[9,13]), Span(\"Confocal image of a leaf trichome\", sentence=450733, chars=[3,35], words=[2,7])),\n",
       " GenePhenoPair(Span(\"etr2-1\", sentence=447651, chars=[22,27], words=[5,5]), Span(\"four-branched trichomes (\", sentence=447651, chars=[159,183], words=[37,39])),\n",
       " GenePhenoPair(Span(\"ALG3\", sentence=388668, chars=[12,15], words=[2,2]), Span(\"mild and severe underglycosylation defects, respectively, but\", sentence=388668, chars=[45,105], words=[7,15])),\n",
       " GenePhenoPair(Span(\"etr2-1\", sentence=447651, chars=[22,27], words=[5,5]), Span(\"two-branched trichomes,\", sentence=447651, chars=[98,120], words=[26,28])),\n",
       " GenePhenoPair(Span(\"At2g35000\", sentence=449955, chars=[66,74], words=[12,12]), Span(\"more susceptible to fungal infection than wild-type plants [\", sentence=449955, chars=[81,140], words=[14,22])),\n",
       " GenePhenoPair(Span(\"aba2-1\", sentence=447072, chars=[55,60], words=[9,9]), Span(\"exhibited a similar phenotype\", sentence=447072, chars=[18,46], words=[3,6])),\n",
       " GenePhenoPair(Span(\"AtbZIP17\", sentence=450192, chars=[153,160], words=[27,27]), Span(\"and a 10-kDa protein product consistent with cleavage at the\", sentence=450192, chars=[70,129], words=[13,22])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=450481, chars=[6,9], words=[1,1]), Span(\"more susceptible to G. cichoracearum (Figure 3A\", sentence=450481, chars=[23,69], words=[4,11])),\n",
       " GenePhenoPair(Span(\"AtbZIP17\", sentence=450192, chars=[153,160], words=[27,27]), Span(\"a 10-kDa protein product consistent with cleavage at the canonical\", sentence=450192, chars=[74,139], words=[14,23])),\n",
       " GenePhenoPair(Span(\"GnTI\", sentence=388625, chars=[98,101], words=[14,14]), Span(\"interferes with correct folding of GnTI and subsequent enzyme activity\", sentence=388625, chars=[163,232], words=[24,33])),\n",
       " GenePhenoPair(Span(\"ein2-1\", sentence=447072, chars=[4,9], words=[1,1]), Span(\"exhibited a similar phenotype\", sentence=447072, chars=[18,46], words=[3,6])),\n",
       " GenePhenoPair(Span(\"AtrbohC\", sentence=450383, chars=[0,6], words=[0,0]), Span(\"more susceptible to the powdery mildew pathogen G. cichoracearum\", sentence=450383, chars=[24,87], words=[4,12])),\n",
       " GenePhenoPair(Span(\"ein2-1\", sentence=447132, chars=[118,123], words=[23,23]), Span(\"greater LR proliferation\", sentence=447132, chars=[143,166], words=[26,28])),\n",
       " GenePhenoPair(Span(\"cwinv4\", sentence=459501, chars=[5,10], words=[1,1]), Span(\"higher than normal levels of starch within the receptacle\", sentence=459501, chars=[37,93], words=[5,13])),\n",
       " GenePhenoPair(Span(\"atl9-3\", sentence=450195, chars=[23,28], words=[5,5]), Span(\"all resulted in a more pronounced susceptibility phenotype than observed\", sentence=450195, chars=[40,111], words=[7,16])),\n",
       " GenePhenoPair(Span(\"etr2-3\", sentence=447695, chars=[74,79], words=[14,14]), Span(\"unbranched trichomes\", sentence=447695, chars=[90,109], words=[17,18])),\n",
       " GenePhenoPair(Span(\"cgl1\", sentence=388625, chars=[4,7], words=[1,1]), Span(\"interferes with correct folding of GnTI and subsequent enzyme activity\", sentence=388625, chars=[163,232], words=[24,33])),\n",
       " GenePhenoPair(Span(\"s1p-3\", sentence=449894, chars=[27,31], words=[6,6]), Span(\"more sensitive to salt stress\", sentence=449894, chars=[37,65], words=[8,12])),\n",
       " GenePhenoPair(Span(\"atl9-1, atl9-2\", sentence=450195, chars=[4,17], words=[1,3]), Span(\"pronounced susceptibility phenotype than observed in wild type plants.\", sentence=450195, chars=[63,132], words=[12,21])),\n",
       " GenePhenoPair(Span(\"atl9-1, atl9-2\", sentence=450195, chars=[4,17], words=[1,3]), Span(\"mutations all resulted in a more pronounced susceptibility phenotype than\", sentence=450195, chars=[30,102], words=[6,15])),\n",
       " GenePhenoPair(Span(\"atl9-1, atl9-2\", sentence=450195, chars=[4,17], words=[1,3]), Span(\"resulted in a more pronounced susceptibility phenotype than observed in\", sentence=450195, chars=[44,114], words=[8,17])),\n",
       " GenePhenoPair(Span(\"ATL9\", sentence=450205, chars=[62,65], words=[7,7]), Span(\"a 2-fold decrease in conidiophores per colony\", sentence=450205, chars=[132,176], words=[17,23])),\n",
       " GenePhenoPair(Span(\"try etr2-3\", sentence=448024, chars=[4,13], words=[1,2]), Span(\"unbranched trichomes that, in a few cases\", sentence=448024, chars=[33,73], words=[6,13])),\n",
       " GenePhenoPair(Span(\"ZIP-4,\", sentence=450028, chars=[190,195], words=[40,41]), Span(\"rescued the salt-sensitive phenotype (\", sentence=450028, chars=[197,234], words=[42,46])),\n",
       " GenePhenoPair(Span(\"alg10-1\", sentence=388420, chars=[31,37], words=[4,4]), Span(\"indistinguishable from the wild type,\", sentence=388420, chars=[43,79], words=[6,11])),\n",
       " GenePhenoPair(Span(\"etr2-1,\", sentence=447968, chars=[28,34], words=[6,7]), Span(\"lower number of branched root hairs at 1.0 muM oryzalin\", sentence=447968, chars=[56,110], words=[11,20])),\n",
       " GenePhenoPair(Span(\"etr2-1\", sentence=447651, chars=[22,27], words=[5,5]), Span(\"three-branched trichomes, and\", sentence=447651, chars=[126,154], words=[31,34])),\n",
       " GenePhenoPair(Span(\"ASHH2\", sentence=423674, chars=[12,16], words=[2,2]), Span(\"leads to substantial changes in inflorescence gene expression.\", sentence=423674, chars=[18,79], words=[3,11])),\n",
       " GenePhenoPair(Span(\"etr2-2\", sentence=447695, chars=[4,9], words=[1,1]), Span(\"higher number of two-branched trichomes (C) while etr2-3\", sentence=447695, chars=[24,79], words=[5,14])),\n",
       " GenePhenoPair(Span(\"atl9-1, atl9-2, atl9-3\", sentence=450191, chars=[73,94], words=[13,17]), Span(\"more than two times the number of mature conidiophores\", sentence=450191, chars=[107,160], words=[20,28])),\n",
       " GenePhenoPair(Span(\"atl9-3\", sentence=450195, chars=[23,28], words=[5,5]), Span(\"a more pronounced susceptibility phenotype than observed in wild type\", sentence=450195, chars=[56,124], words=[10,19])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=450202, chars=[100,103], words=[15,15]), Span(\"restored the wild-type defense phenotype\", sentence=450202, chars=[114,153], words=[17,21])),\n",
       " GenePhenoPair(Span(\"alg10-1\", sentence=388407, chars=[4,10], words=[1,1]), Span(\"a severe underglycosylation defect.\", sentence=388407, chars=[28,62], words=[4,8])),\n",
       " GenePhenoPair(Span(\"35S:ENT1\", sentence=431374, chars=[40,47], words=[8,10]), Span(\"exhibited an increase in AK activity\", sentence=431374, chars=[81,116], words=[19,24])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=450202, chars=[100,103], words=[15,15]), Span(\"more susceptible than the resistant Kas-1 ecotype and complementation\", sentence=450202, chars=[23,91], words=[4,12])),\n",
       " GenePhenoPair(Span(\"spl/ems\", sentence=423726, chars=[112,118], words=[25,25]), Span(\">1.6-fold change), ms1 mutant\", sentence=423726, chars=[61,89], words=[12,18])),\n",
       " GenePhenoPair(Span(\"alg10-1 knf-101\", sentence=388852, chars=[8,22], words=[4,5]), Span(\"root elongation (10-day-old seedlings, 16-h light/8-h dark)\", sentence=388852, chars=[51,109], words=[10,19])),\n",
       " GenePhenoPair(Span(\"ASHH2\", sentence=422454, chars=[12,16], words=[2,2]), Span(\"results in a pleiotropic phenotype.\", sentence=422454, chars=[18,52], words=[3,8])),\n",
       " GenePhenoPair(Span(\"spy-5\", sentence=447991, chars=[18,22], words=[3,3]), Span(\"and three-branched trichomes (Fig.\", sentence=447991, chars=[156,189], words=[30,34])),\n",
       " GenePhenoPair(Span(\"cwinv4\", sentence=459525, chars=[129,134], words=[19,19]), Span(\"less soluble sugarRelated to the starch analyses\", sentence=459525, chars=[26,73], words=[3,9])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=450202, chars=[100,103], words=[15,15]), Span(\"the wild-type defense phenotype (\", sentence=450202, chars=[123,155], words=[18,22]))}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we should be getting an F1 score of around 0.6 to 0.7 on the development set, which is pretty good! However, we should be very careful in interpreting this. Since we developed our labeling functions using this development set as a guide, and our generative model is composed of these labeling functions, we expect it to score very well here!\n",
    "In fact, it is probably somewhat overfit to this set. However this is fine, since in the next tutorial, we'll train a more powerful end extraction model which will generalize beyond the development set, and which we will evaluate on a blind test set (i.e. one we never looked at during development)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing Some Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we might want to look at some examples in one of the error buckets. For example, one of the false negatives that we did not correctly label as true mentions. To do this, we can again just use the Viewer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require.undef('viewer');\n",
       "\n",
       "// NOTE: all elements should be selected using this.$el.find to avoid collisions with other Viewers\n",
       "\n",
       "define('viewer', [\"jupyter-js-widgets\"], function(widgets) {\n",
       "    var ViewerView = widgets.DOMWidgetView.extend({\n",
       "        render: function() {\n",
       "            this.cids   = this.model.get('cids');\n",
       "            this.nPages = this.cids.length;\n",
       "            this.pid  = 0;\n",
       "            this.cxid = 0;\n",
       "            this.cid  = 0;\n",
       "\n",
       "            // Insert the html payload\n",
       "            this.$el.append(this.model.get('html'));\n",
       "\n",
       "            // Initialize all labels from previous sessions\n",
       "            this.labels = this.deserializeDict(this.model.get('_labels_serialized'));\n",
       "            for (var i=0; i < this.nPages; i++) {\n",
       "                this.pid = i;\n",
       "                for (var j=0; j < this.cids[i].length; j++) {\n",
       "                    this.cxid = j;\n",
       "                    for (var k=0; k < this.cids[i][j].length; k++) {\n",
       "                        this.cid = k;\n",
       "                        if (this.cids[i][j][k] in this.labels) {\n",
       "                            this.markCurrentCandidate(false);\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "            }\n",
       "            this.pid  = 0;\n",
       "            this.cxid = 0;\n",
       "            this.cid  = 0;\n",
       "\n",
       "            // Enable button functionality for navigation\n",
       "            var that = this;\n",
       "            this.$el.find(\"#next-cand\").click(function() {\n",
       "                that.switchCandidate(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-cand\").click(function() {\n",
       "                that.switchCandidate(-1);\n",
       "            });\n",
       "            this.$el.find(\"#next-context\").click(function() {\n",
       "                that.switchContext(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-context\").click(function() {\n",
       "                that.switchContext(-1);\n",
       "            });\n",
       "            this.$el.find(\"#next-page\").click(function() {\n",
       "                that.switchPage(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-page\").click(function() {\n",
       "                that.switchPage(-1);\n",
       "            });\n",
       "            this.$el.find(\"#label-true\").click(function() {\n",
       "                that.labelCandidate(true, true);\n",
       "            });\n",
       "            this.$el.find(\"#label-false\").click(function() {\n",
       "                that.labelCandidate(false, true);\n",
       "            });\n",
       "\n",
       "            // Arrow key functionality\n",
       "            this.$el.keydown(function(e) {\n",
       "                switch(e.which) {\n",
       "                    case 74: // j\n",
       "                    that.switchCandidate(-1);\n",
       "                    break;\n",
       "\n",
       "                    case 73: // i\n",
       "                    that.switchPage(-1);\n",
       "                    break;\n",
       "\n",
       "                    case 76: // l\n",
       "                    that.switchCandidate(1);\n",
       "                    break;\n",
       "\n",
       "                    case 75: // k\n",
       "                    that.switchPage(1);\n",
       "                    break;\n",
       "\n",
       "                    case 84: // t\n",
       "                    that.labelCandidate(true, true);\n",
       "                    break;\n",
       "\n",
       "                    case 70: // f\n",
       "                    that.labelCandidate(false, true);\n",
       "                    break;\n",
       "                }\n",
       "            });\n",
       "\n",
       "            // Show the first page and highlight the first candidate\n",
       "            this.$el.find(\"#viewer-page-0\").show();\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Get candidate selector for currently selected candidate, escaping id properly\n",
       "        getCandidate: function() {\n",
       "            return this.$el.find(\".\"+this.cids[this.pid][this.cxid][this.cid]);\n",
       "        },  \n",
       "\n",
       "        // Color the candidate correctly according to registered label, as well as set highlighting\n",
       "        markCurrentCandidate: function(highlight) {\n",
       "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
       "            var tags = this.$el.find(\".\"+cid);\n",
       "\n",
       "            // Clear color classes\n",
       "            tags.removeClass(\"candidate-h\");\n",
       "            tags.removeClass(\"true-candidate\");\n",
       "            tags.removeClass(\"true-candidate-h\");\n",
       "            tags.removeClass(\"false-candidate\");\n",
       "            tags.removeClass(\"false-candidate-h\");\n",
       "            tags.removeClass(\"highlighted\");\n",
       "\n",
       "            if (highlight) {\n",
       "                if (cid in this.labels) {\n",
       "                    tags.addClass(String(this.labels[cid]) + \"-candidate-h\");\n",
       "                } else {\n",
       "                    tags.addClass(\"candidate-h\");\n",
       "                }\n",
       "            \n",
       "            // If un-highlighting, leave with first non-null coloring\n",
       "            } else {\n",
       "                var that = this;\n",
       "                tags.each(function() {\n",
       "                    var cids = $(this).attr('class').split(/\\s+/).map(function(item) {\n",
       "                        return parseInt(item);\n",
       "                    });\n",
       "                    cids.sort();\n",
       "                    for (var i in cids) {\n",
       "                        if (cids[i] in that.labels) {\n",
       "                            var label = that.labels[cids[i]];\n",
       "                            $(this).addClass(String(label) + \"-candidate\");\n",
       "                            $(this).removeClass(String(!label) + \"-candidate\");\n",
       "                            break;\n",
       "                        }\n",
       "                    }\n",
       "                });\n",
       "            }\n",
       "\n",
       "            // Extra highlighting css\n",
       "            if (highlight) {\n",
       "                tags.addClass(\"highlighted\");\n",
       "            }\n",
       "\n",
       "            // Classes for showing direction of relation\n",
       "            if (highlight) {\n",
       "                this.$el.find(\".\"+cid+\"-0\").addClass(\"left-candidate\");\n",
       "                this.$el.find(\".\"+cid+\"-1\").addClass(\"right-candidate\");\n",
       "            } else {\n",
       "                this.$el.find(\".\"+cid+\"-0\").removeClass(\"left-candidate\");\n",
       "                this.$el.find(\".\"+cid+\"-1\").removeClass(\"right-candidate\");\n",
       "            }\n",
       "        },\n",
       "\n",
       "        // Cycle through candidates and highlight, by increment inc\n",
       "        switchCandidate: function(inc) {\n",
       "            var N = this.cids[this.pid].length\n",
       "            var M = this.cids[this.pid][this.cxid].length;\n",
       "            if (N == 0 || M == 0) { return false; }\n",
       "\n",
       "            // Clear highlighting from previous candidate\n",
       "            if (inc != 0) {\n",
       "                this.markCurrentCandidate(false);\n",
       "\n",
       "                // Increment the cid counter\n",
       "\n",
       "                // Move to next context\n",
       "                if (this.cid + inc >= M) {\n",
       "                    while (this.cid + inc >= M) {\n",
       "                        \n",
       "                        // At last context on page, halt\n",
       "                        if (this.cxid == N - 1) {\n",
       "                            this.cid = M - 1;\n",
       "                            inc = 0;\n",
       "                            break;\n",
       "                        \n",
       "                        // Increment to next context\n",
       "                        } else {\n",
       "                            inc -= M - this.cid;\n",
       "                            this.cxid += 1;\n",
       "                            M = this.cids[this.pid][this.cxid].length;\n",
       "                            this.cid = 0;\n",
       "                        }\n",
       "                    }\n",
       "\n",
       "                // Move to previous context\n",
       "                } else if (this.cid + inc < 0) {\n",
       "                    while (this.cid + inc < 0) {\n",
       "                        \n",
       "                        // At first context on page, halt\n",
       "                        if (this.cxid == 0) {\n",
       "                            this.cid = 0;\n",
       "                            inc = 0;\n",
       "                            break;\n",
       "                        \n",
       "                        // Increment to previous context\n",
       "                        } else {\n",
       "                            inc += this.cid + 1;\n",
       "                            this.cxid -= 1;\n",
       "                            M = this.cids[this.pid][this.cxid].length;\n",
       "                            this.cid = M - 1;\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "\n",
       "                // Move within current context\n",
       "                this.cid += inc;\n",
       "            }\n",
       "            this.markCurrentCandidate(true);\n",
       "\n",
       "            // Push this new cid to the model\n",
       "            this.model.set('_selected_cid', this.cids[this.pid][this.cxid][this.cid]);\n",
       "            this.touch();\n",
       "        },\n",
       "\n",
       "        // Switch through contexts\n",
       "        switchContext: function(inc) {\n",
       "            this.markCurrentCandidate(false);\n",
       "\n",
       "            // Iterate context on this page\n",
       "            var M = this.cids[this.pid].length;\n",
       "            if (this.cxid + inc < 0) {\n",
       "                this.cxid = 0;\n",
       "            } else if (this.cxid + inc >= M) {\n",
       "                this.cxid = M - 1;\n",
       "            } else {\n",
       "                this.cxid += inc;\n",
       "            }\n",
       "\n",
       "            // Reset cid and set to first candidate\n",
       "            this.cid = 0;\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Switch through pages\n",
       "        switchPage: function(inc) {\n",
       "            this.markCurrentCandidate(false);\n",
       "            this.$el.find(\".viewer-page\").hide();\n",
       "            if (this.pid + inc < 0) {\n",
       "                this.pid = 0;\n",
       "            } else if (this.pid + inc > this.nPages - 1) {\n",
       "                this.pid = this.nPages - 1;\n",
       "            } else {\n",
       "                this.pid += inc;\n",
       "            }\n",
       "            this.$el.find(\"#viewer-page-\"+this.pid).show();\n",
       "\n",
       "            // Show pagination\n",
       "            this.$el.find(\"#page\").html(this.pid);\n",
       "\n",
       "            // Reset cid and set to first candidate\n",
       "            this.cid = 0;\n",
       "            this.cxid = 0;\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Label currently-selected candidate\n",
       "        labelCandidate: function(label, highlighted) {\n",
       "            var c    = this.getCandidate();\n",
       "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
       "            var cl   = String(label) + \"-candidate\";\n",
       "            var clh  = String(label) + \"-candidate-h\";\n",
       "            var cln  = String(!label) + \"-candidate\";\n",
       "            var clnh = String(!label) + \"-candidate-h\";\n",
       "\n",
       "            // Toggle label highlighting\n",
       "            if (c.hasClass(cl) || c.hasClass(clh)) {\n",
       "                c.removeClass(cl);\n",
       "                c.removeClass(clh);\n",
       "                if (highlighted) {\n",
       "                    c.addClass(\"candidate-h\");\n",
       "                }\n",
       "                this.labels[cid] = null;\n",
       "                this.send({event: 'delete_label', cid: cid});\n",
       "            } else {\n",
       "                c.removeClass(cln);\n",
       "                c.removeClass(clnh);\n",
       "                if (highlighted) {\n",
       "                    c.addClass(clh);\n",
       "                } else {\n",
       "                    c.addClass(cl);\n",
       "                }\n",
       "                this.labels[cid] = label;\n",
       "                this.send({event: 'set_label', cid: cid, value: label});\n",
       "            }\n",
       "\n",
       "            // Set the label and pass back to the model\n",
       "            this.model.set('_labels_serialized', this.serializeDict(this.labels));\n",
       "            this.touch();\n",
       "        },\n",
       "\n",
       "        // Serialization of hash maps, because traitlets Dict doesn't seem to work...\n",
       "        serializeDict: function(d) {\n",
       "            var s = [];\n",
       "            for (var key in d) {\n",
       "                s.push(key+\"~~\"+d[key]);\n",
       "            }\n",
       "            return s.join();\n",
       "        },\n",
       "\n",
       "        // Deserialization of hash maps\n",
       "        deserializeDict: function(s) {\n",
       "            var d = {};\n",
       "            var entries = s.split(/,/);\n",
       "            var kv;\n",
       "            for (var i in entries) {\n",
       "                kv = entries[i].split(/~~/);\n",
       "                if (kv[1] == \"true\") {\n",
       "                    d[kv[0]] = true;\n",
       "                } else if (kv[1] == \"false\") {\n",
       "                    d[kv[0]] = false;\n",
       "                }\n",
       "            }\n",
       "            return d;\n",
       "        },\n",
       "    });\n",
       "\n",
       "    return {\n",
       "        ViewerView: ViewerView\n",
       "    };\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "\n",
    "# NOTE: This if-then statement is only to avoid opening the viewer during automated testing of this notebook\n",
    "# You should ignore this!\n",
    "import os\n",
    "if 'CI' not in os.environ:\n",
    "    sv = SentenceNgramViewer(fp, session, height=400)\n",
    "else:\n",
    "    sv = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf04a0517e64595a22f7db6d7ef79a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenePhenoPair(Span(\"deltaalg10\", sentence=388171, chars=[223,232], words=[33,33]), Span(\"expressed the full-length Arabidopsis\", sentence=388171, chars=[94,130], words=[14,17]))\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{GenePhenoPair(Span(\"ALG10\", sentence=388833, chars=[0,4], words=[0,0]), Span(\"deficiency suppresses the severe phenotypes of the\", sentence=388833, chars=[6,55], words=[1,7])),\n",
       " GenePhenoPair(Span(\"alg10-1 cgl1\", sentence=388637, chars=[7,18], words=[2,3]), Span(\"contains a null allele of GnTI, no signal\", sentence=388637, chars=[103,143], words=[18,26])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=450902, chars=[95,98], words=[14,14]), Span(\"mutant (0.77-fold)\", sentence=450902, chars=[100,117], words=[15,18])),\n",
       " GenePhenoPair(Span(\"ms1\", sentence=423726, chars=[80,82], words=[17,17]), Span(\"mutant (>1.6-fold change).\", sentence=423726, chars=[122,147], words=[27,33])),\n",
       " GenePhenoPair(Span(\"EFR\", sentence=450977, chars=[113,115], words=[24,24]), Span(\"mutant and in wild-type plants.\", sentence=450977, chars=[198,228], words=[42,47])),\n",
       " GenePhenoPair(Span(\"nit1-3\", sentence=446898, chars=[216,221], words=[40,40]), Span(\"enhances the tir-1-1 phenotype\", sentence=446898, chars=[563,592], words=[117,120])),\n",
       " GenePhenoPair(Span(\"FLS2\", sentence=450977, chars=[65,68], words=[11,11]), Span(\"mutant and in wild-type plants.\", sentence=450977, chars=[198,228], words=[42,47])),\n",
       " GenePhenoPair(Span(\"ashh2-1\", sentence=423726, chars=[45,51], words=[9,9]), Span(\"mutant (>2-fold change) and\", sentence=423726, chars=[84,110], words=[18,24])),\n",
       " GenePhenoPair(Span(\"ms1\", sentence=423726, chars=[80,82], words=[17,17]), Span(\">2-fold change) and spl/ems\", sentence=423726, chars=[92,118], words=[20,25])),\n",
       " GenePhenoPair(Span(\"ashh2-1\", sentence=423726, chars=[45,51], words=[9,9]), Span(\">1.6-fold change), ms1 mutant\", sentence=423726, chars=[61,89], words=[12,18])),\n",
       " GenePhenoPair(Span(\"ms1\", sentence=423726, chars=[80,82], words=[17,17]), Span(\"mutant (>2-fold change) and\", sentence=423726, chars=[84,110], words=[18,24])),\n",
       " GenePhenoPair(Span(\"eta3\", sentence=446898, chars=[547,550], words=[115,115]), Span(\"auxin synthesis mutant, nit1-3 (Normanly et al.,\", sentence=446898, chars=[192,239], words=[36,45])),\n",
       " GenePhenoPair(Span(\"ashh2-1\", sentence=423194, chars=[6,12], words=[3,3]), Span(\"ovules with embryo sac-like structure (\", sentence=423194, chars=[14,52], words=[4,9])),\n",
       " GenePhenoPair(Span(\"ASHH2/ashh2-1\", sentence=422672, chars=[218,230], words=[34,35]), Span(\"and endosperm development as no deviation from wt in number\", sentence=422672, chars=[55,113], words=[10,19])),\n",
       " GenePhenoPair(Span(\"axr1-3, tir1-1, eta3/tir1\", sentence=446898, chars=[514,538], words=[107,111]), Span(\"auxin synthesis mutant, nit1-3 (Normanly et al.,\", sentence=446898, chars=[192,239], words=[36,45])),\n",
       " GenePhenoPair(Span(\"ASHH2/ashh2-1\", sentence=422672, chars=[218,230], words=[34,35]), Span(\"development as no deviation from wt in number of ovules/seeds\", sentence=422672, chars=[69,129], words=[12,21])),\n",
       " GenePhenoPair(Span(\"axr4-2, aux1-7\", sentence=446898, chars=[419,432], words=[83,85]), Span(\"auxin synthesis mutant, nit1-3 (Normanly et al.,\", sentence=446898, chars=[192,239], words=[36,45])),\n",
       " GenePhenoPair(Span(\"ENT1-over-expression\", sentence=431365, chars=[81,100], words=[12,12]), Span(\"fresh weight (Fig.\", sentence=431365, chars=[185,202], words=[26,29])),\n",
       " GenePhenoPair(Span(\"etr2-2\", sentence=447695, chars=[4,9], words=[1,1]), Span(\"unbranched trichomes\", sentence=447695, chars=[90,109], words=[17,18])),\n",
       " GenePhenoPair(Span(\"AP1\", sentence=425508, chars=[133,135], words=[21,21]), Span(\"the mutant phenotype\", sentence=425508, chars=[111,130], words=[17,19])),\n",
       " GenePhenoPair(Span(\"At1g74710)\", sentence=450902, chars=[49,58], words=[7,8]), Span(\"mutant (0.77-fold)\", sentence=450902, chars=[100,117], words=[15,18])),\n",
       " GenePhenoPair(Span(\"alg10-1 gntI\", sentence=388637, chars=[83,94], words=[14,15]), Span(\"contains a null allele of GnTI, no signal\", sentence=388637, chars=[103,143], words=[18,26])),\n",
       " GenePhenoPair(Span(\"alg10-1\", sentence=388672, chars=[93,99], words=[16,16]), Span(\"The alg10-1 seedlings\", sentence=388672, chars=[0,20], words=[0,2])),\n",
       " GenePhenoPair(Span(\"deltaalg10\", sentence=388187, chars=[60,69], words=[14,14]), Span(\"reduced number of faster-migrating CPY-forms\", sentence=388187, chars=[85,128], words=[18,22])),\n",
       " GenePhenoPair(Span(\"ashh2-1\", sentence=423726, chars=[45,51], words=[9,9]), Span(\"mutant (>1.6-fold change),\", sentence=423726, chars=[53,78], words=[10,16])),\n",
       " GenePhenoPair(Span(\"CPY\", sentence=388183, chars=[6,8], words=[1,1]), Span(\"reduced number of N-glycans\", sentence=388183, chars=[107,133], words=[16,19])),\n",
       " GenePhenoPair(Span(\"ALG10\", sentence=388187, chars=[51,55], words=[12,12]), Span(\"resulted in a reduced number of faster-migrating\", sentence=388187, chars=[71,118], words=[15,21])),\n",
       " GenePhenoPair(Span(\"spl/ems\", sentence=423726, chars=[112,118], words=[25,25]), Span(\"mutant (>2-fold change) and\", sentence=423726, chars=[84,110], words=[18,24])),\n",
       " GenePhenoPair(Span(\"ms1\", sentence=423726, chars=[80,82], words=[17,17]), Span(\"Number of co-down-regulated genes in the\", sentence=423726, chars=[4,43], words=[3,8])),\n",
       " GenePhenoPair(Span(\"spl/ems\", sentence=423726, chars=[112,118], words=[25,25]), Span(\"mutant (>1.6-fold change),\", sentence=423726, chars=[53,78], words=[10,16])),\n",
       " GenePhenoPair(Span(\"spl/ems\", sentence=423726, chars=[112,118], words=[25,25]), Span(\"Number of co-down-regulated genes in the\", sentence=423726, chars=[4,43], words=[3,8])),\n",
       " GenePhenoPair(Span(\"spl/ems\", sentence=423726, chars=[112,118], words=[25,25]), Span(\"mutant (>1.6-fold change).\", sentence=423726, chars=[122,147], words=[27,33])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=450977, chars=[193,196], words=[41,41]), Span(\"mutant and in wild-type plants.\", sentence=450977, chars=[198,228], words=[42,47])),\n",
       " GenePhenoPair(Span(\"ein2-5, jar1\", sentence=450133, chars=[92,103], words=[17,19]), Span(\"wild-type plants and in the\", sentence=450133, chars=[64,90], words=[12,16])),\n",
       " GenePhenoPair(Span(\"ATL9\", sentence=450133, chars=[16,19], words=[4,4]), Span(\"wild-type plants and in the\", sentence=450133, chars=[64,90], words=[12,16])),\n",
       " GenePhenoPair(Span(\"alg10-1\", sentence=388672, chars=[4,10], words=[1,1]), Span(\"smaller than the wild type and displayed alterations in leaf\", sentence=388672, chars=[113,172], words=[19,28])),\n",
       " GenePhenoPair(Span(\"axr4-2, aux1-7\", sentence=446898, chars=[419,432], words=[83,85]), Span(\"enhances the tir-1-1 phenotype\", sentence=446898, chars=[563,592], words=[117,120])),\n",
       " GenePhenoPair(Span(\"alg10-1\", sentence=388672, chars=[93,99], words=[16,16]), Span(\"indistinguishable from the wild type\", sentence=388672, chars=[27,62], words=[4,8])),\n",
       " GenePhenoPair(Span(\"ms1\", sentence=423726, chars=[80,82], words=[17,17]), Span(\"mutant (>1.6-fold change),\", sentence=423726, chars=[53,78], words=[10,16])),\n",
       " GenePhenoPair(Span(\"ashh2\", sentence=425485, chars=[113,117], words=[16,16]), Span(\"consistent expression changes by real-time\", sentence=425485, chars=[143,184], words=[20,24])),\n",
       " GenePhenoPair(Span(\"ENT1-RNAi\", sentence=431281, chars=[183,191], words=[40,40]), Span(\"adenosine from preloaded liposomes\", sentence=431281, chars=[334,367], words=[84,87])),\n",
       " GenePhenoPair(Span(\"ENT1-over-expression\", sentence=431365, chars=[81,100], words=[12,12]), Span(\"fresh weight while WT plants accumulated\", sentence=431365, chars=[135,174], words=[18,23])),\n",
       " GenePhenoPair(Span(\"alg10-1\", sentence=388507, chars=[238,244], words=[43,43]), Span(\"at the same position as the de-glycosylated wild-type protein,\", sentence=388507, chars=[134,195], words=[27,36])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=450835, chars=[130,133], words=[23,23]), Span(\"A) Hierarchical cluster of ratio values (relative to\", sentence=450835, chars=[0,51], words=[0,9])),\n",
       " GenePhenoPair(Span(\"cwinv4\", sentence=459457, chars=[5,10], words=[1,1]), Span(\"similar activities to wild-type plants (\", sentence=459457, chars=[134,173], words=[21,26])),\n",
       " GenePhenoPair(Span(\"SOS2, NHX1,\", sentence=441756, chars=[97,107], words=[18,21]), Span(\"Several genes\", sentence=441756, chars=[0,12], words=[0,1])),\n",
       " GenePhenoPair(Span(\"Glc3Man9GlcNAc2\", sentence=388262, chars=[94,108], words=[14,14]), Span(\"and smaller amounts of\", sentence=388262, chars=[207,228], words=[30,33])),\n",
       " GenePhenoPair(Span(\"aux1-7\", sentence=446978, chars=[226,231], words=[39,39]), Span(\"statistically significant except for the\", sentence=446978, chars=[174,213], words=[32,36])),\n",
       " GenePhenoPair(Span(\"Glc3Man9GlcNAc2\", sentence=388262, chars=[94,108], words=[14,14]), Span(\"smaller amounts of Glc1Man9GlcNAc2 and Man9GlcNAc2 (data\", sentence=388262, chars=[211,266], words=[31,38])),\n",
       " GenePhenoPair(Span(\"atl9,\", sentence=450307, chars=[153,157], words=[21,22]), Span(\"comparable numbers of conidiophores per colony and\", sentence=450307, chars=[61,110], words=[9,15])),\n",
       " GenePhenoPair(Span(\"H3K9me2,\", sentence=415745, chars=[33,40], words=[4,5]), Span(\"observed in the wild-type plants.\", sentence=415745, chars=[47,79], words=[7,12])),\n",
       " GenePhenoPair(Span(\"HDA6-mediated\", sentence=414869, chars=[21,33], words=[4,4]), Span(\"showed dependence on RdDM\", sentence=414869, chars=[50,74], words=[7,10])),\n",
       " GenePhenoPair(Span(\"stt3a-2\", sentence=388512, chars=[179,185], words=[26,26]), Span(\"more abundant in alg10-1 (Henquet\", sentence=388512, chars=[235,267], words=[34,39])),\n",
       " GenePhenoPair(Span(\"aba2-1\", sentence=447060, chars=[4,9], words=[1,1]), Span(\"than the wild type in both unstressed and stressed seedlings\", sentence=447060, chars=[63,122], words=[11,20])),\n",
       " GenePhenoPair(Span(\"ashh2\", sentence=422801, chars=[118,122], words=[21,21]), Span(\"result in an expected frequency of\", sentence=422801, chars=[83,116], words=[15,20])),\n",
       " GenePhenoPair(Span(\"aba2-1\", sentence=447060, chars=[4,9], words=[1,1]), Span(\"first order LRs than the wild type in both unstressed\", sentence=447060, chars=[47,99], words=[8,17])),\n",
       " GenePhenoPair(Span(\"alg10-1\", sentence=388804, chars=[98,104], words=[14,14]), Span(\"and wild-type plants\", sentence=388804, chars=[106,125], words=[15,17])),\n",
       " GenePhenoPair(Span(\"ALG10-deficient\", sentence=388793, chars=[17,31], words=[3,3]), Span(\"able to rescue the defects observed for the knf-14\", sentence=388793, chars=[50,99], words=[7,15])),\n",
       " GenePhenoPair(Span(\"aba3-1\", sentence=447068, chars=[20,25], words=[3,3]), Span(\"in first order LR number between unstressed and stressed seedlings\", sentence=447068, chars=[108,173], words=[17,26])),\n",
       " GenePhenoPair(Span(\"cwinv4-2\", sentence=459437, chars=[108,115], words=[17,17]), Span(\"as a null mutant, whereas\", sentence=459437, chars=[39,63], words=[5,10])),\n",
       " GenePhenoPair(Span(\"R1\", sentence=428215, chars=[46,47], words=[8,8]), Span(\"carries a protein-truncating SBS in Cullin\", sentence=428215, chars=[66,107], words=[13,18])),\n",
       " GenePhenoPair(Span(\"alg10-1 knf-14\", sentence=388804, chars=[16,29], words=[3,4]), Span(\"and wild-type plants\", sentence=388804, chars=[106,125], words=[15,17])),\n",
       " GenePhenoPair(Span(\"aba3-1\", sentence=447068, chars=[20,25], words=[3,3]), Span(\"difference in first order LR number between unstressed and stressed\", sentence=447068, chars=[97,163], words=[16,25])),\n",
       " GenePhenoPair(Span(\"deltaalg10\", sentence=388262, chars=[125,134], words=[18,18]), Span(\"and smaller amounts of\", sentence=388262, chars=[207,228], words=[30,33])),\n",
       " GenePhenoPair(Span(\"aba2-1\", sentence=447060, chars=[4,9], words=[1,1]), Span(\"the wild type in both unstressed and stressed seedlings (\", sentence=447060, chars=[68,124], words=[12,21])),\n",
       " GenePhenoPair(Span(\"ENT1\", sentence=431172, chars=[31,34], words=[5,5]), Span(\"the main substrate of\", sentence=431172, chars=[105,125], words=[16,19])),\n",
       " GenePhenoPair(Span(\"aba3-1\", sentence=447068, chars=[20,25], words=[3,3]), Span(\"significant difference in first order LR number between unstressed and\", sentence=447068, chars=[85,154], words=[15,24])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=450791, chars=[217,220], words=[37,37]), Span(\"fluctuated between wild-type plants and the\", sentence=450791, chars=[173,215], words=[31,36])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=450791, chars=[217,220], words=[37,37]), Span(\"smaller number (525) fluctuated between wild-type plants\", sentence=450791, chars=[152,207], words=[26,34])),\n",
       " GenePhenoPair(Span(\"promoter:AtS1P\", sentence=449925, chars=[38,51], words=[8,10]), Span(\"responsible for the salt-sensitive phenotype (Fig.\", sentence=449925, chars=[139,188], words=[25,32])),\n",
       " GenePhenoPair(Span(\"s1p-3\", sentence=449925, chars=[76,80], words=[14,14]), Span(\"responsible for the salt-sensitive phenotype (Fig.\", sentence=449925, chars=[139,188], words=[25,32])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=450791, chars=[217,220], words=[37,37]), Span(\"while a smaller number (\", sentence=450791, chars=[144,167], words=[24,28])),\n",
       " GenePhenoPair(Span(\"deltaalg10\", sentence=388262, chars=[125,134], words=[18,18]), Span(\"In contrast to wild-type cells,\", sentence=388262, chars=[0,30], words=[0,5])),\n",
       " GenePhenoPair(Span(\"cwinv4\", sentence=459433, chars=[0,5], words=[0,0]), Span(\"two independent T-DNA mutant lines\", sentence=459433, chars=[65,98], words=[10,14])),\n",
       " GenePhenoPair(Span(\"aba2-1\", sentence=447060, chars=[4,9], words=[1,1]), Span(\"order LRs than the wild type in both unstressed and\", sentence=447060, chars=[53,103], words=[9,18])),\n",
       " GenePhenoPair(Span(\"ashh2\", sentence=422525, chars=[50,54], words=[8,8]), Span(\"and the pleiotropic phenotype of\", sentence=422525, chars=[17,48], words=[3,7])),\n",
       " GenePhenoPair(Span(\"ashh2\", sentence=422525, chars=[11,15], words=[2,2]), Span(\"and the pleiotropic phenotype of\", sentence=422525, chars=[17,48], words=[3,7])),\n",
       " GenePhenoPair(Span(\"cwinv4-2\", sentence=459445, chars=[97,104], words=[19,19]), Span(\"homozygous mutant plants.\", sentence=459445, chars=[208,232], words=[36,39])),\n",
       " GenePhenoPair(Span(\"cwinv4-1\", sentence=459445, chars=[70,77], words=[14,14]), Span(\"homozygous mutant plants.\", sentence=459445, chars=[208,232], words=[36,39])),\n",
       " GenePhenoPair(Span(\"alg10-1\", sentence=388496, chars=[44,50], words=[6,6]), Span(\"more detail we performed SDS-PAGE and immunoblotting using antibodies\", sentence=388496, chars=[55,123], words=[8,16])),\n",
       " GenePhenoPair(Span(\"Figure1B;\", sentence=428098, chars=[244,252], words=[36,37]), Span(\"In six further cases, phenotypes\", sentence=428098, chars=[0,31], words=[0,5])),\n",
       " GenePhenoPair(Span(\"Figure1B;\", sentence=428098, chars=[244,252], words=[36,37]), Span(\"heritable and segregated within\", sentence=428098, chars=[45,75], words=[8,11])),\n",
       " GenePhenoPair(Span(\"HY1\", sentence=428218, chars=[277,279], words=[44,44]), Span(\"late flowering\", sentence=428218, chars=[365,378], words=[62,63])),\n",
       " GenePhenoPair(Span(\"s1p-3,\", sentence=450369, chars=[107,112], words=[17,18]), Span(\"rank ordered by increases in expression under salt stress conditions\", sentence=450369, chars=[11,78], words=[2,11])),\n",
       " GenePhenoPair(Span(\"ashh2\", sentence=422487, chars=[4,8], words=[1,1]), Span(\"smaller than wt organs (Figures 1D and 1E\", sentence=422487, chars=[22,62], words=[4,12])),\n",
       " GenePhenoPair(Span(\"Figure2B).\", sentence=428157, chars=[349,358], words=[55,57]), Span(\"actual number of regenerant mutations by multiplying the detected mutations\", sentence=428157, chars=[239,313], words=[39,48])),\n",
       " GenePhenoPair(Span(\"Figure4; FigureS4).\", sentence=428242, chars=[576,594], words=[97,101]), Span(\"in whole-genome sequence\", sentence=428242, chars=[237,260], words=[40,42])),\n",
       " GenePhenoPair(Span(\"ein2\", sentence=447046, chars=[219,222], words=[36,36]), Span(\"attenuated in ethylene signalling mutants such as\", sentence=447046, chars=[169,217], words=[29,35])),\n",
       " GenePhenoPair(Span(\"PR1\", sentence=450507, chars=[229,231], words=[43,43]), Span(\"drops off to negligible levels at\", sentence=450507, chars=[157,189], words=[28,33])),\n",
       " GenePhenoPair(Span(\"R1\", sentence=428133, chars=[113,114], words=[18,18]), Span(\"or gross chromosomal abnormalities\", sentence=428133, chars=[45,78], words=[7,10])),\n",
       " GenePhenoPair(Span(\"axe1-5\", sentence=416721, chars=[31,36], words=[4,4]), Span(\"wild-type plants\", sentence=416721, chars=[0,15], words=[0,1])),\n",
       " GenePhenoPair(Span(\"aba2-1\", sentence=447060, chars=[4,9], words=[1,1]), Span(\"LRs than the wild type in both unstressed and stressed\", sentence=447060, chars=[59,112], words=[10,19])),\n",
       " GenePhenoPair(Span(\"met1/+ nrpd2\", sentence=428242, chars=[477,488], words=[77,80]), Span(\"in whole-genome sequence\", sentence=428242, chars=[237,260], words=[40,42])),\n",
       " GenePhenoPair(Span(\"sid2-1\", sentence=450311, chars=[95,100], words=[15,15]), Span(\"susceptible to powdery mildew\", sentence=450311, chars=[41,69], words=[7,10])),\n",
       " GenePhenoPair(Span(\"aba3-1\", sentence=447068, chars=[20,25], words=[3,3]), Span(\"first order LR number between unstressed and stressed seedlings.\", sentence=447068, chars=[111,174], words=[18,27])),\n",
       " GenePhenoPair(Span(\"R1\", sentence=428157, chars=[195,196], words=[32,32]), Span(\"detecting homozygous mutations\", sentence=428157, chars=[16,45], words=[3,5])),\n",
       " GenePhenoPair(Span(\"CAF1\", sentence=448016, chars=[76,79], words=[14,14]), Span(\"unbranched trichomes\", sentence=448016, chars=[173,192], words=[33,34])),\n",
       " GenePhenoPair(Span(\"AtS1P\", sentence=449925, chars=[130,134], words=[23,23]), Span(\"responsible for the salt-sensitive phenotype (Fig.\", sentence=449925, chars=[139,188], words=[25,32])),\n",
       " GenePhenoPair(Span(\"Figure2B).\", sentence=428157, chars=[349,358], words=[55,57]), Span(\"the actual number of regenerant mutations by multiplying the detected\", sentence=428157, chars=[235,303], words=[38,47])),\n",
       " GenePhenoPair(Span(\"Figure2B).\", sentence=428157, chars=[349,358], words=[55,57]), Span(\"see Experimental\", sentence=428157, chars=[53,68], words=[8,9])),\n",
       " GenePhenoPair(Span(\"35S:ATL9\", sentence=450307, chars=[163,170], words=[24,26]), Span(\"comparable numbers of conidiophores per colony and\", sentence=450307, chars=[61,110], words=[9,15])),\n",
       " GenePhenoPair(Span(\"knf-14\", sentence=388800, chars=[107,112], words=[18,18]), Span(\"were knockout for alg10-1\", sentence=388800, chars=[39,63], words=[7,10])),\n",
       " GenePhenoPair(Span(\"Figure2B).\", sentence=428157, chars=[349,358], words=[55,57]), Span(\"detecting homozygous mutations\", sentence=428157, chars=[16,45], words=[3,5])),\n",
       " GenePhenoPair(Span(\"aba2-1\", sentence=447060, chars=[4,9], words=[1,1]), Span(\"wild type in both unstressed and stressed seedlings (Fig.\", sentence=447060, chars=[72,128], words=[13,22])),\n",
       " GenePhenoPair(Span(\"FKF1\", sentence=428218, chars=[337,340], words=[57,57]), Span(\"long hypocotyl\", sentence=428218, chars=[97,110], words=[11,12])),\n",
       " GenePhenoPair(Span(\"ashh2-5\", sentence=423447, chars=[139,145], words=[27,27]), Span(\"due to defects in male meiosis,\", sentence=423447, chars=[62,92], words=[12,18])),\n",
       " GenePhenoPair(Span(\"ENT1-RNAi\", sentence=431500, chars=[36,44], words=[8,8]), Span(\"Representative images of\", sentence=431500, chars=[4,27], words=[3,5])),\n",
       " GenePhenoPair(Span(\"drm1 drm2 cmt3.\", sentence=414893, chars=[36,50], words=[6,9]), Span(\"larger overlap to the triple mutant drm1 drm2 cmt3\", sentence=414893, chars=[0,49], words=[0,8])),\n",
       " GenePhenoPair(Span(\"stt3a-2\", sentence=388524, chars=[4,10], words=[1,1]), Span(\"a T-DNA insertion in the gene coding for the\", sentence=388524, chars=[23,66], words=[4,12])),\n",
       " GenePhenoPair(Span(\"stt3a-2\", sentence=388751, chars=[21,27], words=[3,3]), Span(\"indistinguishable from the wild type (\", sentence=388751, chars=[146,183], words=[28,33])),\n",
       " GenePhenoPair(Span(\"alg10-1\", sentence=388751, chars=[124,130], words=[25,25]), Span(\"indistinguishable from the wild type (\", sentence=388751, chars=[146,183], words=[28,33])),\n",
       " GenePhenoPair(Span(\"ein2-1, etr1-3\", sentence=447050, chars=[449,462], words=[93,95]), Span(\"enhanced salt SIMR by testing\", sentence=447050, chars=[89,117], words=[16,20])),\n",
       " GenePhenoPair(Span(\"abi4-1\", sentence=447050, chars=[363,368], words=[73,73]), Span(\"a different phenotype\", sentence=447050, chars=[148,168], words=[26,28])),\n",
       " GenePhenoPair(Span(\"abi4-1\", sentence=447050, chars=[363,368], words=[73,73]), Span(\"enhanced salt SIMR by testing\", sentence=447050, chars=[89,117], words=[16,20])),\n",
       " GenePhenoPair(Span(\"aba2-1, aba3-1\", sentence=447050, chars=[259,272], words=[48,50]), Span(\"a different phenotype\", sentence=447050, chars=[148,168], words=[26,28])),\n",
       " GenePhenoPair(Span(\"At5g19660)\", sentence=449855, chars=[23,32], words=[8,9]), Span(\"in the 5th exon,\", sentence=449855, chars=[156,171], words=[35,39])),\n",
       " GenePhenoPair(Span(\"s1p-5\", sentence=449855, chars=[238,242], words=[55,55]), Span(\"in the 5th exon,\", sentence=449855, chars=[156,171], words=[35,39])),\n",
       " GenePhenoPair(Span(\"At5g19660)\", sentence=449855, chars=[23,32], words=[8,9]), Span(\"in the 8th exon.\", sentence=449855, chars=[258,273], words=[59,63])),\n",
       " GenePhenoPair(Span(\"At5g19660)\", sentence=449855, chars=[23,32], words=[8,9]), Span(\"in the 7th exon, and\", sentence=449855, chars=[193,212], words=[44,49])),\n",
       " GenePhenoPair(Span(\"s1p-3\", sentence=449903, chars=[11,15], words=[2,2]), Span(\"such as KCl and LiCl, and to mannitol (\", sentence=449903, chars=[63,101], words=[11,20])),\n",
       " GenePhenoPair(Span(\"ashh2-5\", sentence=422474, chars=[43,49], words=[7,7]), Span(\"a characteristic dwarf and bushy phenotype (\", sentence=422474, chars=[56,99], words=[9,15])),\n",
       " GenePhenoPair(Span(\"ashh2-1, ashh2-2\", sentence=423447, chars=[118,133], words=[23,25]), Span(\"due to defects in male meiosis,\", sentence=423447, chars=[62,92], words=[12,18])),\n",
       " GenePhenoPair(Span(\"s1p-3\", sentence=449903, chars=[11,15], words=[2,2]), Span(\"salts, such as KCl and LiCl, and to\", sentence=449903, chars=[56,90], words=[9,18])),\n",
       " GenePhenoPair(Span(\"s1p-3\", sentence=449903, chars=[11,15], words=[2,2]), Span(\"other monovalent salts, such as KCl and LiCl,\", sentence=449903, chars=[39,83], words=[7,16])),\n",
       " GenePhenoPair(Span(\"s1p-4\", sentence=449855, chars=[214,218], words=[50,50]), Span(\"in the 5th exon,\", sentence=449855, chars=[156,171], words=[35,39])),\n",
       " GenePhenoPair(Span(\"AC004260)\", sentence=422545, chars=[0,8], words=[0,1]), Span(\"start and stop codons and selected exon-intron borders.\", sentence=422545, chars=[54,108], words=[10,18])),\n",
       " GenePhenoPair(Span(\"s1p-3,\", sentence=449888, chars=[11,16], words=[2,3]), Span(\"with a T-DNA insertion in the 7th exon,\", sentence=449888, chars=[18,56], words=[4,12])),\n",
       " GenePhenoPair(Span(\"cwinv4-2\", sentence=459449, chars=[153,160], words=[26,26]), Span(\"a null mutant, and that\", sentence=459449, chars=[84,106], words=[14,19])),\n",
       " GenePhenoPair(Span(\"HY1\", sentence=428218, chars=[277,279], words=[44,44]), Span(\"mutant alleles confer late\", sentence=428218, chars=[343,368], words=[59,62])),\n",
       " GenePhenoPair(Span(\"ashh2-1\", sentence=423682, chars=[242,248], words=[48,48]), Span(\">0.7 as cut-off (i.e. up- or down-regulation\", sentence=423682, chars=[131,174], words=[26,35])),\n",
       " GenePhenoPair(Span(\"s1p-3\", sentence=450884, chars=[161,165], words=[27,27]), Span(\"type (wt)\", sentence=450884, chars=[129,137], words=[19,22])),\n",
       " GenePhenoPair(Span(\"NO3--enhanced\", sentence=447050, chars=[84,96], words=[14,16]), Span(\"a different phenotype\", sentence=447050, chars=[148,168], words=[26,28])),\n",
       " GenePhenoPair(Span(\"ein2-1, etr1-3\", sentence=447050, chars=[449,462], words=[93,95]), Span(\"a different phenotype\", sentence=447050, chars=[148,168], words=[26,28])),\n",
       " GenePhenoPair(Span(\"MAP4\", sentence=447933, chars=[76,79], words=[9,9]), Span(\"rescue the etr2-3 mutant phenotype\", sentence=447933, chars=[124,157], words=[16,20])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=450783, chars=[122,125], words=[21,21]), Span(\"to wild-type plants (\", sentence=450783, chars=[143,163], words=[24,27])),\n",
       " GenePhenoPair(Span(\"s1p-3\", sentence=449903, chars=[11,15], words=[2,2]), Span(\"to other monovalent salts, such as KCl and LiCl\", sentence=449903, chars=[36,82], words=[6,15])),\n",
       " GenePhenoPair(Span(\"s1p-3\", sentence=449903, chars=[11,15], words=[2,2]), Span(\"monovalent salts, such as KCl and LiCl, and\", sentence=449903, chars=[45,87], words=[8,17])),\n",
       " GenePhenoPair(Span(\"alpha1,2-glucosyltransferase.\", sentence=388271, chars=[189,217], words=[27,28]), Span(\"the corresponding plant\", sentence=388271, chars=[165,187], words=[24,26])),\n",
       " GenePhenoPair(Span(\"deltaalg10\", sentence=388271, chars=[111,120], words=[15,15]), Span(\"the corresponding plant\", sentence=388271, chars=[165,187], words=[24,26])),\n",
       " GenePhenoPair(Span(\"HY1\", sentence=428218, chars=[277,279], words=[44,44]), Span(\"late flowering\", sentence=428218, chars=[156,169], words=[24,25])),\n",
       " GenePhenoPair(Span(\"ALG10\", sentence=388271, chars=[33,37], words=[5,5]), Span(\"the corresponding plant\", sentence=388271, chars=[165,187], words=[24,26])),\n",
       " GenePhenoPair(Span(\"ashh2-1, ashh2-2\", sentence=423447, chars=[118,133], words=[23,25]), Span(\"reduced number of pollen grains\", sentence=423447, chars=[7,37], words=[2,6])),\n",
       " GenePhenoPair(Span(\"ashh2-5\", sentence=423447, chars=[139,145], words=[27,27]), Span(\"reduced number of pollen grains\", sentence=423447, chars=[7,37], words=[2,6])),\n",
       " GenePhenoPair(Span(\"ASHH2/ashh2-1\", sentence=422786, chars=[22,34], words=[2,3]), Span(\"wt plants,\", sentence=422786, chars=[113,122], words=[19,21])),\n",
       " GenePhenoPair(Span(\"ashh2-1/ashh2-1\", sentence=422786, chars=[74,88], words=[11,13]), Span(\"wt plants,\", sentence=422786, chars=[113,122], words=[19,21])),\n",
       " GenePhenoPair(Span(\"alg10-1\", sentence=388512, chars=[252,258], words=[37,37]), Span(\"more severe defect than observed for alg3 and stt3a-2 mutants\", sentence=388512, chars=[133,193], words=[18,27])),\n",
       " GenePhenoPair(Span(\"ALG10\", sentence=388512, chars=[97,101], words=[13,13]), Span(\"more abundant in alg10-1 (Henquet\", sentence=388512, chars=[235,267], words=[34,39])),\n",
       " GenePhenoPair(Span(\"aux1-7\", sentence=446978, chars=[226,231], words=[39,39]), Span(\"and aux1-7 roots, although this decrease\", sentence=446978, chars=[125,164], words=[23,29])),\n",
       " GenePhenoPair(Span(\"ALG10\", sentence=388512, chars=[97,101], words=[13,13]), Span(\"more severe defect than observed for alg3 and stt3a-2 mutants\", sentence=388512, chars=[133,193], words=[18,27])),\n",
       " GenePhenoPair(Span(\"SOS1, SOS2, NHX1\", sentence=441756, chars=[91,106], words=[16,20]), Span(\"Several genes\", sentence=441756, chars=[0,12], words=[0,1])),\n",
       " GenePhenoPair(Span(\"HKT1)\", sentence=441756, chars=[113,117], words=[23,24]), Span(\"Several genes\", sentence=441756, chars=[0,12], words=[0,1])),\n",
       " GenePhenoPair(Span(\"stt3a-2\", sentence=388755, chars=[131,137], words=[19,19]), Span(\"more sensitive towards the treatment with tunicamycin than wild-type seedlings\", sentence=388755, chars=[28,105], words=[5,14])),\n",
       " GenePhenoPair(Span(\"knf-14\", sentence=388793, chars=[94,99], words=[15,15]), Span(\"As a consequence ALG10-deficient mutants\", sentence=388793, chars=[0,39], words=[0,4])),\n",
       " GenePhenoPair(Span(\"alg10-1\", sentence=388755, chars=[4,10], words=[1,1]), Span(\"less sensitive than stt3a-2 (Figure S6\", sentence=388755, chars=[111,148], words=[16,22])),\n",
       " GenePhenoPair(Span(\"alg10-1\", sentence=388755, chars=[4,10], words=[1,1]), Span(\"sensitive towards the treatment with tunicamycin than wild-type seedlings but\", sentence=388755, chars=[33,109], words=[6,15])),\n",
       " GenePhenoPair(Span(\"ALG10\", sentence=388767, chars=[89,93], words=[14,14]), Span(\"driven by the ubiquitin-10 promoter (\", sentence=388767, chars=[133,169], words=[21,26])),\n",
       " GenePhenoPair(Span(\"UBQ10:ALG10),\", sentence=388767, chars=[170,182], words=[27,31]), Span(\"driven by the ubiquitin-10 promoter (\", sentence=388767, chars=[133,169], words=[21,26])),\n",
       " GenePhenoPair(Span(\"alg10-1\", sentence=388767, chars=[66,72], words=[10,10]), Span(\"driven by the ubiquitin-10 promoter (\", sentence=388767, chars=[133,169], words=[21,26])),\n",
       " GenePhenoPair(Span(\"knf-101\", sentence=388793, chars=[170,176], words=[30,30]), Span(\"able to rescue the defects observed for the knf-14\", sentence=388793, chars=[50,99], words=[7,15])),\n",
       " GenePhenoPair(Span(\"alg10-1 knf-101\", sentence=388808, chars=[112,126], words=[19,20]), Span(\"the root growth phenotype\", sentence=388808, chars=[13,37], words=[3,6])),\n",
       " GenePhenoPair(Span(\"knf-101\", sentence=388808, chars=[64,70], words=[12,12]), Span(\"the root growth phenotype\", sentence=388808, chars=[13,37], words=[3,6])),\n",
       " GenePhenoPair(Span(\"aba2-1\", sentence=447072, chars=[55,60], words=[9,9]), Span(\"of first order LRs in unstressed and stressed seedlings but\", sentence=447072, chars=[90,148], words=[14,23])),\n",
       " GenePhenoPair(Span(\"etr2-3\", sentence=447655, chars=[58,63], words=[10,10]), Span(\"altered phenotype\", sentence=447655, chars=[9,25], words=[2,3])),\n",
       " GenePhenoPair(Span(\"ein2-1\", sentence=447072, chars=[4,9], words=[1,1]), Span(\"unstressed and stressed seedlings but no stimulation of first order\", sentence=447072, chars=[112,178], words=[19,28])),\n",
       " GenePhenoPair(Span(\"ein2-1\", sentence=447072, chars=[4,9], words=[1,1]), Span(\"numbers of first order LRs in unstressed and stressed seedlings\", sentence=447072, chars=[82,144], words=[13,22])),\n",
       " GenePhenoPair(Span(\"ein2-1\", sentence=447072, chars=[4,9], words=[1,1]), Span(\"of first order LRs in unstressed and stressed seedlings but\", sentence=447072, chars=[90,148], words=[14,23])),\n",
       " GenePhenoPair(Span(\"cwinv4-2\", sentence=459459, chars=[189,196], words=[32,32]), Span(\"higher cell wall invertase activity observed in cwinv4-2\", sentence=459459, chars=[4,59], words=[1,8])),\n",
       " GenePhenoPair(Span(\"ein2-1\", sentence=447072, chars=[4,9], words=[1,1]), Span(\"first order LRs in unstressed and stressed seedlings but no\", sentence=447072, chars=[93,151], words=[15,24])),\n",
       " GenePhenoPair(Span(\"ein2-1\", sentence=447072, chars=[4,9], words=[1,1]), Span(\"LRs in unstressed and stressed seedlings but no stimulation of\", sentence=447072, chars=[105,166], words=[17,26])),\n",
       " GenePhenoPair(Span(\"zip17\", sentence=450911, chars=[234,238], words=[44,44]), Span(\"in wild-type seedlings, as detected by semi-quantitative\", sentence=450911, chars=[118,173], words=[24,31])),\n",
       " GenePhenoPair(Span(\"STT3A\", sentence=388668, chars=[20,24], words=[4,4]), Span(\"display any obvious phenotype\", sentence=388668, chars=[114,142], words=[18,21])),\n",
       " GenePhenoPair(Span(\"ALG3\", sentence=388668, chars=[12,15], words=[2,2]), Span(\"any obvious phenotype under normal growth conditions (\", sentence=388668, chars=[122,175], words=[19,26])),\n",
       " GenePhenoPair(Span(\"etr2-3\", sentence=447939, chars=[7,12], words=[2,2]), Span(\"possible to disrupt cytoskeletal assembly more easily in the\", sentence=447939, chars=[95,154], words=[17,25])),\n",
       " GenePhenoPair(Span(\"etr2-3\", sentence=447939, chars=[156,161], words=[26,26]), Span(\"possible to disrupt cytoskeletal assembly more easily in the\", sentence=447939, chars=[95,154], words=[17,25])),\n",
       " GenePhenoPair(Span(\"etr2-3\", sentence=447768, chars=[96,101], words=[14,14]), Span(\"stained with 4,6-diamidino-2-phenylindole (DAPI) to determine the\", sentence=447768, chars=[15,79], words=[2,10])),\n",
       " GenePhenoPair(Span(\"etr2-1\", sentence=447651, chars=[22,27], words=[5,5]), Span(\"lacked four-branched trichomes and\", sentence=447651, chars=[233,266], words=[55,58])),\n",
       " GenePhenoPair(Span(\"etr2-1\", sentence=447651, chars=[22,27], words=[5,5]), Span(\"two-branched trichomes, and\", sentence=447651, chars=[284,310], words=[63,66])),\n",
       " GenePhenoPair(Span(\"etr2-1\", sentence=447651, chars=[22,27], words=[5,5]), Span(\"three-branched trichomes (\", sentence=447651, chars=[316,341], words=[69,71])),\n",
       " GenePhenoPair(Span(\"ashh2-1, ashh2-2\", sentence=422474, chars=[22,37], words=[3,5]), Span(\"a characteristic dwarf and bushy phenotype (\", sentence=422474, chars=[56,99], words=[9,15])),\n",
       " GenePhenoPair(Span(\"rdr2\", sentence=414846, chars=[32,35], words=[7,7]), Span(\"silenced state in\", sentence=414846, chars=[10,26], words=[3,5])),\n",
       " GenePhenoPair(Span(\"GFP:LTI6b\", sentence=459431, chars=[176,184], words=[30,32]), Span(\"in contrast to the well-defined localization of a plasma-membrane targeted\", sentence=459431, chars=[21,94], words=[3,12])),\n",
       " GenePhenoPair(Span(\"ALG3\", sentence=388668, chars=[12,15], words=[2,2]), Span(\"display any obvious phenotype\", sentence=388668, chars=[114,142], words=[18,21])),\n",
       " GenePhenoPair(Span(\"AtbZIP17\", sentence=450100, chars=[193,200], words=[36,36]), Span(\"that the 84-kDa construct\", sentence=450100, chars=[13,37], words=[3,6])),\n",
       " GenePhenoPair(Span(\"aba2-1, aba3-1\", sentence=447050, chars=[259,272], words=[48,50]), Span(\"enhanced salt SIMR by testing\", sentence=447050, chars=[89,117], words=[16,20])),\n",
       " GenePhenoPair(Span(\"AtbZIP17\", sentence=450094, chars=[21,28], words=[3,3]), Span(\"developed and introduced into transgenic seedlings.\", sentence=450094, chars=[119,169], words=[18,24])),\n",
       " GenePhenoPair(Span(\"alg10-1\", sentence=388701, chars=[23,29], words=[8,8]), Span(\"soil under long-day conditions (16-h light/8-h dark).\", sentence=388701, chars=[54,106], words=[13,22])),\n",
       " GenePhenoPair(Span(\"alg10-1\", sentence=388701, chars=[23,29], words=[8,8]), Span(\"on soil under long-day conditions (16-h light/8-h dark)\", sentence=388701, chars=[51,105], words=[12,21])),\n",
       " GenePhenoPair(Span(\"ashh2-1\", sentence=423718, chars=[66,72], words=[11,11]), Span(\"inflorescences relative to wt.\", sentence=423718, chars=[74,103], words=[12,16])),\n",
       " GenePhenoPair(Span(\"eta3/tir1-1\", sentence=446906, chars=[125,135], words=[24,25]), Span(\"completely blocked in the aux1-7 mutant,\", sentence=446906, chars=[153,192], words=[30,36])),\n",
       " GenePhenoPair(Span(\"alg10-1\", sentence=388360, chars=[55,61], words=[10,10]), Span(\"perform the last step of the lipid-linked precursor biosynthesis.\", sentence=388360, chars=[270,334], words=[47,56])),\n",
       " GenePhenoPair(Span(\"etr1-3\", sentence=447132, chars=[29,34], words=[6,6]), Span(\"greater LR proliferation\", sentence=447132, chars=[143,166], words=[26,28])),\n",
       " GenePhenoPair(Span(\"aba2-1\", sentence=447072, chars=[55,60], words=[9,9]), Span(\"order LRs in unstressed and stressed seedlings but no stimulation\", sentence=447072, chars=[99,163], words=[16,25])),\n",
       " GenePhenoPair(Span(\"aba2-1\", sentence=447072, chars=[55,60], words=[9,9]), Span(\"numbers of first order LRs in unstressed and stressed seedlings\", sentence=447072, chars=[82,144], words=[13,22])),\n",
       " GenePhenoPair(Span(\"plants.cwinv4\", sentence=459475, chars=[178,190], words=[25,25]), Span(\"amplitudes of total activity for both wild-type and mutant\", sentence=459475, chars=[119,176], words=[16,24])),\n",
       " GenePhenoPair(Span(\"Glc2Man9GlcNAc2-PP-Dol,\", sentence=388074, chars=[256,278], words=[33,34]), Span(\"annotated to the glycosyltransferase family\", sentence=388074, chars=[22,64], words=[4,8])),\n",
       " GenePhenoPair(Span(\"aba2-1\", sentence=447072, chars=[55,60], words=[9,9]), Span(\"with greater numbers of first order LRs in unstressed and\", sentence=447072, chars=[69,125], words=[11,20])),\n",
       " GenePhenoPair(Span(\"cwinv4-1\", sentence=459459, chars=[66,73], words=[10,10]), Span(\"a knockdown mutant).\", sentence=459459, chars=[201,220], words=[34,38])),\n",
       " GenePhenoPair(Span(\"alpha1,2-linkage\", sentence=388074, chars=[236,251], words=[31,31]), Span(\"annotated to the glycosyltransferase family\", sentence=388074, chars=[22,64], words=[4,8])),\n",
       " GenePhenoPair(Span(\"cwinv4-1\", sentence=459459, chars=[154,161], words=[25,25]), Span(\"higher cell wall invertase activity observed in cwinv4-2\", sentence=459459, chars=[4,59], words=[1,8])),\n",
       " GenePhenoPair(Span(\"GT59\", sentence=388074, chars=[66,69], words=[9,9]), Span(\"annotated to the glycosyltransferase family\", sentence=388074, chars=[22,64], words=[4,8])),\n",
       " GenePhenoPair(Span(\"ETR2\", sentence=448316, chars=[60,63], words=[9,9]), Span(\"support the epistatic results\", sentence=448316, chars=[11,39], words=[2,5])),\n",
       " GenePhenoPair(Span(\"ashh2-1\", sentence=423726, chars=[45,51], words=[9,9]), Span(\"mutant (>1.6-fold change).\", sentence=423726, chars=[122,147], words=[27,33])),\n",
       " GenePhenoPair(Span(\"CAF1.\", sentence=448316, chars=[82,86], words=[13,14]), Span(\"support the epistatic results\", sentence=448316, chars=[11,39], words=[2,5])),\n",
       " GenePhenoPair(Span(\"ATL9\", sentence=450093, chars=[20,23], words=[4,4]), Span(\"lower or higher than in Col-0 (inset Figure 2A\", sentence=450093, chars=[61,106], words=[12,21])),\n",
       " GenePhenoPair(Span(\"cwinv4\", sentence=459499, chars=[164,169], words=[27,27]), Span(\"consistently present in wild-type plants (circled in\", sentence=459499, chars=[91,142], words=[14,21])),\n",
       " GenePhenoPair(Span(\"cwinv4-2\", sentence=459459, chars=[189,196], words=[32,32]), Span(\"a knockdown mutant).\", sentence=459459, chars=[201,220], words=[34,38])),\n",
       " GenePhenoPair(Span(\"GT59\", sentence=388074, chars=[66,69], words=[9,9]), Span(\"ultimate step in the assembly of the oligosaccharide precursor.\", sentence=388074, chars=[284,346], words=[36,45])),\n",
       " GenePhenoPair(Span(\"cwinv4-2\", sentence=459459, chars=[139,146], words=[22,22]), Span(\"higher cell wall invertase activity observed in cwinv4-2\", sentence=459459, chars=[4,59], words=[1,8])),\n",
       " GenePhenoPair(Span(\"cwinv4-2\", sentence=459459, chars=[189,196], words=[32,32]), Span(\"a null mutant, whereas\", sentence=459459, chars=[166,187], words=[27,31])),\n",
       " GenePhenoPair(Span(\"cwinv4-2\", sentence=459459, chars=[189,196], words=[32,32]), Span(\"due to the leaky expression of\", sentence=459459, chars=[96,125], words=[14,19])),\n",
       " GenePhenoPair(Span(\"AtrbohC\", sentence=450377, chars=[179,185], words=[24,24]), Span(\"to wild-type plants.\", sentence=450377, chars=[208,227], words=[30,33])),\n",
       " GenePhenoPair(Span(\"AtCWINV4,\", sentence=459393, chars=[43,51], words=[8,9]), Span(\"the only invertase gene\", sentence=459393, chars=[210,232], words=[39,42])),\n",
       " GenePhenoPair(Span(\"ein2-1\", sentence=447072, chars=[4,9], words=[1,1]), Span(\"order LRs in unstressed and stressed seedlings but no stimulation\", sentence=447072, chars=[99,163], words=[16,25])),\n",
       " GenePhenoPair(Span(\"axe1-5\", sentence=415597, chars=[51,56], words=[7,7]), Span(\"wild-type plants\", sentence=415597, chars=[0,15], words=[0,1])),\n",
       " GenePhenoPair(Span(\"HDA6\", sentence=415608, chars=[20,23], words=[3,3]), Span(\"binds directly to all such genes.\", sentence=415608, chars=[25,57], words=[4,10])),\n",
       " GenePhenoPair(Span(\"aba2-1\", sentence=447072, chars=[55,60], words=[9,9]), Span(\"greater numbers of first order LRs in unstressed and stressed\", sentence=447072, chars=[74,134], words=[12,21])),\n",
       " GenePhenoPair(Span(\"aba2-1\", sentence=447072, chars=[55,60], words=[9,9]), Span(\"mutant with greater numbers of first order LRs in unstressed\", sentence=447072, chars=[62,121], words=[10,19])),\n",
       " GenePhenoPair(Span(\"ATL9\", sentence=450696, chars=[167,170], words=[26,26]), Span(\"performed and hybridized with anti-GFP antibody to\", sentence=450696, chars=[92,141], words=[14,20])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=450882, chars=[124,127], words=[18,18]), Span(\"specifically altered between wild-type plants and\", sentence=450882, chars=[74,122], words=[12,17])),\n",
       " GenePhenoPair(Span(\"aba2-1\", sentence=447072, chars=[55,60], words=[9,9]), Span(\"first order LRs in unstressed and stressed seedlings but no\", sentence=447072, chars=[93,151], words=[15,24])),\n",
       " GenePhenoPair(Span(\"aba2-1\", sentence=447072, chars=[55,60], words=[9,9]), Span(\"unstressed and stressed seedlings but no stimulation of first order\", sentence=447072, chars=[112,178], words=[19,28])),\n",
       " GenePhenoPair(Span(\"ATL9\", sentence=450403, chars=[0,3], words=[0,0]), Span(\"but at half of that observed in untreated wild-type plants\", sentence=450403, chars=[53,110], words=[8,17])),\n",
       " GenePhenoPair(Span(\"ALG10,\", sentence=388095, chars=[22,27], words=[3,4]), Span(\"and acts as a Golgi-to-ER-retrieval signal for these proteins.\", sentence=388095, chars=[270,331], words=[55,64])),\n",
       " GenePhenoPair(Span(\"ACRE1b, ATL17\", sentence=450933, chars=[164,176], words=[26,28]), Span(\"several defense genes\", sentence=450933, chars=[9,29], words=[2,4])),\n",
       " GenePhenoPair(Span(\"ashh2-1\", sentence=422601, chars=[16,22], words=[5,5]), Span(\"plant (left) and wt plant (right)\", sentence=422601, chars=[24,56], words=[6,15])),\n",
       " GenePhenoPair(Span(\"ein2-5)\", sentence=450076, chars=[256,262], words=[53,54]), Span(\"or ET-dependent signaling pathways,\", sentence=450076, chars=[125,159], words=[26,30])),\n",
       " GenePhenoPair(Span(\"AtrbohC\", sentence=450421, chars=[115,121], words=[19,19]), Span(\"in line with previous\", sentence=450421, chars=[18,38], words=[3,6])),\n",
       " GenePhenoPair(Span(\"knf-101.\", sentence=388852, chars=[183,190], words=[33,34]), Span(\"10-day-old seedlings, 16-h light/8-h dark) and hypocotyl formation\", sentence=388852, chars=[68,133], words=[13,22])),\n",
       " GenePhenoPair(Span(\"AtS1P (AtS1P-myc-HDEL)\", sentence=450180, chars=[21,42], words=[4,7]), Span(\"down out of plant extracts with anti-myc agarose beads.\", sentence=450180, chars=[90,144], words=[14,23])),\n",
       " GenePhenoPair(Span(\"ENT1-RNAi\", sentence=431192, chars=[39,47], words=[7,7]), Span(\"increased relative to WT leaves and\", sentence=431192, chars=[62,96], words=[10,15])),\n",
       " GenePhenoPair(Span(\"ashh2-1\", sentence=422577, chars=[23,29], words=[6,6]), Span(\"wt plant with main inflorescence and a shorter auxiliary shoot\", sentence=422577, chars=[78,139], words=[15,24])),\n",
       " GenePhenoPair(Span(\"ashh2-1\", sentence=422577, chars=[23,29], words=[6,6]), Span(\"main inflorescence and a shorter auxiliary shoot (right)\", sentence=422577, chars=[92,147], words=[18,27])),\n",
       " GenePhenoPair(Span(\"MYB99\", sentence=425508, chars=[195,199], words=[33,33]), Span(\"the mutant phenotype\", sentence=425508, chars=[111,130], words=[17,19])),\n",
       " GenePhenoPair(Span(\"Glc1Man9GlcNAc2\", sentence=388360, chars=[201,215], words=[34,34]), Span(\"perform the last step of the lipid-linked precursor biosynthesis.\", sentence=388360, chars=[270,334], words=[47,56])),\n",
       " GenePhenoPair(Span(\"alg10-1\", sentence=388360, chars=[248,254], words=[43,43]), Span(\"perform the last step of the lipid-linked precursor biosynthesis.\", sentence=388360, chars=[270,334], words=[47,56])),\n",
       " GenePhenoPair(Span(\"knf-14\", sentence=388833, chars=[57,62], words=[8,8]), Span(\"deficiency suppresses the severe phenotypes of the\", sentence=388833, chars=[6,55], words=[1,7])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=450913, chars=[127,130], words=[21,21]), Span(\"induced in wild-type plants but\", sentence=450913, chars=[54,84], words=[10,14])),\n",
       " GenePhenoPair(Span(\"Glc2Man9GlcNAc2\", sentence=388360, chars=[146,160], words=[23,23]), Span(\"perform the last step of the lipid-linked precursor biosynthesis.\", sentence=388360, chars=[270,334], words=[47,56])),\n",
       " GenePhenoPair(Span(\"DR5)\", sentence=414470, chars=[21,24], words=[4,5]), Span(\"the wild-type plant (\", sentence=414470, chars=[0,20], words=[0,3])),\n",
       " GenePhenoPair(Span(\"ALG10,\", sentence=388360, chars=[44,49], words=[7,8]), Span(\"perform the last step of the lipid-linked precursor biosynthesis.\", sentence=388360, chars=[270,334], words=[47,56])),\n",
       " GenePhenoPair(Span(\"ALG10-GFP\", sentence=388120, chars=[8,16], words=[2,2]), Span(\"proposed function of the enzyme in the assembly of the\", sentence=388120, chars=[98,151], words=[14,23])),\n",
       " GenePhenoPair(Span(\"35S:ENT1\", sentence=431281, chars=[42,49], words=[10,12]), Span(\"adenosine from preloaded liposomes\", sentence=431281, chars=[334,367], words=[84,87])),\n",
       " GenePhenoPair(Span(\"ALG10-GFP\", sentence=388120, chars=[8,16], words=[2,2]), Span(\"agreement with the proposed function of the enzyme in the\", sentence=388120, chars=[79,135], words=[11,20])),\n",
       " GenePhenoPair(Span(\"1(TGG1)\", sentence=388606, chars=[110,116], words=[12,15]), Span(\"beta-thioglucoside glucohydrolase\", sentence=388606, chars=[76,108], words=[10,11])),\n",
       " GenePhenoPair(Span(\"ATL9\", sentence=450081, chars=[38,41], words=[6,6]), Span(\"lower than in wild type\", sentence=450081, chars=[167,189], words=[28,32])),\n",
       " GenePhenoPair(Span(\"cgl1\", sentence=388625, chars=[4,7], words=[1,1]), Span(\"with correct folding of GnTI and subsequent enzyme activity (\", sentence=388625, chars=[174,234], words=[25,34])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=450187, chars=[49,52], words=[7,7]), Span(\"T-DNA insertional lines,\", sentence=450187, chars=[140,163], words=[20,23])),\n",
       " GenePhenoPair(Span(\"ashh2-1\", sentence=422601, chars=[16,22], words=[5,5]), Span(\"left) and wt plant (right).\", sentence=422601, chars=[31,57], words=[8,16])),\n",
       " GenePhenoPair(Span(\"PEN1, PAD4,\", sentence=450933, chars=[114,124], words=[17,20]), Span(\"several defense genes\", sentence=450933, chars=[9,29], words=[2,4])),\n",
       " GenePhenoPair(Span(\"ASHH2/ashh2-1\", sentence=422672, chars=[218,230], words=[34,35]), Span(\"as no deviation from wt in number of ovules/seeds or\", sentence=422672, chars=[81,132], words=[13,22])),\n",
       " GenePhenoPair(Span(\"ASHH2/ashh2-1\", sentence=422672, chars=[218,230], words=[34,35]), Span(\"embryo and endosperm development as no deviation from wt in\", sentence=422672, chars=[48,106], words=[9,18])),\n",
       " GenePhenoPair(Span(\"ASHH2/ashh2-1\", sentence=422672, chars=[218,230], words=[34,35]), Span(\"redundant both for embryo and endosperm development as no deviation\", sentence=422672, chars=[29,95], words=[6,15])),\n",
       " GenePhenoPair(Span(\"AtS1P\", sentence=449892, chars=[29,33], words=[6,6]), Span(\"mature plant phenotypes\", sentence=449892, chars=[62,84], words=[11,13])),\n",
       " GenePhenoPair(Span(\"jar1;\", sentence=450076, chars=[246,250], words=[49,50]), Span(\"or ET-dependent signaling pathways,\", sentence=450076, chars=[125,159], words=[26,30])),\n",
       " GenePhenoPair(Span(\"ETR1, EIN3, PAD2\", sentence=451007, chars=[85,100], words=[21,25]), Span(\"plants or in mock-treated plants pointing to the\", sentence=451007, chars=[203,250], words=[43,50])),\n",
       " GenePhenoPair(Span(\"alg10-1\", sentence=388507, chars=[238,244], words=[43,43]), Span(\"migrated at the same position as the de-glycosylated wild-type protein\", sentence=388507, chars=[125,194], words=[26,35])),\n",
       " GenePhenoPair(Span(\"knf-101\", sentence=388833, chars=[68,74], words=[10,10]), Span(\"deficiency suppresses the severe phenotypes of the\", sentence=388833, chars=[6,55], words=[1,7])),\n",
       " GenePhenoPair(Span(\"tir1-1, eta3/tir1-1\", sentence=446898, chars=[522,540], words=[109,112]), Span(\"an auxin synthesis mutant, nit1-3 (Normanly et al.\", sentence=446898, chars=[189,238], words=[35,44])),\n",
       " GenePhenoPair(Span(\"MET1\", sentence=415259, chars=[29,32], words=[4,4]), Span(\"required for HDA6-mediated epigenetic gene.\", sentence=415259, chars=[37,79], words=[6,11])),\n",
       " GenePhenoPair(Span(\"ASHH2/ashh2-1\", sentence=422672, chars=[218,230], words=[34,35]), Span(\"no deviation from wt in number of ovules/seeds or phenotype\", sentence=422672, chars=[84,142], words=[14,23])),\n",
       " GenePhenoPair(Span(\"eta3\", sentence=446898, chars=[547,550], words=[115,115]), Span(\"enhances the tir-1-1 phenotype\", sentence=446898, chars=[563,592], words=[117,120])),\n",
       " GenePhenoPair(Span(\"eta3\", sentence=446898, chars=[547,550], words=[115,115]), Span(\"an auxin synthesis mutant, nit1-3 (Normanly et al.\", sentence=446898, chars=[189,238], words=[35,44])),\n",
       " GenePhenoPair(Span(\"axr4-2, aux1-7\", sentence=446898, chars=[419,432], words=[83,85]), Span(\"an auxin synthesis mutant, nit1-3 (Normanly et al.\", sentence=446898, chars=[189,238], words=[35,44])),\n",
       " GenePhenoPair(Span(\"tir1-1, eta3/tir1-1\", sentence=446898, chars=[522,540], words=[109,112]), Span(\"auxin synthesis mutant, nit1-3 (Normanly et al.,\", sentence=446898, chars=[192,239], words=[36,45])),\n",
       " GenePhenoPair(Span(\"etr2-3\", sentence=447808, chars=[35,40], words=[10,10]), Span(\"<0.05, t test\", sentence=447808, chars=[103,115], words=[24,28])),\n",
       " GenePhenoPair(Span(\"ATL9\", sentence=450076, chars=[308,311], words=[63,63]), Span(\"or ET-dependent signaling pathways,\", sentence=450076, chars=[125,159], words=[26,30])),\n",
       " GenePhenoPair(Span(\"SAG101)\", sentence=451007, chars=[111,117], words=[29,30]), Span(\"plants or in mock-treated plants pointing to the\", sentence=451007, chars=[203,250], words=[43,50])),\n",
       " GenePhenoPair(Span(\"promoter:AtbZIP17\", sentence=450028, chars=[132,148], words=[30,32]), Span(\"rescued the salt-sensitive phenotype (\", sentence=450028, chars=[197,234], words=[42,46])),\n",
       " GenePhenoPair(Span(\"ENT1-RNAi\", sentence=431281, chars=[76,84], words=[17,17]), Span(\"adenosine from preloaded liposomes\", sentence=431281, chars=[334,367], words=[84,87])),\n",
       " GenePhenoPair(Span(\"sid2-1, npr1-1;\", sentence=450076, chars=[226,240], words=[43,46]), Span(\"or ET-dependent signaling pathways,\", sentence=450076, chars=[125,159], words=[26,30])),\n",
       " GenePhenoPair(Span(\"chi2\", sentence=450028, chars=[57,60], words=[9,9]), Span(\"rescued the salt-sensitive phenotype (\", sentence=450028, chars=[197,234], words=[42,46])),\n",
       " GenePhenoPair(Span(\"axr1-3, tir1-1, eta3/tir1\", sentence=446898, chars=[514,538], words=[107,111]), Span(\"an auxin synthesis mutant, nit1-3 (Normanly et al.\", sentence=446898, chars=[189,238], words=[35,44])),\n",
       " GenePhenoPair(Span(\"BiP\", sentence=449812, chars=[138,140], words=[23,23]), Span(\"Some of the important components of the ATF6-related\", sentence=449812, chars=[0,51], words=[0,7])),\n",
       " GenePhenoPair(Span(\"ATF6,\", sentence=449812, chars=[113,117], words=[18,19]), Span(\"Some of the important components of the ATF6-related\", sentence=449812, chars=[0,51], words=[0,7])),\n",
       " GenePhenoPair(Span(\"Figure2B;\", sentence=428161, chars=[134,142], words=[22,23]), Span(\"hence derive somaclonal mutation frequencies of between\", sentence=428161, chars=[3,57], words=[1,7])),\n",
       " GenePhenoPair(Span(\"tir1-1, eta3/tir1-1\", sentence=446898, chars=[522,540], words=[109,112]), Span(\"enhances the tir-1-1 phenotype\", sentence=446898, chars=[563,592], words=[117,120])),\n",
       " GenePhenoPair(Span(\"35S:ENT1\", sentence=431281, chars=[146,153], words=[31,33]), Span(\"adenosine from preloaded liposomes\", sentence=431281, chars=[334,367], words=[84,87])),\n",
       " GenePhenoPair(Span(\"alg10-1.\", sentence=388570, chars=[152,159], words=[29,30]), Span(\"Protein extracts from wild-type (wt) and\", sentence=388570, chars=[4,43], words=[3,10])),\n",
       " GenePhenoPair(Span(\"ASHH2/ashh2\", sentence=422805, chars=[55,65], words=[9,9]), Span(\"expected number of male\", sentence=422805, chars=[4,26], words=[1,4])),\n",
       " GenePhenoPair(Span(\"NO3--enhanced\", sentence=446898, chars=[76,88], words=[11,13]), Span(\"enhances the tir-1-1 phenotype\", sentence=446898, chars=[563,592], words=[117,120])),\n",
       " GenePhenoPair(Span(\"NIT1\", sentence=446898, chars=[248,251], words=[49,49]), Span(\"enhances the tir-1-1 phenotype\", sentence=446898, chars=[563,592], words=[117,120])),\n",
       " GenePhenoPair(Span(\"axr1-3, tir1-1, eta3/tir1\", sentence=446898, chars=[514,538], words=[107,111]), Span(\"enhances the tir-1-1 phenotype\", sentence=446898, chars=[563,592], words=[117,120])),\n",
       " GenePhenoPair(Span(\"ASHH2/ashh2-1\", sentence=422672, chars=[218,230], words=[34,35]), Span(\"endosperm development as no deviation from wt in number of\", sentence=422672, chars=[59,116], words=[11,20])),\n",
       " GenePhenoPair(Span(\"ATL9\", sentence=450085, chars=[13,16], words=[2,2]), Span(\"higher in Col-0 plants than in any other line\", sentence=450085, chars=[42,86], words=[7,15])),\n",
       " GenePhenoPair(Span(\"H3K4me3.\", sentence=423751, chars=[141,148], words=[25,26]), Span(\"Representative results of\", sentence=423751, chars=[4,28], words=[3,5])),\n",
       " GenePhenoPair(Span(\"H3K4me3, H3K36me2\", sentence=423751, chars=[119,135], words=[21,23]), Span(\"Representative results of\", sentence=423751, chars=[4,28], words=[3,5])),\n",
       " GenePhenoPair(Span(\"ashh2-1\", sentence=422577, chars=[23,29], words=[6,6]), Span(\"plant with main inflorescence and a shorter auxiliary shoot (\", sentence=422577, chars=[81,141], words=[16,25])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=450966, chars=[131,134], words=[27,27]), Span(\"interested in determining the responses of the known elicitor receptors\", sentence=450966, chars=[13,83], words=[3,12])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=450971, chars=[98,101], words=[16,16]), Span(\"essentially unchanged in the\", sentence=450971, chars=[69,96], words=[12,15])),\n",
       " GenePhenoPair(Span(\"RAR1, SGT1, HSP90\", sentence=451007, chars=[60,76], words=[13,17]), Span(\"plants or in mock-treated plants pointing to the\", sentence=451007, chars=[203,250], words=[43,50])),\n",
       " GenePhenoPair(Span(\"hda6\", sentence=414470, chars=[34,37], words=[8,8]), Span(\"the wild-type plant (\", sentence=414470, chars=[0,20], words=[0,3])),\n",
       " GenePhenoPair(Span(\"ashh2\", sentence=425472, chars=[110,114], words=[25,25]), Span(\"more than two fold in ms1\", sentence=425472, chars=[32,56], words=[5,10])),\n",
       " GenePhenoPair(Span(\"AtDMC1\", sentence=425508, chars=[162,167], words=[27,27]), Span(\"the mutant phenotype\", sentence=425508, chars=[111,130], words=[17,19])),\n",
       " GenePhenoPair(Span(\"etr2-3\", sentence=447695, chars=[74,79], words=[14,14]), Span(\"a higher number of two-branched trichomes (\", sentence=447695, chars=[22,64], words=[4,10])),\n",
       " GenePhenoPair(Span(\"ALG10\", sentence=388171, chars=[21,25], words=[3,3]), Span(\"the mutant phenotype\", sentence=388171, chars=[284,303], words=[41,43])),\n",
       " GenePhenoPair(Span(\"EIN3, PAD2, JAR1\", sentence=451007, chars=[91,106], words=[23,27]), Span(\"plants or in mock-treated plants pointing to the\", sentence=451007, chars=[203,250], words=[43,50])),\n",
       " GenePhenoPair(Span(\"COI1, ETR1, EIN3\", sentence=451007, chars=[79,94], words=[19,23]), Span(\"plants or in mock-treated plants pointing to the\", sentence=451007, chars=[203,250], words=[43,50])),\n",
       " GenePhenoPair(Span(\"ashh2-1\", sentence=423726, chars=[45,51], words=[9,9]), Span(\">2-fold change) and spl/ems\", sentence=423726, chars=[92,118], words=[20,25])),\n",
       " GenePhenoPair(Span(\"ashh2-1\", sentence=422708, chars=[118,124], words=[26,26]), Span(\"Total number of seeds/ovules per silique in selfed wt (\", sentence=422708, chars=[4,58], words=[3,12])),\n",
       " GenePhenoPair(Span(\"atl9-1-3),\", sentence=450244, chars=[121,130], words=[18,20]), Span(\"T-DNA insertional mutants (\", sentence=450244, chars=[94,120], words=[14,17])),\n",
       " GenePhenoPair(Span(\"deltaalg10\", sentence=388171, chars=[223,232], words=[33,33]), Span(\"the mutant phenotype\", sentence=388171, chars=[284,303], words=[41,43])),\n",
       " GenePhenoPair(Span(\"ThSOS1.\", sentence=441748, chars=[87,93], words=[14,15]), Span(\"higher than that of ThSOS1\", sentence=441748, chars=[67,92], words=[10,14])),\n",
       " GenePhenoPair(Span(\"ALG10\", sentence=388171, chars=[65,69], words=[11,11]), Span(\"the mutant phenotype\", sentence=388171, chars=[284,303], words=[41,43])),\n",
       " GenePhenoPair(Span(\"sid2-1.\", sentence=450244, chars=[207,213], words=[36,37]), Span(\"T-DNA insertional mutants (\", sentence=450244, chars=[94,120], words=[14,17])),\n",
       " GenePhenoPair(Span(\"cwinv4\", sentence=459531, chars=[78,83], words=[12,12]), Span(\"the overall ratio of\", sentence=459531, chars=[9,28], words=[2,5])),\n",
       " GenePhenoPair(Span(\"HSP90, COI1, ETR1\", sentence=451007, chars=[72,88], words=[17,21]), Span(\"plants or in mock-treated plants pointing to the\", sentence=451007, chars=[203,250], words=[43,50])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=450971, chars=[98,101], words=[16,16]), Span(\"mutant and wild-type plants.\", sentence=450971, chars=[103,130], words=[17,21])),\n",
       " GenePhenoPair(Span(\"deltaalg10\", sentence=388171, chars=[223,232], words=[33,33]), Span(\"expressed the full-length Arabidopsis\", sentence=388171, chars=[94,130], words=[14,17])),\n",
       " GenePhenoPair(Span(\"AK\", sentence=431374, chars=[0,1], words=[0,0]), Span(\"exhibited an increase in AK activity\", sentence=431374, chars=[81,116], words=[19,24])),\n",
       " GenePhenoPair(Span(\"knf-101.\", sentence=388852, chars=[183,190], words=[33,34]), Span(\"root elongation (10-day-old seedlings, 16-h light/8-h dark)\", sentence=388852, chars=[51,109], words=[10,19])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=451007, chars=[198,201], words=[42,42]), Span(\"and ET-mediated signaling (\", sentence=451007, chars=[33,59], words=[9,12])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=451001, chars=[42,45], words=[8,8]), Span(\"mutant and wild-type\", sentence=451001, chars=[47,66], words=[9,11])),\n",
       " GenePhenoPair(Span(\"alg10-1 knf-101\", sentence=388852, chars=[8,22], words=[4,5]), Span(\"10-day-old seedlings, 16-h light/8-h dark) and hypocotyl formation\", sentence=388852, chars=[68,133], words=[13,22])),\n",
       " GenePhenoPair(Span(\"knf-101.\", sentence=388852, chars=[183,190], words=[33,34]), Span(\"elongation (10-day-old seedlings, 16-h light/8-h dark) and\", sentence=388852, chars=[56,113], words=[11,20])),\n",
       " GenePhenoPair(Span(\"etr2-3\", sentence=447978, chars=[4,9], words=[1,1]), Span(\"crossed with several trichome branching mutants to\", sentence=447978, chars=[22,71], words=[4,10])),\n",
       " GenePhenoPair(Span(\"sid2-1\", sentence=450133, chars=[109,114], words=[21,21]), Span(\"wild-type plants and in the\", sentence=450133, chars=[64,90], words=[12,16])),\n",
       " GenePhenoPair(Span(\"ETR2\", sentence=447978, chars=[107,110], words=[17,17]), Span(\"crossed with several trichome branching mutants to\", sentence=447978, chars=[22,71], words=[4,10])),\n",
       " GenePhenoPair(Span(\"AtrbohF\", sentence=450303, chars=[229,235], words=[38,38]), Span(\"tested the defense phenotype of mutants\", sentence=450303, chars=[155,193], words=[26,31])),\n",
       " GenePhenoPair(Span(\"AtrbohD/F\", sentence=450303, chars=[292,300], words=[49,49]), Span(\"tested the defense phenotype of mutants\", sentence=450303, chars=[155,193], words=[26,31])),\n",
       " GenePhenoPair(Span(\"ashh2-1\", sentence=423726, chars=[45,51], words=[9,9]), Span(\"Number of co-down-regulated genes in the\", sentence=423726, chars=[4,43], words=[3,8])),\n",
       " GenePhenoPair(Span(\"stt3a-2, cgl1 alg3,\", sentence=388597, chars=[107,125], words=[25,29]), Span(\"with anti-horseradish peroxidase (\", sentence=388597, chars=[172,205], words=[38,41])),\n",
       " GenePhenoPair(Span(\"ENT1-RNAi\", sentence=431583, chars=[108,116], words=[23,23]), Span(\"Time-dependent uptake of [\", sentence=431583, chars=[0,25], words=[0,3])),\n",
       " GenePhenoPair(Span(\"RLK1\", sentence=450971, chars=[60,63], words=[10,10]), Span(\"mutant and wild-type plants.\", sentence=450971, chars=[103,130], words=[17,21])),\n",
       " GenePhenoPair(Span(\"cwinv4\", sentence=459503, chars=[108,113], words=[20,20]), Span(\"Conversely, the stomata of wild-type nectaries stained\", sentence=459503, chars=[0,53], words=[0,7])),\n",
       " GenePhenoPair(Span(\"ashh2.\", sentence=425502, chars=[357,362], words=[74,75]), Span(\"non-reproductive tissue [\", sentence=425502, chars=[151,175], words=[27,29])),\n",
       " GenePhenoPair(Span(\"ALG10-GFP\", sentence=388120, chars=[8,16], words=[2,2]), Span(\"displayed co-localization with GnTI-CaaaTS-mRFP\", sentence=388120, chars=[18,64], words=[3,6])),\n",
       " GenePhenoPair(Span(\"ATL9\", sentence=450303, chars=[85,88], words=[13,13]), Span(\"tested the defense phenotype of mutants\", sentence=450303, chars=[155,193], words=[26,31])),\n",
       " GenePhenoPair(Span(\"AtrbohD\", sentence=450303, chars=[217,223], words=[36,36]), Span(\"tested the defense phenotype of mutants\", sentence=450303, chars=[155,193], words=[26,31])),\n",
       " GenePhenoPair(Span(\"ashh2-1\", sentence=422577, chars=[23,29], words=[6,6]), Span(\"inflorescence and a shorter auxiliary shoot (right).\", sentence=422577, chars=[97,148], words=[19,28])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=450882, chars=[124,127], words=[18,18]), Span(\"Several genes with known\", sentence=450882, chars=[0,23], words=[0,3])),\n",
       " GenePhenoPair(Span(\"PDF2.5\", sentence=450913, chars=[34,39], words=[6,7]), Span(\"induced in wild-type plants but\", sentence=450913, chars=[54,84], words=[10,14])),\n",
       " GenePhenoPair(Span(\"ashh2-1\", sentence=422577, chars=[23,29], words=[6,6]), Span(\"Dwarf phenotype\", sentence=422577, chars=[4,18], words=[3,4])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=450933, chars=[92,95], words=[14,14]), Span(\"several defense genes\", sentence=450933, chars=[9,29], words=[2,4])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=450933, chars=[92,95], words=[14,14]), Span(\"two disease resistance-like proteins,\", sentence=450933, chars=[126,162], words=[21,25])),\n",
       " GenePhenoPair(Span(\"PEN1, PAD4,\", sentence=450933, chars=[114,124], words=[17,20]), Span(\"two disease resistance-like proteins,\", sentence=450933, chars=[126,162], words=[21,25])),\n",
       " GenePhenoPair(Span(\"cgl1 stt3a-2, cgl1 alg3\", sentence=388597, chars=[102,124], words=[24,28]), Span(\"with anti-horseradish peroxidase (\", sentence=388597, chars=[172,205], words=[38,41])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=450950, chars=[227,230], words=[36,36]), Span(\"compared the expression of genes\", sentence=450950, chars=[100,131], words=[15,19])),\n",
       " GenePhenoPair(Span(\"atl9\", sentence=450481, chars=[6,9], words=[1,1]), Span(\"interested in determining the timing of\", sentence=450481, chars=[205,243], words=[38,43])),\n",
       " GenePhenoPair(Span(\"SGT1, HSP90, COI1\", sentence=451007, chars=[66,82], words=[15,19]), Span(\"plants or in mock-treated plants pointing to the\", sentence=451007, chars=[203,250], words=[43,50])),\n",
       " GenePhenoPair(Span(\"alg10-1 knf-101\", sentence=388852, chars=[8,22], words=[4,5]), Span(\"elongation (10-day-old seedlings, 16-h light/8-h dark) and\", sentence=388852, chars=[56,113], words=[11,20])),\n",
       " GenePhenoPair(Span(\"AtrbohC\", sentence=450303, chars=[136,142], words=[22,22]), Span(\"tested the defense phenotype of mutants\", sentence=450303, chars=[155,193], words=[26,31])),\n",
       " GenePhenoPair(Span(\"cwinv4\", sentence=459507, chars=[25,30], words=[5,5]), Span(\"similar morphology to wild-type plants (\", sentence=459507, chars=[63,102], words=[13,18])),\n",
       " GenePhenoPair(Span(\"RLK1\", sentence=450971, chars=[60,63], words=[10,10]), Span(\"essentially unchanged in the\", sentence=450971, chars=[69,96], words=[12,15])),\n",
       " GenePhenoPair(Span(\"35S:ENT1\", sentence=431414, chars=[39,46], words=[9,11]), Span(\"Fresh weights of 5-week-old\", sentence=431414, chars=[4,30], words=[3,6])),\n",
       " GenePhenoPair(Span(\"alg10-1.\", sentence=388427, chars=[225,232], words=[33,34]), Span(\"Since the relative amounts of oligomannosidic and complex N-glycans\", sentence=388427, chars=[0,66], words=[0,8])),\n",
       " GenePhenoPair(Span(\"GT59\", sentence=388074, chars=[66,69], words=[9,9]), Span(\"the ultimate step in the assembly of the oligosaccharide precursor\", sentence=388074, chars=[280,345], words=[35,44])),\n",
       " GenePhenoPair(Span(\"axe1-5\", sentence=414488, chars=[0,5], words=[0,0]), Span(\">3 fold\", sentence=414488, chars=[39,45], words=[6,8]))}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.lf_helpers import (\n",
    "    get_left_tokens,\n",
    "    get_between_tokens,\n",
    "    get_right_tokens,\n",
    "    contains_token,\n",
    "    get_doc_candidate_spans,\n",
    "    get_sent_candidate_spans,\n",
    "    get_text_between,\n",
    "    get_text_splits,\n",
    "    get_tagged_text,\n",
    "    is_inverted,\n",
    "    get_tagged_text,\n",
    ")\n",
    "c = sv.get_selected() if sv else list(fp.union(fn))[0]\n",
    "print(c)\n",
    "print(\"\\n\")\n",
    "\n",
    "c.labels\n",
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../snorkel/snorkel/annotations.py:80: RuntimeWarning: invalid value encountered in divide\n",
      "  ac = (tp+tn).astype(float) / (tp+tn+fp+fn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Empirical Acc.</th>\n",
       "      <th>Learned Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_gene</th>\n",
       "      <td>0</td>\n",
       "      <td>0.019520</td>\n",
       "      <td>0.019520</td>\n",
       "      <td>0.018769</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.834598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_mutant</th>\n",
       "      <td>1</td>\n",
       "      <td>0.069069</td>\n",
       "      <td>0.069069</td>\n",
       "      <td>0.068318</td>\n",
       "      <td>10</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.834826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_variant</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.839088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_express</th>\n",
       "      <td>3</td>\n",
       "      <td>0.010511</td>\n",
       "      <td>0.010511</td>\n",
       "      <td>0.010511</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.838128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_JJ</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.839529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_IN</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.839053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_dna</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.839016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_rna</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.839333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_snp</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.839463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_protein</th>\n",
       "      <td>9</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.835974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_LRB</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.838169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_RRB</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.838872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_NNP</th>\n",
       "      <td>12</td>\n",
       "      <td>0.070571</td>\n",
       "      <td>0.070571</td>\n",
       "      <td>0.070571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>66</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.839527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf1</th>\n",
       "      <td>13</td>\n",
       "      <td>0.228228</td>\n",
       "      <td>0.228228</td>\n",
       "      <td>0.227477</td>\n",
       "      <td>29</td>\n",
       "      <td>238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.108614</td>\n",
       "      <td>0.834557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf2</th>\n",
       "      <td>14</td>\n",
       "      <td>0.091592</td>\n",
       "      <td>0.091592</td>\n",
       "      <td>0.091592</td>\n",
       "      <td>37</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.349057</td>\n",
       "      <td>0.834501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf3</th>\n",
       "      <td>15</td>\n",
       "      <td>0.089339</td>\n",
       "      <td>0.089339</td>\n",
       "      <td>0.089339</td>\n",
       "      <td>32</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.301887</td>\n",
       "      <td>0.833702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf4</th>\n",
       "      <td>16</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.838730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf5</th>\n",
       "      <td>17</td>\n",
       "      <td>0.310060</td>\n",
       "      <td>0.310060</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>89</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.261765</td>\n",
       "      <td>0.837220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf6</th>\n",
       "      <td>18</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.838977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf7</th>\n",
       "      <td>19</td>\n",
       "      <td>0.024775</td>\n",
       "      <td>0.024775</td>\n",
       "      <td>0.024775</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.836544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf8</th>\n",
       "      <td>20</td>\n",
       "      <td>0.014264</td>\n",
       "      <td>0.014264</td>\n",
       "      <td>0.014264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.836880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf9</th>\n",
       "      <td>21</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.012763</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.835530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf10</th>\n",
       "      <td>22</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.836085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf11</th>\n",
       "      <td>23</td>\n",
       "      <td>0.044294</td>\n",
       "      <td>0.044294</td>\n",
       "      <td>0.042793</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.834451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf2a</th>\n",
       "      <td>24</td>\n",
       "      <td>0.014264</td>\n",
       "      <td>0.014264</td>\n",
       "      <td>0.014264</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.836565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf12</th>\n",
       "      <td>25</td>\n",
       "      <td>0.098348</td>\n",
       "      <td>0.098348</td>\n",
       "      <td>0.098348</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.836636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf13</th>\n",
       "      <td>26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.839174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf14</th>\n",
       "      <td>27</td>\n",
       "      <td>0.053303</td>\n",
       "      <td>0.053303</td>\n",
       "      <td>0.048799</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.837436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf15</th>\n",
       "      <td>28</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.837750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf16</th>\n",
       "      <td>29</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.006006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.835857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf23</th>\n",
       "      <td>36</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.838737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf24</th>\n",
       "      <td>37</td>\n",
       "      <td>0.873123</td>\n",
       "      <td>0.872372</td>\n",
       "      <td>0.840841</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>829</td>\n",
       "      <td>0.840771</td>\n",
       "      <td>0.850496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf25</th>\n",
       "      <td>38</td>\n",
       "      <td>0.171171</td>\n",
       "      <td>0.171171</td>\n",
       "      <td>0.163664</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>178</td>\n",
       "      <td>0.931937</td>\n",
       "      <td>0.844201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf26</th>\n",
       "      <td>39</td>\n",
       "      <td>0.060811</td>\n",
       "      <td>0.060811</td>\n",
       "      <td>0.060811</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>51</td>\n",
       "      <td>0.671053</td>\n",
       "      <td>0.834113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf27</th>\n",
       "      <td>40</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.838573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf28</th>\n",
       "      <td>41</td>\n",
       "      <td>0.117117</td>\n",
       "      <td>0.117117</td>\n",
       "      <td>0.101351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>118</td>\n",
       "      <td>0.874074</td>\n",
       "      <td>0.840937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf29</th>\n",
       "      <td>42</td>\n",
       "      <td>0.017267</td>\n",
       "      <td>0.017267</td>\n",
       "      <td>0.017267</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.840232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf30</th>\n",
       "      <td>43</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>146</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>0.839164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_gene_dp</th>\n",
       "      <td>44</td>\n",
       "      <td>0.006006</td>\n",
       "      <td>0.006006</td>\n",
       "      <td>0.006006</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.835706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_genotype_dp</th>\n",
       "      <td>45</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.839149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_phenotype_dp</th>\n",
       "      <td>46</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.839228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_mutation</th>\n",
       "      <td>47</td>\n",
       "      <td>0.126126</td>\n",
       "      <td>0.126126</td>\n",
       "      <td>0.123123</td>\n",
       "      <td>45</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.296053</td>\n",
       "      <td>0.836703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_pheno</th>\n",
       "      <td>48</td>\n",
       "      <td>0.048799</td>\n",
       "      <td>0.048799</td>\n",
       "      <td>0.046547</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.836907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_dev_dp</th>\n",
       "      <td>49</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_protein_dp</th>\n",
       "      <td>50</td>\n",
       "      <td>0.004505</td>\n",
       "      <td>0.004505</td>\n",
       "      <td>0.004505</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.835854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_network_dp</th>\n",
       "      <td>51</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.839301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_JJ_dp</th>\n",
       "      <td>52</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.839087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_helpers</th>\n",
       "      <td>53</td>\n",
       "      <td>0.070571</td>\n",
       "      <td>0.070571</td>\n",
       "      <td>0.070571</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.306667</td>\n",
       "      <td>0.834489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_adjwords</th>\n",
       "      <td>54</td>\n",
       "      <td>0.116366</td>\n",
       "      <td>0.116366</td>\n",
       "      <td>0.116366</td>\n",
       "      <td>63</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.833893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_statswords</th>\n",
       "      <td>55</td>\n",
       "      <td>0.116366</td>\n",
       "      <td>0.116366</td>\n",
       "      <td>0.116366</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>78</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.834296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfj_1</th>\n",
       "      <td>56</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.838191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfj_2</th>\n",
       "      <td>57</td>\n",
       "      <td>0.056306</td>\n",
       "      <td>0.056306</td>\n",
       "      <td>0.056306</td>\n",
       "      <td>22</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.360656</td>\n",
       "      <td>0.839306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfj_3</th>\n",
       "      <td>58</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.839564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfj_4</th>\n",
       "      <td>59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.838696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfj_5</th>\n",
       "      <td>60</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.839299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfj_6</th>\n",
       "      <td>61</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.838739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfj_7</th>\n",
       "      <td>62</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.835512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfj_8</th>\n",
       "      <td>63</td>\n",
       "      <td>0.017267</td>\n",
       "      <td>0.017267</td>\n",
       "      <td>0.016517</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.835092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfj_9</th>\n",
       "      <td>64</td>\n",
       "      <td>0.684685</td>\n",
       "      <td>0.684685</td>\n",
       "      <td>0.660661</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>681</td>\n",
       "      <td>0.847015</td>\n",
       "      <td>0.846565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfj_10</th>\n",
       "      <td>65</td>\n",
       "      <td>0.023273</td>\n",
       "      <td>0.023273</td>\n",
       "      <td>0.021772</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.835531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  j  Coverage  Overlaps  Conflicts  TP   FP   FN   TN  \\\n",
       "LF_gene           0  0.019520  0.019520   0.018769   2   24    0    0   \n",
       "LF_mutant         1  0.069069  0.069069   0.068318  10   73    0    0   \n",
       "LF_variant        2  0.000000  0.000000   0.000000   0    0    0    0   \n",
       "LF_express        3  0.010511  0.010511   0.010511   4    9    0    0   \n",
       "LF_JJ             4  0.000000  0.000000   0.000000   0    0    0    0   \n",
       "LF_IN             5  0.000000  0.000000   0.000000   0    0    0    0   \n",
       "LF_dna            6  0.000751  0.000751   0.000751   0    0    0    0   \n",
       "LF_rna            7  0.000000  0.000000   0.000000   0    0    0    0   \n",
       "LF_snp            8  0.000000  0.000000   0.000000   0    0    0    0   \n",
       "LF_protein        9  0.007508  0.007508   0.007508   0    0    2    8   \n",
       "LF_LRB           10  0.000000  0.000000   0.000000   0    0    0    0   \n",
       "LF_RRB           11  0.000000  0.000000   0.000000   0    0    0    0   \n",
       "LF_NNP           12  0.070571  0.070571   0.070571   0    0   21   66   \n",
       "lf1              13  0.228228  0.228228   0.227477  29  238    0    0   \n",
       "lf2              14  0.091592  0.091592   0.091592  37   69    0    0   \n",
       "lf3              15  0.089339  0.089339   0.089339  32   74    0    0   \n",
       "lf4              16  0.001502  0.001502   0.001502   0    2    0    0   \n",
       "lf5              17  0.310060  0.310060   0.305556  89  251    0    0   \n",
       "lf6              18  0.006757  0.006757   0.006757   0    9    0    0   \n",
       "lf7              19  0.024775  0.024775   0.024775   0    0    0   27   \n",
       "lf8              20  0.014264  0.014264   0.014264   0    0    0   16   \n",
       "lf9              21  0.013514  0.013514   0.012763   0    0    1   16   \n",
       "lf10             22  0.007508  0.007508   0.006757   0    0    0   10   \n",
       "lf11             23  0.044294  0.044294   0.042793   0    0    4   39   \n",
       "lf2a             24  0.014264  0.014264   0.014264   9    6    0    0   \n",
       "lf12             25  0.098348  0.098348   0.098348  10  100    0    0   \n",
       "lf13             26  0.000000  0.000000   0.000000   0    0    0    0   \n",
       "lf14             27  0.053303  0.053303   0.048799  22   35    0    0   \n",
       "lf15             28  0.013514  0.013514   0.013514   0    0    5   11   \n",
       "lf16             29  0.006757  0.006757   0.006006   0    0    0    8   \n",
       "...              ..       ...       ...        ...  ..  ...  ...  ...   \n",
       "lf23             36  0.000000  0.000000   0.000000   0    0    0    0   \n",
       "lf24             37  0.873123  0.872372   0.840841   0    0  157  829   \n",
       "lf25             38  0.171171  0.171171   0.163664   0    0   13  178   \n",
       "lf26             39  0.060811  0.060811   0.060811   0    0   25   51   \n",
       "lf27             40  0.000000  0.000000   0.000000   0    0    0    0   \n",
       "lf28             41  0.117117  0.117117   0.101351   0    0   17  118   \n",
       "lf29             42  0.017267  0.017267   0.017267   0    0    6   14   \n",
       "lf30             43  0.144144  0.144144   0.135135   0    0   20  146   \n",
       "LF_gene_dp       44  0.006006  0.006006   0.006006   1    7    0    0   \n",
       "LF_genotype_dp   45  0.000000  0.000000   0.000000   0    0    0    0   \n",
       "LF_phenotype_dp  46  0.003003  0.003003   0.003003   0    0    0    0   \n",
       "LF_mutation      47  0.126126  0.126126   0.123123  45  107    0    0   \n",
       "LF_pheno         48  0.048799  0.048799   0.046547  22   32    0    0   \n",
       "LF_dev_dp        49  0.000000  0.000000   0.000000   0    0    0    0   \n",
       "LF_protein_dp    50  0.004505  0.004505   0.004505   0    0    0    5   \n",
       "LF_network_dp    51  0.000000  0.000000   0.000000   0    0    0    0   \n",
       "LF_JJ_dp         52  0.000000  0.000000   0.000000   0    0    0    0   \n",
       "lf_helpers       53  0.070571  0.070571   0.070571  23   52    0    0   \n",
       "lf_adjwords      54  0.116366  0.116366   0.116366  63   78    0    0   \n",
       "lf_statswords    55  0.116366  0.116366   0.116366   0    0   63   78   \n",
       "lfj_1            56  0.054054  0.054054   0.054054  18   49    0    0   \n",
       "lfj_2            57  0.056306  0.056306   0.056306  22   39    0    0   \n",
       "lfj_3            58  0.000000  0.000000   0.000000   0    0    0    0   \n",
       "lfj_4            59  0.000000  0.000000   0.000000   0    0    0    0   \n",
       "lfj_5            60  0.000000  0.000000   0.000000   0    0    0    0   \n",
       "lfj_6            61  0.003003  0.003003   0.003003   0    0    0    4   \n",
       "lfj_7            62  0.011261  0.011261   0.011261   1   12    0    0   \n",
       "lfj_8            63  0.017267  0.017267   0.016517   5   15    0    0   \n",
       "lfj_9            64  0.684685  0.684685   0.660661   0    0  123  681   \n",
       "lfj_10           65  0.023273  0.023273   0.021772   0    0    5   15   \n",
       "\n",
       "                 Empirical Acc.  Learned Acc.  \n",
       "LF_gene                0.076923      0.834598  \n",
       "LF_mutant              0.120482      0.834826  \n",
       "LF_variant                  NaN      0.839088  \n",
       "LF_express             0.307692      0.838128  \n",
       "LF_JJ                       NaN      0.839529  \n",
       "LF_IN                       NaN      0.839053  \n",
       "LF_dna                      NaN      0.839016  \n",
       "LF_rna                      NaN      0.839333  \n",
       "LF_snp                      NaN      0.839463  \n",
       "LF_protein             0.800000      0.835974  \n",
       "LF_LRB                      NaN      0.838169  \n",
       "LF_RRB                      NaN      0.838872  \n",
       "LF_NNP                 0.758621      0.839527  \n",
       "lf1                    0.108614      0.834557  \n",
       "lf2                    0.349057      0.834501  \n",
       "lf3                    0.301887      0.833702  \n",
       "lf4                    0.000000      0.838730  \n",
       "lf5                    0.261765      0.837220  \n",
       "lf6                    0.000000      0.838977  \n",
       "lf7                    1.000000      0.836544  \n",
       "lf8                    1.000000      0.836880  \n",
       "lf9                    0.941176      0.835530  \n",
       "lf10                   1.000000      0.836085  \n",
       "lf11                   0.906977      0.834451  \n",
       "lf2a                   0.600000      0.836565  \n",
       "lf12                   0.090909      0.836636  \n",
       "lf13                        NaN      0.839174  \n",
       "lf14                   0.385965      0.837436  \n",
       "lf15                   0.687500      0.837750  \n",
       "lf16                   1.000000      0.835857  \n",
       "...                         ...           ...  \n",
       "lf23                        NaN      0.838737  \n",
       "lf24                   0.840771      0.850496  \n",
       "lf25                   0.931937      0.844201  \n",
       "lf26                   0.671053      0.834113  \n",
       "lf27                        NaN      0.838573  \n",
       "lf28                   0.874074      0.840937  \n",
       "lf29                   0.700000      0.840232  \n",
       "lf30                   0.879518      0.839164  \n",
       "LF_gene_dp             0.125000      0.835706  \n",
       "LF_genotype_dp              NaN      0.839149  \n",
       "LF_phenotype_dp             NaN      0.839228  \n",
       "LF_mutation            0.296053      0.836703  \n",
       "LF_pheno               0.407407      0.836907  \n",
       "LF_dev_dp                   NaN      0.835794  \n",
       "LF_protein_dp          1.000000      0.835854  \n",
       "LF_network_dp               NaN      0.839301  \n",
       "LF_JJ_dp                    NaN      0.839087  \n",
       "lf_helpers             0.306667      0.834489  \n",
       "lf_adjwords            0.446809      0.833893  \n",
       "lf_statswords          0.553191      0.834296  \n",
       "lfj_1                  0.268657      0.838191  \n",
       "lfj_2                  0.360656      0.839306  \n",
       "lfj_3                       NaN      0.839564  \n",
       "lfj_4                       NaN      0.838696  \n",
       "lfj_5                       NaN      0.839299  \n",
       "lfj_6                  1.000000      0.838739  \n",
       "lfj_7                  0.076923      0.835512  \n",
       "lfj_8                  0.250000      0.835092  \n",
       "lfj_9                  0.847015      0.846565  \n",
       "lfj_10                 0.750000      0.835531  \n",
       "\n",
       "[66 rows x 10 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_dev.lf_stats(session, L_gold_dev, gen_model.weights.lf_accuracy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatically Creating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import FeatureAnnotator\n",
    "import multiprocessing\n",
    "featurizer = FeatureAnnotator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-da8d9aaa3796>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time F_train = featurizer.apply(split=0, parallelism=multiprocessing.cpu_count())'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mF_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2077\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2080\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/snorkel/snorkel/annotations.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, split, key_group, replace_key_set, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# Run the Annotator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAnnotator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace_key_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplace_key_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcids_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Load the matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/snorkel/snorkel/udf.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, xs, clear, parallelism, progress_bar, count, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_st\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallelism\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/snorkel/snorkel/udf.pyc\u001b[0m in \u001b[0;36mapply_mt\u001b[0;34m(self, xs, parallelism, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQUEUE_TIMEOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                         \u001b[0mout_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/snorkel/snorkel/annotations.pyc\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, y, clear, key_group, replace_key_set, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;31m# Key not in cache or DB; add to both if create_new_keyset = True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mreplace_key_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m                 \u001b[0mkey_id\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_insert_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minserted_primary_key\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/orm/session.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, clause, params, mapper, bind, **kw)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         return self._connection_for_bind(\n\u001b[0;32m-> 1107\u001b[0;31m             bind, close_with_result=True).execute(clause, params or {})\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclause\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, object, *multiparams, **params)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectNotExecutableError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/sql/elements.pyc\u001b[0m in \u001b[0;36m_execute_on_connection\u001b[0;34m(self, connection, multiparams, params)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_on_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_execution\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_clauseelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectNotExecutableError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36m_execute_clauseelement\u001b[0;34m(self, elem, multiparams, params)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0minline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistilled_params\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                 \u001b[0mschema_translate_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema_for_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m                 if not self.schema_for_object.is_default else None)\n\u001b[0m\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         ret = self._execute_context(\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(self, bind, dialect, **kw)\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/sql/elements.pyc\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, default, bind, dialect, **kw)\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m                 \u001b[0mdialect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStrCompileDialect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdialect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdialect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/sql/elements.pyc\u001b[0m in \u001b[0;36m_compiler\u001b[0;34m(self, dialect, **kw)\u001b[0m\n\u001b[1;32m    440\u001b[0m         Dialect.\"\"\"\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatement_compiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdialect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/sql/compiler.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dialect, statement, column_keys, inline, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;31m# dialect.label_length or dialect.max_identifier_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncated_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mCompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdialect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         if (\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/sql/compiler.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dialect, statement, bind, schema_translate_map, compile_kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcan_execute\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execution_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcompile_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     @util.deprecated(\"0.7\", \":class:`.Compiled` objects now compile \"\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/sql/compiler.pyc\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, obj, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiler_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/sql/visitors.pyc\u001b[0m in \u001b[0;36m_compiler_dispatch\u001b[0;34m(self, visitor, **kw)\u001b[0m\n\u001b[1;32m     79\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedCompilationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;31m# The optimization opportunity is lost for this case because the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/sql/compiler.pyc\u001b[0m in \u001b[0;36mvisit_insert\u001b[0;34m(self, insert_stmt, asfrom, **kw)\u001b[0m\n\u001b[1;32m   1966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1967\u001b[0m         crud_params = crud._setup_crud_params(\n\u001b[0;32m-> 1968\u001b[0;31m             self, insert_stmt, crud.ISINSERT, **kw)\n\u001b[0m\u001b[1;32m   1969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcrud_params\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/sql/crud.pyc\u001b[0m in \u001b[0;36m_setup_crud_params\u001b[0;34m(compiler, stmt, local_stmt_type, **kw)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal_stmt_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mISINSERT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mISUPDATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_get_crud_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompiler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshould_restore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/sql/crud.pyc\u001b[0m in \u001b[0;36m_get_crud_params\u001b[0;34m(compiler, stmt, **kw)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mcompiler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0m_getattr_col_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_column_as_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             _col_bind_name, check_columns, values, kw)\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstmt_parameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/sql/crud.pyc\u001b[0m in \u001b[0;36m_scan_cols\u001b[0;34m(compiler, stmt, parameters, _getattr_col_key, _column_as_key, _col_bind_name, check_columns, values, kw)\u001b[0m\n\u001b[1;32m    288\u001b[0m                 _append_param_insert_hasdefault(\n\u001b[1;32m    289\u001b[0m                     \u001b[0mcompiler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimplicit_return_defaults\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                     values, kw)\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/sql/crud.pyc\u001b[0m in \u001b[0;36m_append_param_insert_hasdefault\u001b[0;34m(compiler, stmt, c, implicit_return_defaults, values, kw)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         values.append(\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_create_insert_prefetch_bind_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompiler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         )\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/sql/crud.pyc\u001b[0m in \u001b[0;36m_create_insert_prefetch_bind_param\u001b[0;34m(compiler, c, process, name)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_create_insert_prefetch_bind_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompiler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m     \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_bind_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompiler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m     \u001b[0mcompiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert_prefetch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/sql/crud.pyc\u001b[0m in \u001b[0;36m_create_bind_param\u001b[0;34m(compiler, col, value, process, required, name, **kw)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     bindparam = elements.BindParameter(\n\u001b[0;32m--> 161\u001b[0;31m         name, value, type_=col.type, required=required)\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0mbindparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_crud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CS341_Arabidopsis/venv/local/lib/python2.7/site-packages/sqlalchemy/sql/elements.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, key, value, type_, unique, required, quote, callable_, isoutparam, _compared_to_operator, _compared_to_type)\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misoutparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misoutparam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequired\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequired\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%time F_train = featurizer.apply(split=0, parallelism=multiprocessing.cpu_count())\n",
    "F_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next, we apply the feature set we just got from the training set to the dev and test sets by using apply_existing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "CPU times: user 2min 45s, sys: 6.15 s, total: 2min 51s\n",
      "Wall time: 9min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "F_dev  = featurizer.apply_existing(split=1, parallelism=multiprocessing.cpu_count())\n",
    "F_test = featurizer.apply_existing(split=2, parallelism=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F_train = featurizer.load_matrix(session, split=0)\n",
    "F_dev   = featurizer.load_matrix(session, split=1)\n",
    "F_test  = featurizer.load_matrix(session, split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Discriminative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the training marginals to train a discriminative model that classifies each Candidate as a true or false mention. We'll use a random hyperparameter search, evaluated on the development set labels, to find the best hyperparameters for our model. To run a hyperparameter search, we need labels for a development set. If they aren't already available, we can manually create labels using the Viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import SparseLogisticRegression\n",
    "disc_model = SparseLogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we set up and run the hyperparameter search, training our model with different hyperparamters and picking the best model configuration to keep. We'll set the random seed to maintain reproducibility.\n",
    "Note that we are fitting our model's parameters to the training set generated by our labeling functions, while we are picking hyperparamters with respect to score over the development set labels which we created by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized RandomSearch search of size 20. Search space size = 125.\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning.utils import MentionScorer\n",
    "from snorkel.learning import RandomSearch, ListParameter, RangeParameter\n",
    "\n",
    "# Searching over learning rate\n",
    "rate_param = RangeParameter('lr', 1e-6, 1e-2, step=1, log_base=10)\n",
    "l1_param  = RangeParameter('l1_penalty', 1e-6, 1e-2, step=1, log_base=10)\n",
    "l2_param  = RangeParameter('l2_penalty', 1e-6, 1e-2, step=1, log_base=10)\n",
    "\n",
    "searcher = RandomSearch(session, disc_model, F_train, train_marginals, [rate_param, l1_param, l2_param], n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll load in our dev set labels. We will pick the optimal result from the hyperparameter search by testing against these labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we run the hyperparameter search / train the end extraction model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "[1] Testing lr = 1.00e-02, l1_penalty = 1.00e-03, l2_penalty = 1.00e-04\n",
      "============================================================\n",
      "[SparseLR] lr=0.01 l1=0.001 l2=0.0001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=302  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.22s)\tAvg. loss=0.746804\tNNZ=17217\n",
      "[SparseLR] Epoch 25 (1.14s)\tAvg. loss=0.222985\tNNZ=17217\n",
      "[SparseLR] Epoch 49 (2.00s)\tAvg. loss=0.215898\tNNZ=17217\n",
      "[SparseLR] Training done (2.00s)\n",
      "[SparseLR] Model saved. To load, use name\n",
      "\t\tSparseLR_0\n",
      "============================================================\n",
      "[2] Testing lr = 1.00e-04, l1_penalty = 1.00e-06, l2_penalty = 1.00e-03\n",
      "============================================================\n",
      "[SparseLR] lr=0.0001 l1=1e-06 l2=0.001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=302  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.21s)\tAvg. loss=0.743375\tNNZ=17217\n",
      "[SparseLR] Epoch 25 (1.11s)\tAvg. loss=0.664518\tNNZ=17217\n",
      "[SparseLR] Epoch 49 (1.96s)\tAvg. loss=0.604258\tNNZ=17217\n",
      "[SparseLR] Training done (1.96s)\n",
      "============================================================\n",
      "[3] Testing lr = 1.00e-03, l1_penalty = 1.00e-05, l2_penalty = 1.00e-05\n",
      "============================================================\n",
      "[SparseLR] lr=0.001 l1=1e-05 l2=1e-05\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=302  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.13s)\tAvg. loss=0.731438\tNNZ=17217\n",
      "[SparseLR] Epoch 25 (1.08s)\tAvg. loss=0.363584\tNNZ=17217\n",
      "[SparseLR] Epoch 49 (1.97s)\tAvg. loss=0.283983\tNNZ=17217\n",
      "[SparseLR] Training done (1.97s)\n",
      "============================================================\n",
      "[4] Testing lr = 1.00e-03, l1_penalty = 1.00e-06, l2_penalty = 1.00e-03\n",
      "============================================================\n",
      "[SparseLR] lr=0.001 l1=1e-06 l2=0.001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=302  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.10s)\tAvg. loss=0.733366\tNNZ=17217\n",
      "[SparseLR] Epoch 25 (1.00s)\tAvg. loss=0.373808\tNNZ=17217\n",
      "[SparseLR] Epoch 49 (1.88s)\tAvg. loss=0.295390\tNNZ=17217\n",
      "[SparseLR] Training done (1.88s)\n",
      "============================================================\n",
      "[5] Testing lr = 1.00e-02, l1_penalty = 1.00e-04, l2_penalty = 1.00e-05\n",
      "============================================================\n",
      "[SparseLR] lr=0.01 l1=0.0001 l2=1e-05\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=302  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.10s)\tAvg. loss=0.725027\tNNZ=17217\n",
      "[SparseLR] Epoch 25 (1.02s)\tAvg. loss=0.203916\tNNZ=17217\n",
      "[SparseLR] Epoch 49 (1.87s)\tAvg. loss=0.197835\tNNZ=17217\n",
      "[SparseLR] Training done (1.87s)\n",
      "============================================================\n",
      "[6] Testing lr = 1.00e-06, l1_penalty = 1.00e-03, l2_penalty = 1.00e-05\n",
      "============================================================\n",
      "[SparseLR] lr=1e-06 l1=0.001 l2=1e-05\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=302  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.12s)\tAvg. loss=0.763970\tNNZ=17217\n",
      "[SparseLR] Epoch 25 (1.03s)\tAvg. loss=0.762968\tNNZ=17217\n",
      "[SparseLR] Epoch 49 (1.98s)\tAvg. loss=0.762013\tNNZ=17217\n",
      "[SparseLR] Training done (1.98s)\n",
      "============================================================\n",
      "[7] Testing lr = 1.00e-06, l1_penalty = 1.00e-03, l2_penalty = 1.00e-02\n",
      "============================================================\n",
      "[SparseLR] lr=1e-06 l1=0.001 l2=0.01\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=302  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.12s)\tAvg. loss=0.763347\tNNZ=17217\n",
      "[SparseLR] Epoch 25 (1.01s)\tAvg. loss=0.762420\tNNZ=17217\n",
      "[SparseLR] Epoch 49 (1.92s)\tAvg. loss=0.761535\tNNZ=17217\n",
      "[SparseLR] Training done (1.92s)\n",
      "[SparseLR] Model saved. To load, use name\n",
      "\t\tSparseLR_6\n",
      "============================================================\n",
      "[8] Testing lr = 1.00e-02, l1_penalty = 1.00e-05, l2_penalty = 1.00e-02\n",
      "============================================================\n",
      "[SparseLR] lr=0.01 l1=1e-05 l2=0.01\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=302  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.19s)\tAvg. loss=0.737488\tNNZ=17217\n",
      "[SparseLR] Epoch 25 (1.14s)\tAvg. loss=0.220153\tNNZ=17217\n",
      "[SparseLR] Epoch 49 (2.00s)\tAvg. loss=0.215134\tNNZ=17217\n",
      "[SparseLR] Training done (2.00s)\n",
      "============================================================\n",
      "[9] Testing lr = 1.00e-04, l1_penalty = 1.00e-02, l2_penalty = 1.00e-06\n",
      "============================================================\n",
      "[SparseLR] lr=0.0001 l1=0.01 l2=1e-06\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=302  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.15s)\tAvg. loss=0.975864\tNNZ=17217\n",
      "[SparseLR] Epoch 25 (1.12s)\tAvg. loss=0.875285\tNNZ=17217\n",
      "[SparseLR] Epoch 49 (2.04s)\tAvg. loss=0.799437\tNNZ=17217\n",
      "[SparseLR] Training done (2.04s)\n",
      "============================================================\n",
      "[10] Testing lr = 1.00e-06, l1_penalty = 1.00e-05, l2_penalty = 1.00e-03\n",
      "============================================================\n",
      "[SparseLR] lr=1e-06 l1=1e-05 l2=0.001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=302  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.15s)\tAvg. loss=0.749968\tNNZ=17217\n",
      "[SparseLR] Epoch 25 (1.20s)\tAvg. loss=0.749087\tNNZ=17217\n",
      "[SparseLR] Epoch 49 (2.10s)\tAvg. loss=0.748246\tNNZ=17217\n",
      "[SparseLR] Training done (2.10s)\n",
      "============================================================\n",
      "[11] Testing lr = 1.00e-04, l1_penalty = 1.00e-02, l2_penalty = 1.00e-04\n",
      "============================================================\n",
      "[SparseLR] lr=0.0001 l1=0.01 l2=0.0001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=302  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.17s)\tAvg. loss=0.940309\tNNZ=17217\n",
      "[SparseLR] Epoch 25 (1.12s)\tAvg. loss=0.848682\tNNZ=17217\n",
      "[SparseLR] Epoch 49 (2.02s)\tAvg. loss=0.778449\tNNZ=17217\n",
      "[SparseLR] Training done (2.02s)\n",
      "============================================================\n",
      "[12] Testing lr = 1.00e-03, l1_penalty = 1.00e-06, l2_penalty = 1.00e-03\n",
      "============================================================\n",
      "[SparseLR] lr=0.001 l1=1e-06 l2=0.001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=302  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.21s)\tAvg. loss=0.743996\tNNZ=17217\n",
      "[SparseLR] Epoch 25 (1.13s)\tAvg. loss=0.374960\tNNZ=17217\n",
      "[SparseLR] Epoch 49 (2.03s)\tAvg. loss=0.296599\tNNZ=17217\n",
      "[SparseLR] Training done (2.03s)\n",
      "============================================================\n",
      "[13] Testing lr = 1.00e-04, l1_penalty = 1.00e-04, l2_penalty = 1.00e-05\n",
      "============================================================\n",
      "[SparseLR] lr=0.0001 l1=0.0001 l2=1e-05\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=302  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.19s)\tAvg. loss=0.821351\tNNZ=17217\n",
      "[SparseLR] Epoch 25 (1.17s)\tAvg. loss=0.727969\tNNZ=17217\n",
      "[SparseLR] Epoch 49 (2.09s)\tAvg. loss=0.656210\tNNZ=17217\n",
      "[SparseLR] Training done (2.09s)\n",
      "============================================================\n",
      "[14] Testing lr = 1.00e-03, l1_penalty = 1.00e-05, l2_penalty = 1.00e-04\n",
      "============================================================\n",
      "[SparseLR] lr=0.001 l1=1e-05 l2=0.0001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=302  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.21s)\tAvg. loss=0.795967\tNNZ=17217\n",
      "[SparseLR] Epoch 25 (1.10s)\tAvg. loss=0.372633\tNNZ=17217\n",
      "[SparseLR] Epoch 49 (1.94s)\tAvg. loss=0.291247\tNNZ=17217\n",
      "[SparseLR] Training done (1.94s)\n",
      "============================================================\n",
      "[15] Testing lr = 1.00e-04, l1_penalty = 1.00e-02, l2_penalty = 1.00e-05\n",
      "============================================================\n",
      "[SparseLR] lr=0.0001 l1=0.01 l2=1e-05\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=302  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.22s)\tAvg. loss=0.950242\tNNZ=17217\n",
      "[SparseLR] Epoch 25 (1.17s)\tAvg. loss=0.853536\tNNZ=17217\n",
      "[SparseLR] Epoch 49 (2.07s)\tAvg. loss=0.777524\tNNZ=17217\n",
      "[SparseLR] Training done (2.07s)\n",
      "============================================================\n",
      "[16] Testing lr = 1.00e-05, l1_penalty = 1.00e-06, l2_penalty = 1.00e-04\n",
      "============================================================\n",
      "[SparseLR] lr=1e-05 l1=1e-06 l2=0.0001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=302  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.23s)\tAvg. loss=0.780900\tNNZ=17217\n",
      "[SparseLR] Epoch 25 (1.11s)\tAvg. loss=0.770263\tNNZ=17217\n",
      "[SparseLR] Epoch 49 (1.99s)\tAvg. loss=0.760326\tNNZ=17217\n",
      "[SparseLR] Training done (1.99s)\n",
      "============================================================\n",
      "[17] Testing lr = 1.00e-06, l1_penalty = 1.00e-02, l2_penalty = 1.00e-03\n",
      "============================================================\n",
      "[SparseLR] lr=1e-06 l1=0.01 l2=0.001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=302  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.24s)\tAvg. loss=0.932090\tNNZ=17217\n",
      "[SparseLR] Epoch 25 (1.15s)\tAvg. loss=0.930984\tNNZ=17217\n",
      "[SparseLR] Epoch 49 (2.02s)\tAvg. loss=0.929927\tNNZ=17217\n",
      "[SparseLR] Training done (2.02s)\n",
      "============================================================\n",
      "[18] Testing lr = 1.00e-02, l1_penalty = 1.00e-05, l2_penalty = 1.00e-06\n",
      "============================================================\n",
      "[SparseLR] lr=0.01 l1=1e-05 l2=1e-06\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=302  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.28s)\tAvg. loss=0.730220\tNNZ=17217\n",
      "[SparseLR] Epoch 25 (1.22s)\tAvg. loss=0.196750\tNNZ=17217\n",
      "[SparseLR] Epoch 49 (2.12s)\tAvg. loss=0.190840\tNNZ=17217\n",
      "[SparseLR] Training done (2.12s)\n",
      "============================================================\n",
      "[19] Testing lr = 1.00e-05, l1_penalty = 1.00e-02, l2_penalty = 1.00e-06\n",
      "============================================================\n",
      "[SparseLR] lr=1e-05 l1=0.01 l2=1e-06\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=302  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.36s)\tAvg. loss=0.949832\tNNZ=17217\n",
      "[SparseLR] Epoch 25 (1.78s)\tAvg. loss=0.939677\tNNZ=17217\n",
      "[SparseLR] Epoch 49 (2.78s)\tAvg. loss=0.930168\tNNZ=17217\n",
      "[SparseLR] Training done (2.78s)\n",
      "============================================================\n",
      "[20] Testing lr = 1.00e-02, l1_penalty = 1.00e-05, l2_penalty = 1.00e-04\n",
      "============================================================\n",
      "[SparseLR] lr=0.01 l1=1e-05 l2=0.0001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=302  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.32s)\tAvg. loss=0.698077\tNNZ=17217\n",
      "[SparseLR] Epoch 25 (1.40s)\tAvg. loss=0.198065\tNNZ=17217\n",
      "[SparseLR] Epoch 49 (2.34s)\tAvg. loss=0.191936\tNNZ=17217\n",
      "[SparseLR] Training done (2.34s)\n",
      "INFO:tensorflow:Restoring parameters from ./SparseLR_6-0\n",
      "[SparseLR] Loaded model <SparseLR_6>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>l1_penalty</th>\n",
       "      <th>l2_penalty</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>Rec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.195531</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.289256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.172376</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.285192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.166172</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.162085</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.274920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.162626</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.273113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.161706</td>\n",
       "      <td>0.862434</td>\n",
       "      <td>0.272348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.160160</td>\n",
       "      <td>0.846561</td>\n",
       "      <td>0.269360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.155819</td>\n",
       "      <td>0.835979</td>\n",
       "      <td>0.262677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.154762</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.260652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.156319</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.258478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.151136</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.248831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.143634</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>0.238267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.148541</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.237540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.140316</td>\n",
       "      <td>0.751323</td>\n",
       "      <td>0.236470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.174263</td>\n",
       "      <td>0.343915</td>\n",
       "      <td>0.231317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.131936</td>\n",
       "      <td>0.566138</td>\n",
       "      <td>0.214000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.146825</td>\n",
       "      <td>0.391534</td>\n",
       "      <td>0.213564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.146881</td>\n",
       "      <td>0.386243</td>\n",
       "      <td>0.212828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.130641</td>\n",
       "      <td>0.291005</td>\n",
       "      <td>0.180328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.137566</td>\n",
       "      <td>0.106557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lr  l1_penalty  l2_penalty     Prec.      Rec.        F1\n",
       "6   0.000001    0.001000    0.010000  0.195531  0.555556  0.289256\n",
       "9   0.000001    0.000010    0.001000  0.172376  0.825397  0.285192\n",
       "7   0.010000    0.000010    0.010000  0.166172  0.888889  0.280000\n",
       "0   0.010000    0.001000    0.000100  0.162085  0.904762  0.274920\n",
       "4   0.010000    0.000100    0.000010  0.162626  0.851852  0.273113\n",
       "19  0.010000    0.000010    0.000100  0.161706  0.862434  0.272348\n",
       "11  0.001000    0.000001    0.001000  0.160160  0.846561  0.269360\n",
       "17  0.010000    0.000010    0.000001  0.155819  0.835979  0.262677\n",
       "14  0.000100    0.010000    0.000010  0.154762  0.825397  0.260652\n",
       "13  0.001000    0.000010    0.000100  0.156319  0.746032  0.258478\n",
       "10  0.000100    0.010000    0.000100  0.151136  0.703704  0.248831\n",
       "2   0.001000    0.000010    0.000010  0.143634  0.698413  0.238267\n",
       "18  0.000010    0.010000    0.000001  0.148541  0.592593  0.237540\n",
       "3   0.001000    0.000001    0.001000  0.140316  0.751323  0.236470\n",
       "5   0.000001    0.001000    0.000010  0.174263  0.343915  0.231317\n",
       "1   0.000100    0.000001    0.001000  0.131936  0.566138  0.214000\n",
       "15  0.000010    0.000001    0.000100  0.146825  0.391534  0.213564\n",
       "16  0.000001    0.010000    0.001000  0.146881  0.386243  0.212828\n",
       "12  0.000100    0.000100    0.000010  0.130641  0.291005  0.180328\n",
       "8   0.000100    0.010000    0.000001  0.086957  0.137566  0.106557"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1701)\n",
    "searcher.fit(F_dev, L_gold_dev, n_epochs=50, rebalance=0.5, print_freq=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note that to train a model without tuning any hyperparameters (at your own risk) just use the train method of the discriminative model. For instance, to train with 20 epochs and a learning rate of 0.001, you could run:\n",
    "disc_model.train(F_train, train_marginals, n_epochs=20, lr=0.001)\n",
    "We can analyze the learned model by examining the weights. For example, we can print out the features with the highest weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: TDL_INV_LEMMA:LEFT-OF-MENTION[methylesterification pectin in]         Weight: -0.386015\n",
      "Feature: TDL_LEMMA:RIGHT-OF-MENTION[concentration lower figure]                Weight: -0.384107\n",
      "Feature: TDL_LEMMA:SEQ-BETWEEN[wild-type , but]                                Weight: 0.368519\n",
      "Feature: TDL_INV_LEMMA:PARENTS-OF-BETWEEN-MENTION-and-MENTION[None indicate reduce]Weight: -0.362101\n",
      "Feature: TDL_INV_LEMMA:RIGHT-OF-MENTION[these line transgenic]                 Weight: 0.361407\n"
     ]
    }
   ],
   "source": [
    "w, _ = disc_model.get_weights()\n",
    "largest_idxs = reversed(np.argsort(np.abs(w))[-5:])\n",
    "for i in largest_idxs:\n",
    "    print 'Feature: {0: <70}Weight: {1:.6f}'.format(F_train.get_key(session, i).name, w[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this last section of the tutorial, we'll get the score we've been after: the performance of the extraction model on the blind test set (split 2). First, we load the test set labels and gold candidates we made in Part III."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we score using the discriminative model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.36\n",
      "Neg. class accuracy: 0.617\n",
      "Precision            0.102\n",
      "Recall               0.36\n",
      "F1                   0.158\n",
      "----------------------------------------\n",
      "TP: 67 | FP: 593 | TN: 956 | FN: 119\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = disc_model.score(session, F_test, L_gold_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note that if this is the final test set that you will be reporting final numbers on, to avoid biasing results you should not inspect results. However you can run the model on your development set and, as we did in the previous part with the generative labeling function model, inspect examples to do error analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the intro tutorial, we automatically featurized the candidates and trained a linear model over these features. Here, we'll train a more complicated model for relation extraction: an LSTM network. You can read more about LSTMs here or here. An LSTM is a type of recurrent neural network and automatically generates a numerical representation for the candidate based on the sentence text, so no need for featurizing explicitly as in the intro tutorial. LSTMs take longer to train, and Snorkel doesn't currently support hyperparameter searches for them. We'll train a single model here, but feel free to try out other parameter sets. Just make sure to use the development set - and not the test set - for model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = session.query(GenePhenoPair).filter(GenePhenoPair.split == 0).all()\n",
    "dev = session.query(GenePhenoPair).filter(GenePhenoPair.split == 0).all()\n",
    "test = session.query(GenePhenoPair).filter(GenePhenoPair.split == 2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dev_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-8d6a52790c61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mlstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1701\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_marginals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_candidates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrain_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dev_labels' is not defined"
     ]
    }
   ],
   "source": [
    "from snorkel.contrib.rnn import reRNN\n",
    "\n",
    "train_kwargs = {\n",
    "    'lr':         0.01,\n",
    "    'dim':        100,\n",
    "    'n_epochs':   50,\n",
    "    'dropout':    0.5,\n",
    "    'rebalance':  0.25,\n",
    "    'print_freq': 5\n",
    "}\n",
    "\n",
    "lstm = reRNN(seed=1701, n_threads=None)\n",
    "lstm.train(train, train_marginals, dev_candidates=dev, dev_labels=dev_labels, **train_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thomas's Code\n",
    "## `DDLiteModel` objects and feature generation\n",
    "We'll then create a `DDLiteModel` object for our extracted gene candidates. This lets us iterate with our model and labeling functions. Since `Entities` object defines a feature generation method, features are automatically created when we initialize a `DDLiteModel` object. These are generic features from the NLP markup and dependency tree in the neighborhood of the mention. Alternatively, you can define a custom feature set as a NumPy array or a Scipy sparse matrix. Here, we pickle our feature matrix so we don't have to recompute it in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 30533 features for each of 1968 mentions\n"
     ]
    }
   ],
   "source": [
    "feats = None\n",
    "\n",
    "pkl_f = 'gene_tag_example/gene_tag_feats_v1.pkl'\n",
    "try:\n",
    "    with open(pkl_f, 'rb') as f:\n",
    "        feats = cPickle.load(f)\n",
    "except:\n",
    "    %time E.extract_features()\n",
    "    with open(pkl_f, 'w+') as f:\n",
    "        cPickle.dump(E.feats, f)\n",
    "\n",
    "DDL = DDLiteModel(E, feats)\n",
    "print \"Extracted {} features for each of {} mentions\".format(DDL.num_feats(), DDL.num_candidates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a blind, gold standard ground truth set to evaluate our predictions. We can add these by using the uids for the candidates we want, and align these with a value of 1 for positive or a value of -1 for negative. We'll load in a set now using `DDL.update_gt()` and set it as the holdout. We'll assign half of the holdout to a validation set for parameter tuning, and the other half to a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../ddlite.py:602: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  self.dev1 = idxs[ : np.floor(dev_split * len(idxs))]\n",
      "../ddlite.py:603: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  self.dev2 = idxs[np.floor(dev_split * len(idxs)) : ]\n",
      "../ddlite.py:594: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  self.validation = h[ : np.floor(validation_frac * len(h))]\n",
      "../ddlite.py:595: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  self.test = h[np.floor(validation_frac * len(h)) : ]\n"
     ]
    }
   ],
   "source": [
    "with open('gene_tag_example/gt/uids.pkl', 'rb') as f:\n",
    "    uids = cPickle.load(f)\n",
    "with open('gene_tag_example/gt/gt.pkl', 'rb') as f:\n",
    "    gt = cPickle.load(f)\n",
    "    \n",
    "DDL.update_gt(gt[:50], uids=uids[:50])\n",
    "DDL.set_holdout(validation_frac=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a ground truth set with MindTagger\n",
    "In order to evaluate our labeling functions and learning results, we'll create a small set of ground truth labels for some candidates using [Mindtagger](http://deepdive.stanford.edu/labeling). This will highlight each candidate in the sentence in which it appears. We set the response to yes if it is a mention of gene, and no otherwise. If you aren't sure, you can abstain from labeling. In a real application, we would likely want to tag more than 20 candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making sure MindTagger is installed. Hang on!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"1200\"\n",
       "            src=\"http://Sen.local:8113/#/mindtagger/430d959c331c0d86\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x111143fd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DDL.open_mindtagger(num_sample=100, width='100%', height=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll retrieve the tags and add them to our `DDLiteModel`. We can also use a previously defined Mindtagger label set, similar to how we added our gold labels (this time, we'll use indexes instead of uids). These labels are used for evaluating our labeling functions against the *development set*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DDL.add_mindtagger_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DDL.update_gt(gt[50:], uids=uids[50:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing labeling functions\n",
    "We'll use data programming to learn a logistic regression model which will predict the probability of a candidate entity being a true gene mention. Since our training data is not manually labeled, we'll generate many (potentially noisy) labels as a surrogate for precise, manual labels. Feature extraction and model learning are very simple in ddlite. Writing labeling functions is where the real artistry comes in. One of ddlite's goals is to enable rapid prototyping, debugging, and experimenting with labeling functions. These can be used either to create a simple standalone app, or to plug into DeepDive. Labeling functions, or LFs, are functions that take an `Candidate` object. They must return 1 (for a positive label), 0 (for abstaining), or -1 (for a negative example). For now, we'll write a few simple LFs to get started:\n",
    "\n",
    "* The first, second, and third LFs return a positive label if the lemma \"gene\", \"mutant\", or \"express\" appear in a window around the mention, respectively\n",
    "* The third LF returns a positive label if the dependency parent of any of the words in the mention is \"mutation\", and abstains otherwise\n",
    "* The fourth, fifth, and sixth LF return a negative label if the mention candidate contains \"DNA\", \"RNA\", or \"SNP\" respectively (these are common uppercase nouns which are not genes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LF_gene(m):\n",
    "    return 1 if ('gene' in m.post_window('lemmas')) or ('gene' in m.pre_window('lemmas')) else 0\n",
    "def LF_gene_dp(m):\n",
    "    return 1 if 'gene' in [m.lemmas[m.dep_parents[i] - 1] for i in m.idxs] else 0\n",
    "def LF_genotype_dp(m):\n",
    "    return 1 if 'genotype' in [m.lemmas[m.dep_parents[i] - 1] for i in m.idxs] else 0\n",
    "def LF_mutant(m):\n",
    "    return 1 if ('mutant' in m.post_window('lemmas')) or ('mutant' in m.pre_window('lemmas')) else 0\n",
    "def LF_variant(m):\n",
    "    return 1 if ('variant' in m.post_window('lemmas')) or ('variant' in m.pre_window('lemmas')) else 0\n",
    "def LF_express(m):\n",
    "    return 1 if ('express' in m.post_window('lemmas')) or ('express' in m.pre_window('lemmas')) else 0\n",
    "def LF_mutation(m):\n",
    "    return 1 if 'mutation' in [m.lemmas[m.dep_parents[i] - 1] for i in m.idxs] else 0\n",
    "def LF_JJ(m):\n",
    "    return 1 if 'JJ' in m.post_window('poses') else 0\n",
    "def LF_IN(m):\n",
    "    return 1 if 'IN' in m.pre_window('poses', 1) else 0\n",
    "\n",
    "def LF_dna(m):\n",
    "    return -1 if 'DNA' in m.mention('words') else 0\n",
    "def LF_rna(m):\n",
    "    return -1 if 'RNA' in m.mention('words') else 0\n",
    "def LF_snp(m):\n",
    "    return -1 if 'SNP' in m.mention('words') else 0\n",
    "def LF_protein(m):\n",
    "    return -1 if 'protein' in m.pre_window('lemmas') else 0\n",
    "def LF_LRB(m):\n",
    "    return -1 if '-LRB-' in m.post_window('poses', 1) else 0\n",
    "def LF_RRB(m):\n",
    "    return -1 if '-RRB-' in m.post_window('poses', 1) else 0\n",
    "def LF_dev_dp(m):\n",
    "    return -1 if 'development' in [m.lemmas[m.dep_parents[i] - 1] for i in m.idxs] else 0\n",
    "def LF_protein_dp(m):\n",
    "    return -1 if 'protein' in [m.lemmas[m.dep_parents[i] - 1] for i in m.idxs] else 0\n",
    "def LF_network_dp(m):\n",
    "    return -1 if 'network' in [m.lemmas[m.dep_parents[i] - 1] for i in m.idxs] else 0\n",
    "def LF_JJ_dp(m):\n",
    "    return -1 if 'JJ' in [m.poses[m.dep_parents[i] - 1] for i in m.idxs] else 0\n",
    "def LF_NNP(m):\n",
    "    return -1 if 'NNP' in m.mention('poses') else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our intuition is that the few simple LFs given above won't yield a good model. We'll see this more concretely when we evaluate the labeling functions. For now, let's leave them as is. After writing the LFs, we simply collect them and apply them to mentions. If we define more LFs later, we can apply them incrementally or overwrite all the LFs so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LFs = [LF_JJ, LF_JJ_dp, LF_NNP, LF_RRB, LF_dev_dp, LF_dna, LF_express, LF_gene, LF_gene_dp,\n",
    "       LF_genotype_dp, LF_mutant, LF_mutation, LF_network_dp, LF_protein, LF_protein_dp,\n",
    "       LF_rna, LF_snp, LF_variant, LF_IN, LF_LRB]\n",
    "DDL.apply_lfs(LFs, clear=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use ddlite's LF assessment utilities to debug and analyze our LFs before running inference. First, we'll generate summary plots which show the following:\n",
    "\n",
    "* Do the LFs cover the data well or do we have many candidates for which all of the LFs abstained?\n",
    "* Is there overlap between the LFs? Do many return positive or negative labels for the same candidate?\n",
    "* Do the LFs conflict with each other? Do candidates tend to have many of one type of label, or a mix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LF stats on training set\n",
      "Coverage:\t69.135%\n",
      "Overlap:\t30.083%\n",
      "Conflict:\t15.276%\n"
     ]
    }
   ],
   "source": [
    "DDL.print_lf_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABEkAAAGJCAYAAAB2NW1eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111461550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DDL.plot_lf_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we may expect, the few LFs do not cover the data very well. We can switch to an LF view of these measures and show tables for the LFs with the most conflict, lowest coverage, and lowest empirical accuracy as compared to the development set labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td><b>Labeling function</b></td><td><b>Percent candidates where LF has conflict</b></td></tr><tr><td>LF_IN</td><td>7.98%</td></tr><tr><td>LF_NNP</td><td>6.52%</td></tr><tr><td>LF_JJ</td><td>5.27%</td></tr></table>"
      ],
      "text/plain": [
       "DictTable([('LF_IN', ['7.98%']),\n",
       "           ('LF_NNP', ['6.52%']),\n",
       "           ('LF_JJ', ['5.27%']),\n",
       "           ('LF_RRB', ['3.49%']),\n",
       "           ('LF_gene', ['2.76%']),\n",
       "           ('LF_LRB', ['2.45%']),\n",
       "           ('LF_JJ_dp', ['1.46%']),\n",
       "           ('LF_gene_dp', ['1.15%']),\n",
       "           ('LF_mutation', ['0.99%']),\n",
       "           ('LF_dna', ['0.63%']),\n",
       "           ('LF_protein_dp', ['0.63%']),\n",
       "           ('LF_mutant', ['0.57%']),\n",
       "           ('LF_variant', ['0.52%']),\n",
       "           ('LF_snp', ['0.36%']),\n",
       "           ('LF_express', ['0.31%']),\n",
       "           ('LF_rna', ['0.31%']),\n",
       "           ('LF_dev_dp', ['0.21%']),\n",
       "           ('LF_protein', ['0.21%']),\n",
       "           ('LF_genotype_dp', ['0.10%']),\n",
       "           ('LF_network_dp', ['0.00%'])])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DDL.top_conflict_lfs(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td><b>Labeling function</b></td><td><b>Candidate coverage</b></td></tr><tr><td>LF_network_dp</td><td>0.10%</td></tr><tr><td>LF_dev_dp</td><td>0.21%</td></tr><tr><td>LF_express</td><td>0.78%</td></tr></table>"
      ],
      "text/plain": [
       "DictTable([('LF_network_dp', ['0.10%']),\n",
       "           ('LF_dev_dp', ['0.21%']),\n",
       "           ('LF_express', ['0.78%']),\n",
       "           ('LF_rna', ['0.89%']),\n",
       "           ('LF_protein', ['0.94%']),\n",
       "           ('LF_genotype_dp', ['0.99%']),\n",
       "           ('LF_mutant', ['1.25%']),\n",
       "           ('LF_snp', ['1.36%']),\n",
       "           ('LF_protein_dp', ['1.51%']),\n",
       "           ('LF_dna', ['1.98%']),\n",
       "           ('LF_NNP', ['10.74%']),\n",
       "           ('LF_RRB', ['13.50%']),\n",
       "           ('LF_JJ', ['16.48%']),\n",
       "           ('LF_JJ_dp', ['2.61%']),\n",
       "           ('LF_IN', ['26.23%']),\n",
       "           ('LF_variant', ['3.18%']),\n",
       "           ('LF_LRB', ['4.59%']),\n",
       "           ('LF_mutation', ['4.90%']),\n",
       "           ('LF_gene_dp', ['5.84%']),\n",
       "           ('LF_gene', ['8.86%'])])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DDL.lowest_coverage_lfs(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% accuracy and 0 generalization score are \"perfect\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../ddlite.py:564: UserWarning: Dev sets are too small for reliable estimates\n",
      "  warnings.warn(\"Dev sets are too small for reliable estimates\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"margin-right: 1%;float: left\"><tr><td><b>Labeling function</b></td><td><b>Positive accuracy</b></td><td><b>Gen. score</b></td></tr><tr><td>LF_mutant</td><td>0.00% (n=0)</td><td>0.00 (n=0)</td></tr><tr><td>LF_express</td><td>0.00% (n=0)</td><td>0.00 (n=0)</td></tr><tr><td>LF_gene_dp</td><td>0.00% (n=0)</td><td>1.00 (n=3)</td></tr><tr><td>LF_IN</td><td>33.33% (n=6)</td><td>0.27 (n=5)</td></tr><tr><td>LF_JJ</td><td>50.00% (n=4)</td><td>0.00 (n=4)</td></tr><tr><td>LF_gene</td><td>100.00% (n=1)</td><td>0.00 (n=3)</td></tr><tr><td>LF_variant</td><td>100.00% (n=2)</td><td>0.00 (n=1)</td></tr><tr><td>LF_mutation</td><td>100.00% (n=1)</td><td>0.00 (n=1)</td></tr><tr><td>LF_genotype_dp</td><td>100.00% (n=2)</td><td>0.00 (n=1)</td></tr></table><table style=\"float: left\"><tr><td><b>Labeling function</b></td><td><b>Negative accuracy</b></td><td><b>Gen. score</b></td></tr><tr><td>LF_snp</td><td>0.00% (n=0)</td><td>1.00 (n=1)</td></tr><tr><td>LF_network_dp</td><td>0.00% (n=0)</td><td>0.00 (n=0)</td></tr><tr><td>LF_dna</td><td>0.00% (n=0)</td><td>1.00 (n=1)</td></tr><tr><td>LF_LRB</td><td>0.00% (n=0)</td><td>0.00 (n=0)</td></tr><tr><td>LF_rna</td><td>0.00% (n=0)</td><td>0.00 (n=0)</td></tr><tr><td>LF_RRB</td><td>75.00% (n=4)</td><td>0.25 (n=1)</td></tr><tr><td>LF_JJ_dp</td><td>100.00% (n=1)</td><td>1.00 (n=0)</td></tr><tr><td>LF_dev_dp</td><td>100.00% (n=1)</td><td>1.00 (n=0)</td></tr><tr><td>LF_protein_dp</td><td>100.00% (n=1)</td><td>1.00 (n=0)</td></tr><tr><td>LF_NNP</td><td>100.00% (n=3)</td><td>0.00 (n=2)</td></tr></table>"
      ],
      "text/plain": [
       "<ddlite.SideTables instance at 0x1116f6290>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DDL.lowest_empirical_accuracy_lfs(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td><b>Labeling<br />function</b></td><td><b>Label<br />type</b></td><td><b>Candidate<br />coverage</b></td><td><b>Candidate<br />conflict</b></td><td><b>Positive<br />accuracy</b></td><td><b>Positive<br />gen. score</b></td><td><b>Negative<br />accuracy</b></td><td><b>Negative<br />gen. score</b></td></tr><tr><td><b><font color=\"#ee0b40\">LF_rna</font></b></td><td>Negative</td><td>0.89%</td><td>0.31%</td><td>N/A</td><td>N/A</td><td>0.00% (n=0)</td><td>0.00 (n=0)</td></tr><tr><td><b><font color=\"#ee0b40\">LF_dev_dp</font></b></td><td>Negative</td><td>0.21%</td><td>0.21%</td><td>N/A</td><td>N/A</td><td>100.00% (n=1)</td><td>1.00 (n=0)</td></tr><tr><td><b><font color=\"#ee0b40\">LF_protein</font></b></td><td>Negative</td><td>0.94%</td><td>0.21%</td><td>N/A</td><td>N/A</td><td>100.00% (n=1)</td><td>1.00 (n=0)</td></tr><tr><td><b><font color=\"#ee0b40\">LF_NNP</font></b></td><td>Negative</td><td>10.74%</td><td>6.52%</td><td>N/A</td><td>N/A</td><td>100.00% (n=3)</td><td>0.00 (n=2)</td></tr><tr><td><b><font color=\"#ee0b40\">LF_LRB</font></b></td><td>Negative</td><td>4.59%</td><td>2.45%</td><td>N/A</td><td>N/A</td><td>0.00% (n=0)</td><td>0.00 (n=0)</td></tr><tr><td><b><font color=\"#ee0b40\">LF_JJ_dp</font></b></td><td>Negative</td><td>2.61%</td><td>1.46%</td><td>N/A</td><td>N/A</td><td>100.00% (n=1)</td><td>1.00 (n=0)</td></tr><tr><td><b><font color=\"#ee0b40\">LF_protein_dp</font></b></td><td>Negative</td><td>1.51%</td><td>0.63%</td><td>N/A</td><td>N/A</td><td>100.00% (n=1)</td><td>1.00 (n=0)</td></tr><tr><td><b><font color=\"#ee0b40\">LF_network_dp</font></b></td><td>Negative</td><td>0.10%</td><td>0.00%</td><td>N/A</td><td>N/A</td><td>0.00% (n=0)</td><td>0.00 (n=0)</td></tr><tr><td><b><font color=\"#ee0b40\">LF_RRB</font></b></td><td>Negative</td><td>13.50%</td><td>3.49%</td><td>N/A</td><td>N/A</td><td>75.00% (n=4)</td><td>0.25 (n=1)</td></tr><tr><td><b><font color=\"#ee0b40\">LF_snp</font></b></td><td>Negative</td><td>1.36%</td><td>0.36%</td><td>N/A</td><td>N/A</td><td>0.00% (n=0)</td><td>1.00 (n=1)</td></tr><tr><td><b><font color=\"#ee0b40\">LF_dna</font></b></td><td>Negative</td><td>1.98%</td><td>0.63%</td><td>N/A</td><td>N/A</td><td>0.00% (n=0)</td><td>1.00 (n=1)</td></tr><tr><td><b><font color=\"#0099ff\">LF_express</font></b></td><td>Positive</td><td>0.78%</td><td>0.31%</td><td>0.00% (n=0)</td><td>0.00 (n=0)</td><td>N/A</td><td>N/A</td></tr><tr><td><b><font color=\"#0099ff\">LF_variant</font></b></td><td>Positive</td><td>3.18%</td><td>0.52%</td><td>100.00% (n=2)</td><td>0.00 (n=1)</td><td>N/A</td><td>N/A</td></tr><tr><td><b><font color=\"#0099ff\">LF_IN</font></b></td><td>Positive</td><td>26.23%</td><td>7.98%</td><td>33.33% (n=6)</td><td>0.27 (n=5)</td><td>N/A</td><td>N/A</td></tr><tr><td><b><font color=\"#0099ff\">LF_mutation</font></b></td><td>Positive</td><td>4.90%</td><td>0.99%</td><td>100.00% (n=1)</td><td>0.00 (n=1)</td><td>N/A</td><td>N/A</td></tr><tr><td><b><font color=\"#0099ff\">LF_gene_dp</font></b></td><td>Positive</td><td>5.84%</td><td>1.15%</td><td>0.00% (n=0)</td><td>1.00 (n=3)</td><td>N/A</td><td>N/A</td></tr><tr><td><b><font color=\"#0099ff\">LF_genotype_dp</font></b></td><td>Positive</td><td>0.99%</td><td>0.10%</td><td>100.00% (n=2)</td><td>0.00 (n=1)</td><td>N/A</td><td>N/A</td></tr><tr><td><b><font color=\"#0099ff\">LF_JJ</font></b></td><td>Positive</td><td>16.48%</td><td>5.27%</td><td>50.00% (n=4)</td><td>0.00 (n=4)</td><td>N/A</td><td>N/A</td></tr><tr><td><b><font color=\"#0099ff\">LF_gene</font></b></td><td>Positive</td><td>8.86%</td><td>2.76%</td><td>100.00% (n=1)</td><td>0.00 (n=3)</td><td>N/A</td><td>N/A</td></tr><tr><td><b><font color=\"#0099ff\">LF_mutant</font></b></td><td>Positive</td><td>1.25%</td><td>0.57%</td><td>0.00% (n=0)</td><td>0.00 (n=0)</td><td>N/A</td><td>N/A</td></tr></table>"
      ],
      "text/plain": [
       "DictTable([('<b><font color=\"#ee0b40\">LF_rna</font></b>',\n",
       "            ['Negative',\n",
       "             '0.89%',\n",
       "             '0.31%',\n",
       "             'N/A',\n",
       "             'N/A',\n",
       "             '0.00% (n=0)',\n",
       "             '0.00 (n=0)']),\n",
       "           ('<b><font color=\"#ee0b40\">LF_dev_dp</font></b>',\n",
       "            ['Negative',\n",
       "             '0.21%',\n",
       "             '0.21%',\n",
       "             'N/A',\n",
       "             'N/A',\n",
       "             '100.00% (n=1)',\n",
       "             '1.00 (n=0)']),\n",
       "           ('<b><font color=\"#ee0b40\">LF_protein</font></b>',\n",
       "            ['Negative',\n",
       "             '0.94%',\n",
       "             '0.21%',\n",
       "             'N/A',\n",
       "             'N/A',\n",
       "             '100.00% (n=1)',\n",
       "             '1.00 (n=0)']),\n",
       "           ('<b><font color=\"#ee0b40\">LF_NNP</font></b>',\n",
       "            ['Negative',\n",
       "             '10.74%',\n",
       "             '6.52%',\n",
       "             'N/A',\n",
       "             'N/A',\n",
       "             '100.00% (n=3)',\n",
       "             '0.00 (n=2)']),\n",
       "           ('<b><font color=\"#ee0b40\">LF_LRB</font></b>',\n",
       "            ['Negative',\n",
       "             '4.59%',\n",
       "             '2.45%',\n",
       "             'N/A',\n",
       "             'N/A',\n",
       "             '0.00% (n=0)',\n",
       "             '0.00 (n=0)']),\n",
       "           ('<b><font color=\"#ee0b40\">LF_JJ_dp</font></b>',\n",
       "            ['Negative',\n",
       "             '2.61%',\n",
       "             '1.46%',\n",
       "             'N/A',\n",
       "             'N/A',\n",
       "             '100.00% (n=1)',\n",
       "             '1.00 (n=0)']),\n",
       "           ('<b><font color=\"#ee0b40\">LF_protein_dp</font></b>',\n",
       "            ['Negative',\n",
       "             '1.51%',\n",
       "             '0.63%',\n",
       "             'N/A',\n",
       "             'N/A',\n",
       "             '100.00% (n=1)',\n",
       "             '1.00 (n=0)']),\n",
       "           ('<b><font color=\"#ee0b40\">LF_network_dp</font></b>',\n",
       "            ['Negative',\n",
       "             '0.10%',\n",
       "             '0.00%',\n",
       "             'N/A',\n",
       "             'N/A',\n",
       "             '0.00% (n=0)',\n",
       "             '0.00 (n=0)']),\n",
       "           ('<b><font color=\"#ee0b40\">LF_RRB</font></b>',\n",
       "            ['Negative',\n",
       "             '13.50%',\n",
       "             '3.49%',\n",
       "             'N/A',\n",
       "             'N/A',\n",
       "             '75.00% (n=4)',\n",
       "             '0.25 (n=1)']),\n",
       "           ('<b><font color=\"#ee0b40\">LF_snp</font></b>',\n",
       "            ['Negative',\n",
       "             '1.36%',\n",
       "             '0.36%',\n",
       "             'N/A',\n",
       "             'N/A',\n",
       "             '0.00% (n=0)',\n",
       "             '1.00 (n=1)']),\n",
       "           ('<b><font color=\"#ee0b40\">LF_dna</font></b>',\n",
       "            ['Negative',\n",
       "             '1.98%',\n",
       "             '0.63%',\n",
       "             'N/A',\n",
       "             'N/A',\n",
       "             '0.00% (n=0)',\n",
       "             '1.00 (n=1)']),\n",
       "           ('<b><font color=\"#0099ff\">LF_express</font></b>',\n",
       "            ['Positive',\n",
       "             '0.78%',\n",
       "             '0.31%',\n",
       "             '0.00% (n=0)',\n",
       "             '0.00 (n=0)',\n",
       "             'N/A',\n",
       "             'N/A']),\n",
       "           ('<b><font color=\"#0099ff\">LF_variant</font></b>',\n",
       "            ['Positive',\n",
       "             '3.18%',\n",
       "             '0.52%',\n",
       "             '100.00% (n=2)',\n",
       "             '0.00 (n=1)',\n",
       "             'N/A',\n",
       "             'N/A']),\n",
       "           ('<b><font color=\"#0099ff\">LF_IN</font></b>',\n",
       "            ['Positive',\n",
       "             '26.23%',\n",
       "             '7.98%',\n",
       "             '33.33% (n=6)',\n",
       "             '0.27 (n=5)',\n",
       "             'N/A',\n",
       "             'N/A']),\n",
       "           ('<b><font color=\"#0099ff\">LF_mutation</font></b>',\n",
       "            ['Positive',\n",
       "             '4.90%',\n",
       "             '0.99%',\n",
       "             '100.00% (n=1)',\n",
       "             '0.00 (n=1)',\n",
       "             'N/A',\n",
       "             'N/A']),\n",
       "           ('<b><font color=\"#0099ff\">LF_gene_dp</font></b>',\n",
       "            ['Positive',\n",
       "             '5.84%',\n",
       "             '1.15%',\n",
       "             '0.00% (n=0)',\n",
       "             '1.00 (n=3)',\n",
       "             'N/A',\n",
       "             'N/A']),\n",
       "           ('<b><font color=\"#0099ff\">LF_genotype_dp</font></b>',\n",
       "            ['Positive',\n",
       "             '0.99%',\n",
       "             '0.10%',\n",
       "             '100.00% (n=2)',\n",
       "             '0.00 (n=1)',\n",
       "             'N/A',\n",
       "             'N/A']),\n",
       "           ('<b><font color=\"#0099ff\">LF_JJ</font></b>',\n",
       "            ['Positive',\n",
       "             '16.48%',\n",
       "             '5.27%',\n",
       "             '50.00% (n=4)',\n",
       "             '0.00 (n=4)',\n",
       "             'N/A',\n",
       "             'N/A']),\n",
       "           ('<b><font color=\"#0099ff\">LF_gene</font></b>',\n",
       "            ['Positive',\n",
       "             '8.86%',\n",
       "             '2.76%',\n",
       "             '100.00% (n=1)',\n",
       "             '0.00 (n=3)',\n",
       "             'N/A',\n",
       "             'N/A']),\n",
       "           ('<b><font color=\"#0099ff\">LF_mutant</font></b>',\n",
       "            ['Positive',\n",
       "             '1.25%',\n",
       "             '0.57%',\n",
       "             '0.00% (n=0)',\n",
       "             '0.00 (n=0)',\n",
       "             'N/A',\n",
       "             'N/A'])])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DDL.lf_summary_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our development set is small, we can't evaluate LF performance particularly well. If we observe LFs with very low accuracy, poor generalization, and a sufficiently large sample size, this could be an indication that the LF is buggy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning\n",
    "To learn weights for the features and LFs, we use a simple, regularized logistic regression model. Again, the results won't be meaningful without more LFs. We'll tell ddlite to log the results and print out a summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training for rate=0.01, mu=1e-07\n",
      "\tLearning epoch = 0\tGradient mag. = 0.094753\n",
      "\tLearning epoch = 250\tGradient mag. = 0.103007\n",
      "Final gradient magnitude for rate=0.01, mu=1e-07: 0.110\n",
      "Begin training for rate=0.01, mu=1e-09\n",
      "\tLearning epoch = 0\tGradient mag. = 0.027539\n",
      "\tLearning epoch = 250\tGradient mag. = 0.028324\n",
      "\tLearning epoch = 500\tGradient mag. = 0.027695\n",
      "\tLearning epoch = 750\tGradient mag. = 0.027098\n",
      "\tLearning epoch = 1000\tGradient mag. = 0.026531\n",
      "\tLearning epoch = 1250\tGradient mag. = 0.025994\n",
      "\tLearning epoch = 1500\tGradient mag. = 0.025483\n",
      "\tLearning epoch = 1750\tGradient mag. = 0.024998\n",
      "\tLearning epoch = 2000\tGradient mag. = 0.024538\n",
      "\tLearning epoch = 2250\tGradient mag. = 0.024099\n",
      "\tLearning epoch = 2500\tGradient mag. = 0.023682\n",
      "\tLearning epoch = 2750\tGradient mag. = 0.023284\n",
      "Final gradient magnitude for rate=0.01, mu=1e-09: 0.023\n",
      "Begin training for rate=0.01, mu=1e-05\n",
      "\tLearning epoch = 0\tGradient mag. = 0.027539\n",
      "\tLearning epoch = 250\tGradient mag. = 0.028325\n",
      "\tLearning epoch = 500\tGradient mag. = 0.027696\n",
      "\tLearning epoch = 750\tGradient mag. = 0.027099\n",
      "\tLearning epoch = 1000\tGradient mag. = 0.026533\n",
      "\tLearning epoch = 1250\tGradient mag. = 0.025996\n",
      "\tLearning epoch = 1500\tGradient mag. = 0.025486\n",
      "\tLearning epoch = 1750\tGradient mag. = 0.025002\n",
      "\tLearning epoch = 2000\tGradient mag. = 0.024541\n",
      "\tLearning epoch = 2250\tGradient mag. = 0.024103\n",
      "\tLearning epoch = 2500\tGradient mag. = 0.023686\n",
      "\tLearning epoch = 2750\tGradient mag. = 0.023289\n",
      "Final gradient magnitude for rate=0.01, mu=1e-05: 0.023\n",
      "Begin training for rate=0.01, mu=0.001\n",
      "\tLearning epoch = 0\tGradient mag. = 0.027539\n",
      "\tLearning epoch = 250\tGradient mag. = 0.028372\n",
      "\tLearning epoch = 500\tGradient mag. = 0.027788\n",
      "\tLearning epoch = 750\tGradient mag. = 0.027236\n",
      "\tLearning epoch = 1000\tGradient mag. = 0.026714\n",
      "\tLearning epoch = 1250\tGradient mag. = 0.026218\n",
      "\tLearning epoch = 1500\tGradient mag. = 0.025749\n",
      "\tLearning epoch = 1750\tGradient mag. = 0.025304\n",
      "\tLearning epoch = 2000\tGradient mag. = 0.024881\n",
      "\tLearning epoch = 2250\tGradient mag. = 0.024480\n",
      "\tLearning epoch = 2500\tGradient mag. = 0.024099\n",
      "\tLearning epoch = 2750\tGradient mag. = 0.023737\n",
      "Final gradient magnitude for rate=0.01, mu=0.001: 0.023\n",
      "Begin training for rate=0.01, mu=0.1\n",
      "\tLearning epoch = 0\tGradient mag. = 0.027539\n",
      "SGD converged for mu=0.1 after 10 steps\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwEAAAFDCAYAAABiEAJbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111564710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18 s, sys: 213 ms, total: 18.2 s\n",
      "Wall time: 18.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><b>ID</b></td><td><b># LFs</b></td><td><b>Test set size</b></td><td><b>Model</b></td><td><b>Precision</b></td><td><b>Recall</b></td><td><b>F1</b></td></tr><tr><td>0</td><td>20</td><td>25</td><td>Logistic regression</td><td>0.500</td><td>1.000</td><td>0.667</td></tr></table><table><tr><td><b>LF</b></td></tr><tr><td>LF_JJ</td></tr><tr><td>LF_JJ_dp</td></tr><tr><td>LF_NNP</td></tr><tr><td>LF_RRB</td></tr><tr><td>LF_dev_dp</td></tr><tr><td>LF_dna</td></tr><tr><td>LF_express</td></tr><tr><td>LF_gene</td></tr><tr><td>LF_gene_dp</td></tr><tr><td>LF_genotype_dp</td></tr><tr><td>LF_mutant</td></tr><tr><td>LF_mutation</td></tr><tr><td>LF_network_dp</td></tr><tr><td>LF_protein</td></tr><tr><td>LF_protein_dp</td></tr><tr><td>LF_rna</td></tr><tr><td>LF_snp</td></tr><tr><td>LF_variant</td></tr><tr><td>LF_IN</td></tr><tr><td>LF_LRB</td></tr></table>"
      ],
      "text/plain": [
       "<ddlite.ModelLog instance at 0x10fe581b8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (12,4)\n",
    "mu_seq = np.ravel([1e-9, 1e-5, 1e-3, 1e-1])\n",
    "lf_opts = {'sample': False, 'verbose': True}\n",
    "model_opts = {'sample': False, 'n_iter': 3000, 'alpha': 0.5, 'mu': mu_seq, 'bias': False, 'verbose': True}\n",
    "%time DDL.train_model(method='lr', lf_opts=lf_opts, model_opts=model_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use [DeepDive-style calibration plots](http://deepdive.stanford.edu/calibration) to evaluate the quality of our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/numpy-1.11.0-py2.7-macosx-10.11-x86_64.egg/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtoAAAEZCAYAAACpeoK0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xe8XFW5//HPN4QkkEBoSkwCaRSBSy8iiASl1wtXiiDN\nBirIT64F0NwkRgG9CKKAFBGpFxARECkJ5RDpRQJI6IYACTm0gCRgTHl+f6w9YTKZOWfOOTOz5+R8\n36/XeZ09e3Z5pqzZa6+99rMUEZiZmZmZWW31yjsAMzMzM7NlkSvaZmZmZmZ14Iq2mZmZmVkduKJt\nZmZmZlYHrmibmZmZmdWBK9pmZmZmZnXQ4yrakk6V9O0ql71O0m71jqnWJF0i6cfZ9GckPdPJ7fxG\n0g9rG11V+71X0qYdXGfxa+7E/u6W9OXOrFsrks6QdGyeMXQnxeVY0o6SXm1j2W753koaK+nybHot\nSf+UpE5s52RJF9Y+wnb3e5WkfRu931rqrseAZUW1x2t/TkuStIakZyT1zTuWzpL0cUlTJS2fdyxd\n1aMq2pLWAA4HLqhylZ8BP61y2xtIui+bHi/puDaWPVLSguzA+a6kv0naq8qYOiQi7o2IDdpbLovp\nryXrfiMiqnr9tSJpb+CfEfFEI/fbSOXea+AM4BRJvfOIqTupUI7bGhCg6vdWUn9Jr2TTR0s6o41l\nd5S0MCvH72UHtqOqexVVC4CIeDUiVo52Bj4od9IREadFxNdrHFebJG0MbBIRN2WPy33nO7vtaZI+\nV4ttlWx3rKTLSmZXfQyw2urg8bqqz0nS8KzMntvV+JrcScAlETEPateY1F6jRhe3vUS5jog3gLuA\nY+qxv0bqURVt4CjglsKXrz0R8QiwkqQtqlh8S+CRounH2ln+/uzAuQrwO+BaSQNLF5K0XDWx1oBo\nu7LSKMcCl+cdRJ0t9V5HxCzgGaBbtwA2yFF0rBx35L3dHPhbNr1l0XQlM7JyPJB0cLtI0idLF+qB\n5fgY4Mqix80SV4d08BhgtXUUVZbzDnxORwB/Bw5udEtpo34DJPUBjgSuqMfmaWw5vgpXtLudPYB7\nCg8krSLpz5LekPR2Nj24ZJ17gGpam7fio8r15sCTHYjrd8AKwKjCGaOk70t6PXsOSXtLelzS7Kxr\nxcZFr2NzSY9lrWpXA/2KnlviDFTSUEl/zF7zm5J+lVUMfgN8WtL7kt7Jll2iO4akr0l6QdJbkm6Q\n9Imi5xZJOkbS85LekXRO0XOjJLVkrfdvSPq/cm9C9sP3ObLPSFJfSR9IWi17/ENJ8yUNyB7/WNKZ\nRZtYTdLNWQvjA5JGFG17O0kPZ+/fQ5I+XenDkPTl7JLV25JulbR2heX6Sro8ez8K2/1Y9tzKkn4r\naWb2eU5QUva9zlT7XevplijHGSl1kXhT0j8kHVryfGfK8VbA49UGFRE3ArOBDSUNy8rElyVNB+7M\ngtxW0n3Z9+VxSTsWvYDhWTl5T9LtwBpFzxW21yt7vKqk30makX1Pr5e0InALMDj7bv1T0iAVdUHJ\n1t1X0t+zcnqXik4MlFqV/lvSE1mM/6d04EbS6tlv5Oxsn6WfQbHFn1Ebvy99lLr1TJf0uqTzlF3q\nrrQvpRbntYE/Z6/vu6U7bitOSZ9Q6mbwhqSXJB2fzd8NOIVUAXtfUvHn7nKZj6XKuaT9snLzntKx\naNeip6v5nI4AxgFvA/uUbHsjSROz78zrkk7K5veSdIqkF7Pv3COShpSWyWzZxS3HSldx7pV0pqS3\ngLGSRkq6MztmvCHpCkkrF61f7vi8fBbTRkXLfUzSXEmrl3mNnwJmR8TMbNmfADsA52Tx/yqb/8mi\n1/uMpAOLtr+npKez5V+VdGKl35fSnZdbt+i5svWYNsr1Q8BISWu187k2t4joMX/AG8CWRY9XA/YH\n+gL9gWuA60vW+Q5wXRvbnAi8A8wH3gXey6bfAf5SYZ0jgcnZdG/ghGy9lYAds/VPBZbPYtscaCUd\n+EW6nDYte3554GXg28BywH8B/wZ+nG1/R+CVbLoXMIV0Kb0f0AfYrjSmojgvKdrO54A3gU2zff4K\nuKdo2UXATdlrWCt7r3fNnrsKODmbXrzPMu/LhsD7JfNagP2z6duBF4Ddssf3APsWxfomqRWyF+ls\n/qrsuVWzz+PQ7LlDsserZs/fDXw5m94PeB5YL1v2FOC+CvF+Hbgx+4yUfU4Dsuf+BJyXvc9rAA8C\nX6v0Xmfz9wcezbucNPsfS5fjQpn53+y7+VlgDrBute8t8NvsOzEP+Cepwlwox09VWKe4bCnbxzxg\nXWBYViZ+TzqJ7gsMBt4q+v5+Pnu8evb4/qLXsEMWx2XZc8OAhUCv7PFfgP8DViaV+x1KYyqKc2zR\ndtbL3pvPZet9LytTvbPnp2Xf1TWBVYCpwNez507NvtO9snW3r/C+rJi99tWL5pX7fTkLuAEYSPr9\nvRH4aXv7ymLcqY3Psuy62Wf0KPDDbP5w4EVgl9L3qWR7bR4D/Newcr4N6Rj7uezxJ4D1qv2cispU\nX1I3kxuLnhsAzAT+H+kY1R/YOnvue8ATwDrZ441Jx5QlymT2XPGx5EjSb8g3s+9iX2AUqdz3BlYn\nHd/OzJZv6/h8DnBa0X6+XRx/yev8JvDnknmL48oerwi8QjrxEOm4/ibwyez5mUX7Hghslk0v9ftS\nZv+V1q1Yj8meL1uus/d+77y/j13562kt2qsA7xceRMQ7EfGniJgXEXOB00hfpGLvZ+uVFRG7ks4g\nH4/UDeR04KSIWC0i2jq7/nTWsjMTOBj4z4goxLYQGBsR8yNdNvsacH5EPBrJ5aQD+rbZX++I+FVE\nLIyIP/JRF5ZSnyL9OH0/Iv4VEf+OiPvbiLHYocDFEfFERMwHTs5eQ3Fr72kR8X5EvEoq2Jtl8+cD\nwyQNaWefS3w+mcnAjkqX3TYhVfB3zFq+tgaK+33+KSIei4hFpMvWhf3vBTwfEVdFxKKIuBp4lpIW\njcwx2et4PtvO6cBmFc6o55N+LNfLPpfHI2KOpI+TWmO+k73PbwG/BL5Y4XUXtPlds8XKfU8CGJOV\nmcmkiuhBRc+3V46/Cowk/divQTpYnZ+V440rrQcMycrxm8AY4EsR8UJRTGMj4sOsHH+JdPJ9e7bP\nO0kVvz2z79dWwP9kr+GvwJ/L7VDpStJuwDER8c+s3Ffb//kg4OaIuCsiFpIO6isA2xUtc3ZEtEbE\nu1kMxeX4E8CIbJ/3VdjHKtlrL/2MSn2NVEbey35/T+ejMtLevtq6KbTSulsDa0TET7P5L5NOsA5p\nJ06Xy3yUlvMvk45BdwFExOsR8XzR8+19TkeQKqDzgD8Auyv1AwfYG3g9In6ZHaPmRuqOAvAV4IcR\n8WK236ciYnaVr2FGRJyXHXfmRcRLEXFnRCyIiLdJJ5uFOkdbx+fLScfggsOp3MWy3O9jqb2BaRFx\nWXbsegL4I1Bo1f43sJGklbLyOaXK19vWum3VYwrKletuX/56WkV7NqnFFQBJK0i6QNLLkt4ltZCu\nIi1xZ/9KpLPopUj6lqTZpDOujbLpCcCPlC7LrlFuvcwD2UH84xGxXUTcXfTcm1lltmAY8N/ZNt/J\n9jOU1EI2GJhRsu3pFfY5FJieVSA7anDxdrMD49vAkKJlWoumPyC1EkBqEegFPCzpKUlHV9jHEp9P\n5h5gJ2ALUnecScBoUuF8oeQHb1aF/S8Re2Z6SewFw4CzC+919hqjwrKXkVrZr5b0mqTTsxOCYaRW\nydeLPq/zKeoKUEHF75otodz3ZHZE/Kvo8XTS517QVjneJ/uMXiN9dq3ApcAR2efXVr/PGVk5XiMi\ntoiIP5Q8/1rR9DDgoJJyvD3p4Do4ew0flryGcoYC70TEP9uIq5LSchzAq1RXjv8XeAmYmF1G/0GF\nfRTe59LPaDGlLlYrAo8VlbVbSSeuHdlXOT+vsO4wshOjovf/ZODj7WzP5TIfpeV8LdLnWklbZbwf\nqRL5B4Cs8jedjyqvbW17LeAfVUe9pCVuHFTKpPF/2fHiXdKV18JxoeLxOSIeAj5Q6gq6Pqll/KYK\n+yz3+1hqGLBtSVk4lHQlC9KV8b2A6Vl3mG0rbaiMSuu2VY9pS7cvfz2tov0k6dJpwX+TLvNuHak1\n+rPZ/OKK9gakivRSIuLciFiVjyqDw4DXImLV7OD7VifjLL3Z4FXSJdXVsr9VI2JARFwDvM7SlcCy\nfYqz7aytoj5lbeyz1EzS6wNSdgbSQfG1imsUNhzxRkR8PSKGkG52PE/SyDKLvpg2/VHfb9Ll9PVJ\nl+XviYhnSa9vT5bup9tW7MNL5q3N0icokN6jY8q81w+WeV0LI2JCRGxEahHch9Rq8irwL9Kl88I2\nVomITQqrVoiz4nfNllBajgFWlbRC0eO1SZ97QVvl+M9ZOb4cODKbfpvU+rlaRLR3Q2Rbij/rV0ld\nE4q/WytFxM9J5bjcayjnVdL9CCuXea5D5TizFtWV4zkR8d2IGEW6sfRESTuVWe4DUqWl+DMqjest\nUiV+o6L3Y5VIN5W2t682X2PWGllu3VeBf5S8/wMjonBly+WyuZSW81dJFcxK2vqc9id1s7pAqf/1\n66RK3pFVbPuVCs/Nzf6vWDSvtM9y6XfqVFK3qo2yOseX+Ki+0dbxGdLJ/+HZ33UR8e8Ky5X7fSxX\np2gpKQsrR8RxAJGuDP8n8DFSl65rK2xnKW2s21Y9puy2s4ardejm5a+nVbRvIbWGFqwEfAj8U+mG\nu3Fl1tmR1NLSls1IX+5qshR0xkXAsZK2gcUpyPbMKrsPAAskHS+pt6QDSH3ZynmYdEA/XdKKSjfz\nFS4ZtwJDVflO7P8Djpa0SdZt41TgwUjdRNok6QuSCicD75J+aMqdtc8H7qCo+07WwvcY8C0+qljf\nT6qwV1vRvgVYV9IhkpaTdDDpR7ncpfnzSangNsxiHyjpCxVe12hJ/5H9MM4hXbJeGCnLxUTgLEkr\nKRkpqXAiV+m9rua7ZkuXY0gHq/FKNw7tQGpRKW5drua93RJ4XOkm2tdLrip1Rull0CuAfSTtqnSD\nVb+shWpwRLxC6kZSeA2fYemuTYLFWVRuJZ2wrpKV+x2yZVqB1StUwiEd9PaStFO23ndJJ4UPtPti\npL0kFSoc7wMLKFOOM7ewZDe8Jb7zWUv6RcAv9dENxEOU3dxWYV8Li7ZV7kS9vTgfBt5XutG8X/Zb\nsJGkrYq2O1xaKle5y2U+Ssv5xaRj0E7Zb+rgrHW3oK3P6chs/Y1J/ZE3BT5D6ha4EXAzMEjSt5Vu\n0h1QON5m602QtA6k1JWSVs0a0mYAX8rK85dp+0QAUp1jDul7OIR0tbegreMzpO6Q+wOHka6mVvIw\n6cp8cYNVaZm5GVhP0pey34HlJW2ldIPk8pIOlbRypO5l77Nk2av4+9LOum3VY8rFCKkuM62aekYz\n62kV7cuAPfRREvdfks5G3yJV3m4pXljS1qSb8x6ttEGlvpVvZZetN6f9tH4dFhGPkfo3naN0ifV5\nsjPxrDJwAHA0qRXuQFJfq3LbWUQ6eK9LOkt/lY/6sd4FPA3MkvRGmXXvJPVBvZ704zKCJfs2tnWm\nuzXwkKR/km5++nak/pHlXEhqFS52D+nmpYeLHg8g9d9ud/8R8Q6pT9p3SZ/1d4G9irqdRNGyN5D6\nil6tdGnvSWD3CpseBFxHupH1aVK/9EJKpSNIN7NMJd1Q9wc+au1Y6r3OfhQ3IL0/1rbScgzpADWb\n1GJ7OemqxPNQ3XurlGN7WKT+1bUqx0t8JyPiNdLNtqeQ+nRPJ30XC7/Dh5G6RL1NKmuXtrG9w0kV\nyGdJB6gTsn08Rzop/ofS5dklWtiy9+RLpJur3iSdkOwTEQvKxVxiXeAOSe8D9wHnRkSlk92Lsv0U\nlPt9OYl0FevBrKxN5KOWuHL7KpT304Ax2etbnNGgvTiz37+9SQ0j00g3211EaumEVEYFvC3pUaju\nGGB1s0Q5j9Rn+mjScfs90o2Ea0Pbn5NSJrHPAWdlV1cLf38jVcyPjIg5wC6kKyCzSMfY0dkmziSd\noE6U9B6pX3/hytPXge+TjisbkL5vbRlPOqEv3P+w+FjdzvGZrLL5eJqMeyvtIKsT/J70G1FwNnCg\nUoaRX2avd1fSMXxm9nc66ZhFtu60rFx+nfTb1O7vS4V1D83WrViPyZQr14eRGr+6NaWGhTptPBWQ\nyaQPrw/pLtlTJI0lveGFH9xTIuK2bJ2TSTc9LABOiIiJNY7pJ8AbEfGrKpa9DvhtITZrDKWBLY6L\nZXjQmlJKA6O8GBFN9aOi1Fr/KKlL1FJ5qJVSRe1Buox6VHTsppmuxNWRctyU7+2yTtIVwLWRDVrT\nHXWnY4Cki0knEq1F3dRKl8mlvHZWteW8O31OXSHpt8DMiPifdpZbg1T32jyqHG+g2WRXulpIr6FS\nN5luoa4VbQBJK0bEB0p9be4j9YvemXT2eWbJshuQUsFtTeo/dQcpRVd9gzSzsiR9h9QCs3JpRVvS\nHqQTor0kfYqUraIjN82YWY1k3Y3mkO4DWKqi7fLavUkaRmrR3jwiKt0obU2o7l1HshtjIOWQ7EW6\nvAvl07jsB1wdKfXNy6T8rpX6G5tZHUkaSrrp9LcVFtmPrK9gpLviB0pas8KyZlZHWXeCttLOubx2\nU0oDxz0F/NyV7O6n7hXt7CaBx0n9nloiYmr21HGSpiiNnlcYenwIS6bDmUH5tGpmVn9nkW7WqXRF\nyeXVrPtwee2mIuJ/sqwgp+cdi3VcI1q0F0XE5qSuIJ9VGnL4PGBkRGxGqoD/ot5xmFn1JO1F6us5\nhXT1qa0BQszMzKyM3o3aUUT8U9JfgK1K7lS/iI/SrM0g5XQtGEqZXMeS3GfbrERE1LIyvD2wr6Q9\nSXfYryTpsogozghTVXkFl1mzcmpcZtvj8mrWBZ0tr3Vt0Za0RqFbiNJADLsAU0pSwhwA/D2bvgk4\nJMtjOYKUqPxhyogmGL++3N/YsWNzj6E7xdXo2NZcc8mxOtZcc1hTxNXV96vWIuKUiFg7IkaSUkDd\nFUtWsgvl9QgApdG/3o2IVirI+33rTp9xM8fWyLiyb07RH0tMd4f3q1JsddLW1acOldehQ4Nrrsn/\nvcvz+1ft37jDDmMO6Vs5Nvs/Bxh32GG5x9bs7113ia8r6t2i/QngUkkiVeovj4g7JV0maTPSIAIv\nA8cARMRUSdeScg/PB74ZXX2FZkVaW6dT3OW4tdU9IjpC0jGkPK4XRsQt2YADL5LShR2dc3hmPZak\nq0i5n1eX9AqpzteHTpbXm2+GXXaBQYPgs59ta0k7asIExj74IONfSqO4zwXGjhrF8RMm5BuYddqf\n/gSTJ8NZZ3V9W3WtaEfEU8AWZeaXtowVP3caKXG5mTWBSF297smmLyh57rhcgjKzJUTEoVUsU3V5\n3XRTuPJKOPBAeOwxGDq0a/Ety4aNGMHxkyZxxjHHcPc996ADD+T4CRMYNmJE3qFZJ9x/P3z963Bb\njbKyN6yPdk8xevTovEMoq1njguaNzXEt+5r5vWzW2BxXxzVzbG3ZZRe4/XYY0kS5SZr1vRw2YgRj\nL72UHTfckNFXXNH+Cjlo1veuoBnie/55OOAAuOwy2HLL2myz7gPW1IMk9yixTkm9mIq/O+py/6tm\nIIlo7I1VHeIya51Rrrx+9Lh7l91mLrMur50UAf37wxtvwIABeUdjHdTaCtttB6ecAl/5ypLPdaW8\n1j29n5mZmdkyT4IRI2DatLwjsU74n/+Bww9fupLdVe46YmZmZlYLI0fCP/4BG2+cdyTWQWefDX37\n1n67btE2MzOzqkyfDueem3cUTWzEiFTRtm6nX790UaLWXNE2MzOzqvTrB2eeCRdfnHckTWrkSHcd\nsSW464iZmZlVZc014dZbU27twYNhjz3yjqjJjBwJd9yRdxTWRNyibWZmZlVbbz24/no44oiUY9uK\nFPpoW1O74w746lcbsy9XtM3MzKxDttsOLrwQ9tkH3n4772iaSCHryKJFeUdiFTzxBBx6KBx5ZGP2\n564jZmZm1mH775/qlauvnnckTaR/fxg4EGbNSn1rrKm88grsvXe6oXeHHRqzT7dom5mZWadstlne\nETQhdx9pSrNnp3sKTjwRDjywcft1RdvMzMysVlzRbkqnnQa77grf+U5j9+uuI2ZmZma14lzaTekn\nP4HeOdR63aJtZmZmNfHcc/Db3+YdRc7cot2U+vSBXjnUel3RNjMzs5pYYQUYPx6uvTbvSHLkQWus\niLuOmJmZWU2svTbcfDPssgsMGpQGtulx3KJtRdyibWZmZjWz6aZw1VUps8PUqXlHk4PBg1Ny8Q8/\nzDuSHuuBB+CQQ/KOInFF28zMzGpq553hf/8X9twT5szJO5oGW245GDYMXn4570h6pOefTzneGzUg\nTXtc0TYzM7OaO+IIuPFGGDAg70hy4O4juWhtTbmyf/rT9L8ZuKJtZkuR1FfSQ5Iel/S0pFPLLLOj\npHcl/S37+1EesZpZ89p007wjyIkr2g03d24a9fHww+ErX8k7mo/4ZkgzW0pEzJO0U0R8IGk54D5J\n20fEfSWLTo6IffOI0cysabmi3XC/+hVsvDGMHZt3JEtyRdvMyoqID7LJvqSrX7PLLKbGRWRm1k2M\nGAGTJ+cdRY/yve9BBKjJjkruOmJmZUnqJelxYBbQEhHl8gd8WtIUSX+RtGGDQzSzbmbKFLjiiryj\naADn0m643r1h+eXzjmJpda1oV+rnKWlVSRMlPSfpdkkDi9Y5WdILkp6RtGs94zOzyiJiUURsDgwF\nPitpx5JFHgPWjojNgHOAGxodo5l1LyuuCN/9Ltx6a96R1FlhGPaIvCOxnNW160ilfp7AvsAdEfFz\nST8ATgZOylrEDgI2IB3c75C0boS/qWZ5iYh/SvoLsBVwT9H8OUXTt0o6T9JqEfFOue2MGzdu8fTo\n0aMZPXp03WI2azYtLS20tLTkHUbu1lsPrr8e9tsPbrsNttwy74jqZOBA6NcP3nwTPv7xvKOxHKlR\ndVhJKwItwFHA9cCOEdEqaRDpsvQnJZ0ERET8LFvnVmBcRDxUsi3Xva1TJAHF3x2xLHyXJBERNeuZ\nJmkNYH5EvCdpBeB2YHxE3Fm0zJoR0ZpNbwNcGxHDK2zPZdY6rFx5/ehx9y67tS6ztdSI8vqnP8G3\nvgX33Zcaf5dJ22yT7tDbdtu8I1nmPPEEjBmT0kc2ok92V8pr3W+GlNSLdIl5FHB+REwtPkBHxCxJ\nhdO9IcADRavPyOaZWWN9ArhUqabTC7g8Iu6UdAzpZPhC4AuSvgHMBz4EDs4vXDPrTvbfH2bMSAPa\nPPEE9OmTd0R1UMg84op2Tb3ySkrjd+aZzXfjYzl1r2hHxCJgc0krA7dLGs2STRSUedwuX4a2nqze\nl6Ej4ilgizLzLyiaPhc4t25BmNky7bjjYIcdltFKNjjFXx3Mnp0GojnxRDjwwLyjqU7Duo4ASBpD\navn6CjC6qOvI3RGxQZmuI7cBY911xGrFXUfy4TJrneGuI/lwea2R3/4W7r8ffve7vCNZJsybB7vt\nBptvDmed1dh9d6W81jvryBqFjCJZP89dgMeBm0h9tQGOBG7Mpm8CDpHUR9IIYB3g4XrGaGZmZlZz\nhcwjVhMXXwwf+xj84hd5R9IxdW3RlrQxcCmpGaLQz/MMSasB1wJrAdOBgyLi3Wydk0kt3vOBEyJi\nYpnt+mzbOsUt2vlwmbXOcIt2Plxea2TaNNhxx9Sp2Lps0SKYPx/69m38vrtSXhvadaRW/CNgneWK\ndj5cZq0zXNHOR57l9f77YdYsOOCAXHZfWwsWQP/+8P77y3BH9J6habuOmJmZmVWrf3849thlZPTy\n3r1h6FCYPj3vSCxHrmibmZlZU9h0U7jqqpRRYurUvKOpAWce6fFc0TYzM7OmsfPO8L//m3Jsz5yZ\ndzRd5Ip2pzz/fMowsmBB3pF0nSvaZmZm1lSOOAK+9rU0VPuiRXlH0wWuaHdYa2vKlX3QQan3TXfn\niraZmdkyQNLukp6V9LykH5R5fnVJt0qaIukpSUflEGbVTjklpXTr1Z1rKq5od8jcuWnUx8MPh698\nJe9oaqM7f33NzMwMkNQLOAfYDdgI+KKkT5YsdhwwJSI2A3YCfiGpadsMJdhkk7yj6CLn0q7aggVw\n8MGw8cYwdmze0dSOK9pmZmbd3zbACxExPSLmA1cD+5UsMwtYKZteCXg7IpaBXrBNrNCi3Y1TUTbK\ntdemyvYFF6STrGWFK9pmZmbd3xDg1aLHr2Xzil0EbCRpJvAEcEKDYuu5Vl011Rpnz847kqb3xS/C\njTfC8svnHUltNe0lIzMzM6upk4EnImInSaOASZI2iYg5pQuOGzdu8fTo0aMZPXp0w4Jsy6RJqdVz\njz3yjqRK0ket2qutlnc0TU3KZ9THclpaWmhpaanJtjwypPUoHhkyHy6z1hkeGbJD29sWGBcRu2eP\nTwIiIn5WtMwtwE8j4r7s8Z3ADyLi0ZJtNW15vf/+lInktttgyy3zjqZKX/hCSqFx0EF5R2Kd5JEh\nzczMerZHgHUkDZPUBzgEuKlkmWeAnQEkrQmsB3SrO/W22w4uvBD22QemTcs7mio580iP5oq2mZlZ\nNxcRC0lZRSYCTwNXR8Qzko6R9PVssdOArSQ9AUwCvh8R7+QTceftv39K/bfHHvD223lHUwVXtJfy\nyivw+c/Dhx/mHUn9uY+2mZnZMiAibgPWL5l3QdH0W8A+jY6rHo47LlXWDjwQ7ryzybNUjBwJ112X\ndxRNY/bsdJL01a/CCivkHU39uY+29Sjuo50Pl1nrDPfRzkd3Ka+LFsHTT6e8y03txRdh113dqg3M\nm5eGVt98czjrrLyjqV5Xyqsr2tajuKKdD5dZ6wxXtPPh8lpj//43rLQSzJmz7OWu64BFi+Cww1LW\nmGuu6V4jfvpmSDOrKUl9JT0k6XFJT0s6tcJyv5L0Qjak82aNjtPMrOn16QODBsGrr7a/7DLs1lvh\ntdfg8su7VyW7q3rQSzWzakXEPGCniNgc2AT4nKTti5eRtAcwKiLWBY4Bzm98pGZm3cDIkd0oTUp9\n7LVXyoN2uBDmAAAgAElEQVTer1/ekTSWK9pmVlZEfJBN9iX9VpQObbYfcFm27EPAwCxlmJlZLm64\nASZPzjuKMpx5BOh5lWxwRdvMKpDUS9LjwCygJSKmlixSOuTzDJYe8tlyMmvWLGbOnMnMmTN5551u\nl8HNrFMGDEiZSKaW/lrlzRXtHsvp/cysrIhYBGwuaWVgoqQdI+Kezm6vWYd0Xhbdfvvt7L33f9Kn\nz6oALFz4T15++UUGDRrUsBgGDRpOa+t0ANZccxizZr3csH03Yyy1HNLZKtt5ZzjjDNhzzzSK5ODB\neUeUGTkyNbdbj+OsI9ajOOtIp7c/BvggIn5RNO984O6IuCZ7/CywY0S0llnfZbaBrrzySo499hbm\nzLkSgAEDRjFlykRGjRrVsBiWLGudK2e1yjpSi1hqzVlH6uunP02pqydPTgk/cvfQQyn59yOP5B1J\nQ7S2wiGHpHOLgQPzjqbrnHXEzGpK0hqSBmbTKwC7AFNKFrsJOCJbZlvg3XKVbDOzRjvlFNhmGzjy\nyLwjyfSgriNz58Lee8OOOy4bleyuctcRMyvnE8ClSk2BvYDLI+JOSccAEREXRsQtkvaU9CIwFzg6\nz4DNzAokOPdceP75vCPJrLFGGq3l3XdhlVXyjqZuFiyAgw9OgwiNHZt3NM2hrhVtSUNJWQnWBBYB\nF0bEryWNBb4GvJEteko2dCySTga+DCwAToiIifWM0cyWFhFPAVuUmX9ByePjGhaUmVkH9O4NG26Y\ndxQZ6aMUf5tvnnc0dREB3/wmzJ8PF1yQXrLVv0V7AXBiREyRNAB4TNKk7LkzI+LM4oUlbQAcBGwA\nDAXukLRut+8sZmZmZj3bMl7Rvu8+ePRRuOeeHj0A5lLq2kc7ImZFxJRseg7wDB+l/yp3rrMfcHVE\nLIiIl4EXgG3qGaM1r0GDhiNp8d+gQcPzDsnMzKxzlvF+2p/5DDzwQJPcfNpEGnYzpKThwGbAQ9ms\n47Jhm39buOkK5+W1IikdVyz+K6TnMjMz64wrr4THHstp58t4RRugb9+8I2g+DbkZMus2ch2pz/Uc\nSecBP46IkPQT4BfAVzuyTefktZ7MOXnNzDpuxRVhn31SN4cRIxq885Ej4eabG7xTy1vdK9qSepMq\n2ZdHxI0AEfFm0SIXAX/OpmcAaxU9NzSbt5TiirZZT1N6cjl+/Pj8gjEz6yb23x9mzIA99kiV7dVX\nb+DOe0CLti2tEV1HfgdMjYizCzMkFQ9PdgDw92z6JuAQSX0kjQDWAR5uQIxmZmbWAxx3HOy7L+y3\nH3z4YQN3PHw4vPIKLFzYwJ3W3vRp0/jhgV9i31V34qT/+hLTp03LO6SmVu/0ftsDhwFPSXqc1Nn2\nFOBQSZuRUv69DBwDEBFTJV0LTAXmA990xhEzMzOrpdNPh8MOS+noLrmkQTvt1y81oc+YAWuv3aCd\n1tb0adM4e+ddmPCPl+gPzL0exj7xIMdPmsSwhvfF6R7qWtGOiPuA5co8dVsb65wGnFa3oMzMzKxH\n69ULfv97ePnlBu+40H2km1a0L/nRmMWVbID+wPiXXuKMMWMYe8UVeYbWtDwEu5mZmfU4ffvC+us3\neKfdvJ/2C3+dsbiSXdAfWDRzZh7hdAuuaJuZmZk1QmHQmm7oiSfgufeGMLdk/lyg1+DBeYTULbii\nbWZmZtYI3bhFe9NN4aqHJzB20KDFle25wNjevTnqa1/LM7Sm1pA82mZmZmbN7qKLYPvtYcMN67SD\nblzRBlhv/REcv/vunPH44yxabTV6DR7M8euvz7DDDoNbboFNNsk7xKbjiraZmZkZKTHInnvC/fdD\nXXpDdPOKNsCwhx5i7GWXwVZbfTTzk5+EXXaBP/4xjcVui7nriJmZmRlw+OHwta/BXnvB++/XYQeD\nBqUNz5lTh403wKuvwhtvwOabLzn/wAPhiivggAPgL3/JJ7Ym5Yq2mZmZWeaUU2CbbeALX4D582u8\ncSmN/d7kN0TOnQu77lomzEmTYOedYbkymZt32SUNMf+Vr8Dllzckzu7AFW0zMzOzjATnngvLLw/f\n/34ddjBiRFN3H1mwAA4+GIYMSYNZLuH222G33SqvvM02cPfd8MMfwtlnV16uB3EfbTMzM7MivXvD\nNddAa2sdNt7E/bQj0miZ8+fDhRemk47FFi6EO+6AX/yi7Y1ssAHce29qEn/rLfjxj0s21LO4RdvM\nzMysRP/+qU5cc02cS/vUU+GRR+C661KL/hL+9rfUx3zo0PY3tPba8Ne/wm23wTe+kSrpPZQr2mZm\nZmaN0qQt2v/4RxqW/pZbYKWVyiwwcWJqpa7Wxz4Gd90FL7wAhxwC8+bVKtRupd2KtqT+knpl0+tJ\n2ldS6XmOmTWhzpZfSUMl3SXpaUlPSfp2mWV2lPSupL9lfz+qx2swM1umNGlFe+RI+Pvf4ROfqLBA\nRyvakGrst9wCixbB3nt332wrXVBNi/ZkoJ+kIcBE4HDg9/UMysxqprPldwFwYkRsBHwa+JakT5bb\nfkRskf39pFZBm5k1o7PPrkGvj0LWkUWLahJTLfXtW+GJ999PXUc++9nObfTaa9Pr/vznU7/tHqSa\nirYi4gPgAOC8iDgQ2Ki+YZlZjXSq/EbErIiYkk3PAZ4BhpTbfi2DNTNrZsstB3vsAW+/3YWN9O8P\nAwfCrFk1i6vu7r4bPvWpFHtnLLccXHBBqmjvsEPKx91DVFXRlvRp4DCgkIW8TAJFM2tCXS6/koYD\nmwEPlXn605KmSPqLpHoNWmxm1hSOOw723Tf9ffhhFzbUpN1HKupMt5FSUrrb8qtfTaNHPvtsbWJr\nctWk9zsBOBn4U0Q8LWkkcHd9wzKzGulS+ZU0ALgOOCFr2S72GLB2RHwgaQ/gBmC9StsaN27c4unR\no0czevToasMw6/ZaWlpoaWnJOwyrgdNPh8MOgy99KfWIKDd2S7sKubRzGq583rw0IM9pp8F//EcV\nK0ycmF5sLfz3f8Maa8BOO8FNNzF9jTX4/ZgxLJoxg15DhnDUhAkMGzGiNvtqAoqIvGPoMEnRHeO2\njpEEFH/Ooqufez222QwkERE17cYhqTdwM3BrRLQ78oCkacCWEfFOmedcZhvoyiuv5Nhjb2HOnCsB\nGDBgFFOmTGTUqFENi2HJsta5clauvHZmm7WIpdbqVGZ3B35Julp9cUT8rMwyo4GzgOWBNyNipzLL\nuLy2Y968NG7LjjvC+PGd2MCYMamGXtQA0SiLFqUThfnzU67wdk8Upk2DbbeF11+HXjVMVvfnPzP9\nyCP5db9+jH/9dfoDc4Gxo0Zx/KRJTVXZ7kp5bbdFW9J6wHeB4cXLR8TnOrNDM2ucLpbf3wFTK1Wy\nJa0ZEa3Z9DakE/elKtlmVn9ZdqFzgM8DM4FHJN0YEc8WLTMQOBfYNSJmSFojn2i7v7594YYb0j2C\nnTJyZOr3nIOTT05dpCdNqrI1ftKkNLx6LSvZAPvsw++33JLxd9xBoed3f2D8Sy9xxpgxjL3iitru\nLyfVdB35A3A+8Fug52YcN+ueOlV+JW1P6tf9lKTHSc2BpwDDgIiIC4EvSPoGMB/4EDi4xrGbWfW2\nAV6IiOkAkq4G9gOKO8IeCvwxImYARETPSv9QY6uskv46ZeRI+N3vahpPNc45B268Ee67D1ZYocqV\nJk5MndLrYNGCBZTeXtkfWDRzZl32l4dqKtoLIuI3dY/EzOqhU+U3Iu6jnZsmI+JcUuuYmeVvCFCc\nyuE1UuW72HrA8pLuBgYAv4qIyxsUnxXL4WbIWbPgrLPSKOqrr17lSgsWwJ13wq9/XZeYeg0ZwlxY\norI9F+g1eHBd9peHaq4D/FnSNyV9QtJqhb+6R2ZmteDya2YFvYEtgD2A3YExktbJN6QeavDglCOw\nS6lLOmbQIJg6Nd2HWbVHHknDqVccxaZrjpowgbGjRjE3e1zoo33UhAl12V8eqmnRPjL7/72ieQGM\nrH04ZlZjLr9mPcMMYO2ix0OzecVeA96KiH8B/5I0GdgUeLF0Y84S1Dk/+xkcfniqR7dpueVg2DB4\n+WXYYINGhAa0MSBNJbVI69eGYSNGcPykSZwxZgyLZs6k1+DBHN8EWUdqmSWo3Yp2RDTPbZ9m1iEu\nv2Y9xiPAOpKGAa8DhwBfLFnmRuDXkpYD+gKfAs4st7FxOWTDWBYsXAh77QWTJ6fRx9tU6D7SwIp2\nh02cWPfMKMNGjGi6Gx9LTy7Hdyq1TNJu1xFJy0v6tqTrsr/jJC1fzcYlDZV0l6SnJT0l6dvZ/FUl\nTZT0nKTbszuhC+ucLOkFSc9Iqt9plFkP0JXya2aNJel4Sat2Zt2IWAgcB0wEngaujohnJB0j6evZ\nMs8CtwNPAg8CF0bE1NpEb5AyemyzTcpRPX9+OwsXcmnXSZczNL77Ljz5ZG65vpcV1fTR/g2wJXBe\n9rdlNq8aC4ATI2Ij4NPAtyR9EjgJuCMi1gfuIg2oQTay3EHABqQ+ZOcpJUA1s87pSvk1s8Zak5SW\n71pJu3f0+BcRt0XE+hGxbkScns27IMsSVFjmjIjYKCI2iYj63OHWg0lw7rmw/PJwzDHtVHbreEPk\nggVw4IHwULnxfKt1992w/fYdSE9i5VRT0d46Io6MiLuyv6OBravZeETMiogp2fQc4BlSv7H9gEuz\nxS4F/jOb3pd0Fr4gIl4GXmDpu6bNrHqdLr9m1lgR8SNgXeBi4CjgBUmnSmrcSEPWZb17p4FgnnoK\nfvnLNhasU0U7Ar75zZTje4sturCh22+va//snqKaivbC4kKeDeHc4XzakoYDm5EuVy0e6CIiZgEf\nzxYrTU80I5tnVid9kbTE36BBw/MOqpZqUn7NrDGyIRlnZX8LgFWB6yT9PNfArEP694e//CWNwFjR\nyJFp1MUaO/XUlCzkuutSy3qnRLiiXSPVZB35HnC3pH+Qxr8dBhzdkZ1IGgBcB5wQEXMklV5M6XBP\nIt8RbbUxj9KvX2tr8/dW6sAd0V0uv2bWGJJOAI4A3iINMvW9iJifjfr4AvD9POOzjvn4x9tZoNBH\nOyL1OamByy6Diy6CBx6o4mbMtrz0UhpnfqONahJXT1ZN1pE7Ja0LrJ/Nei4i5lW7A0m9SZXsyyPi\nxmx2a2H4ZkmDgDey+TOAtYpWL5eeCPAd0dazVXtHdFfLr5k11GrAAYXRHQsiYpGkvXOKyepl4EDo\n1w/efLOKWnn73nsPfvxjuPXWGqS9LqT1821yXVax64ikz2X/DwD2AtbJ/vbK5lXrd8DUiDi7aN5N\npP5nkPL83lg0/xBJfSSNyPb3cAf2ZWbUtPyaWePcCrxTeCBpZUmfAoiIZ3KLyuqnhv20Bw6Ep5+u\nUbbAOufP7knaatHekZQRZJ8yzwVwfXsbl7Q9cBjwlKTHs/VOAX4GXCvpy8B0UqYRImKqpGuBqcB8\n4JtZfzUz65gul18za7jfkEZuLJhTZp51UxEwYQJ861tFQ6AXKtrbbluTfXR4QJpy5s+HlpbUB8W6\nrGJFOyLGZpM/jogleutnrc3tioj7gOUqPL1zhXVOA06rZvtmVl4tyq+ZNZyKG5eyLiPV3Etl3YAE\nc+bAvvvCHXdkWfPqmOKv0x58EEaNgo99LO9IlgnVZB35Y5l519U6EDOrC5dfs+7jH9kAU8tnfycA\nTVYLs644/XRYe2340pfSKJJdGbSmbtf73W2kptrqo/1JSf8FDJR0QNHfUUC/hkVoZh3m8mvWLR0L\nbEdKAvAaaYj0r+cakdVUr17w+9/D22/DiSdCjOhci/aiRXDkkallvOZc0a6pti5JrQ/sDazCkv08\n3we+Vs+gzKzLXH7NupmIeAM4JO84rL769oUbbkgjm/9h8EgO6kRF++STU/18++1rHNw778Azz8B2\n29V4wz1XW320bwRulPTpiHiggTGZWRe5/Jp1P5L6AV8BNqLoylNEfDm3oKwuVlkFbrsNBvRbC/6n\nFf79b+jTp6p1zzkHbrwR7ruvDqOj33kn7LBDje6qNKiuj/axklYpPJC0qqTf1TEmM6sdl1+z7uNy\nYBCwG3APaSyJ93ONyOpm6FBYZY3eaWL69PZXAP70JzjttJQre3HmklqaOBF2260OG+65qqlobxIR\n7xYeRMRsYPP6hWRmNeTya9Z9rBMRY4C5EXEpKQf+p3KOyeqtyswjH34IJ50EN92U7qGsuQj3z66D\natIG9ZK0anaARtJqVa5nZvlz+TXrPuZn/9+V9B/ALKDrQwZac6uyor3CCvDkk3Xs1fHcc6myvf76\n7S9rVaumRfsXwAOSJkj6CXA/8PP6hmVmNdKp8itpqKS7JD0t6SlJ366w3K8kvSBpiqTNahy7WU9z\noaRVgR+RRkqeShrgzZZlWUV7wQIYOxbeb6OzUF27TnvY9bpot2UrIi6T9CjwuWzWARExtb5hmVkt\ndKH8LgBOjIgpkgYAj0maGBHPFhaQtAcwKiLWzYaJPh+ozfBmZj2MpF7AP7OrT5OBkTmHZI0yYgQ8\n/DDLLQezZsEXvgA33wzLL9/gOCZOhCOOaPBOl31t5dFeOfu/Guny1VXZ36xsnpk1qa6W34iYFRFT\nsuk5wDPAkJLF9gMuy5Z5iJSze82avQizHiQiFgHfzzsOy0HWoi3BueemCvYxx9RxQJpy5s2DyZPh\n859v4E57hra6jlyV/X8MeLTor/DYzJpXzcqvpOHAZsBDJU8NAV4tejyDpSvjZla9OyR9V9JaklYr\n/OUdlNVZoY92BL17wzXXwFNPwaabpiwjDfHAA7DBBnVKZdKztZVHe+/sfz3ubTWzOqpV+c26jVwH\nnJC1bHfauHHjFk+PHj2a0aNHd2Vz1mQGDRpOa2t1Kcp6opaWFlpaWtpb7ODs/7eK5gXuRrJsW3XV\n1C969mxYbTX6909dR37yE9h55wbF4GwjdVOxoi1pi7ZWjIi/1T4cM6uFWpRfSb1JlezLswFwSs0A\n1ip6PDSbV1ZxRduWPamSXXyt2zdUFSs9uRw/fvxSy7hhq4eSPmrVXi1dwFhzTfj1rxsYw+23wy9/\n2cAd9hxt3Qz5i+x/P2Ar4AnSL+cmpEvPn65vaGbWBbUov78DpkbE2RWev4nU8naNpG2BdyOitUtR\nm/VgksreiRYRlzU6FmuwQkV7q60av+8334QXX4RtfS97PbTVdWQnAEnXA1tExFPZ4/8AxjUkOjPr\nlK6WX0nbA4cBT0l6nNRUeQowLG0+LoyIWyTtKelFYC5wdF1ejFnPsXXRdD/g88DfyG46tmVYlbm0\n6+KOO2D06BzSnPQM1QxcsX7hIA0QEX+XtEEdYzKz2ulU+Y2I+4DlqljuuC7GZ2aZiDi++LGkVYCr\ncwrHGmnkSPhbTj1yPex6XVUzYM2Tkn4raXT2dxHwZL0DM7OacPk1677mAu633ROMGJFPi7aHXa+7\nalq0jwa+AZyQPZ4M/KZuEZlZLbn8mnUTkv7MR3eU9gI2BK7NLyJrmLy6jkydmoabHDWq8fvuIaoZ\nGfJfks4HbomI5xoQk5nViMuvWbdyRtH0AmB6RLyWVzDWQMOGwYwZMH9+Y/tK3367h12vs3a7jkja\nF5gC3JY93kzSTfUOzMy6zuXXrFt5BXgoIu7J7pN4OxswypZ1ffrAoEHw6qvtL1tL7jZSd9X00R4L\nbAO8C5ANy+w+Y2bdg8uvWffxB2BR0eOF2TzrCUaOhGnTGre/f/0L7rsPPve5xu2zB6qmoj0/It4r\nmRdllzSzZuPya9Z99I6IfxceZNN9cozHGqnR/bTvvRc22QRWWaVx++yBqqloPy3pUGA5SetK+jVw\nf53jMrPacPk16z7ezLp7ASBpP+CtHOOxRmp0RdvdRhqimor28cBGwDzgKuA94P9Vs3FJF0tqlfRk\n0byxkl6T9Lfsb/ei506W9IKkZyT507cuGzRoOJIW//VAnS6/ZtZwxwKnSHpF0ivAD4Bjco7JGsUV\n7WVSm1lHJC0H/Dgivgv8sBPbvwT4NUuPanVmRJxZsq8NgIOADYChwB2S1o0IX+a2Tmttnc6SPSV6\nTmW7BuXXzBooIl4CtpU0IHs8J+eQrJEaWdGeNQumT4ett25/WeuSNlu0I2Ih8JnObjwi7gVml3mq\nXG1nP+DqiFgQES8DL5Bu4jKzTuhq+TWzxpJ0qqRVImJORMyRtKqkn+QdlzVIIwetmTQp3QTZu5rh\nVKwrquk68rikmyQdLumAwl8X93ucpCnZiHUDs3lDgOK8NjOyeWbWefUov2ZWH3tExLuFBxExG9gz\nx3iskT72MZg3D959t/1lu8rdRhqmmlOZfsDbQHH+lwCu7+Q+zyNdzo7sTP0XwFc7upFx48Ytnh49\nejSjR4/uZDhmpfou0Z97zTWHMWvWy/mFU0ZLSwstLS3VLFrr8mtm9bOcpL4RMQ9A0gpA35xjskaR\nPkrxt/nm9dvPokWpRfvHP67fPmyxaira34uImt31HBFvFj28CPhzNj0DWKvouaHZvLKKK9pmtTWP\n4n7dra3N16+79ORy/PjxlRatafk1s7q6ErhT0iWkLpZHAZfmGpE1ViMq2k89BSuvnLqqWN1V7Doi\naR9JbwJPZllCtuvkPkRRn2xJg4qeOwD4ezZ9E3CIpD6SRgDrAA93cp9mPVoNy6+ZNUhE/Az4CSkp\nwPrA7cCwateXtLukZyU9L+kHbSy3taT57kbWhBpxQ6S7jTRUW320fwrsEBGDgf8CTuvoxiVdRcrZ\nu16Wruho4OeSnpQ0BdgR+A5AREwFrgWmArcA33TGkeZQmiJv0KDheYdk7ety+TWzXLSSLqkdSOry\n9Uw1K0nqBZwD7EZK6flFSZ+ssNzppEq8NRtXtJc5bXUdWRARzwJExEOSVuroxiPi0DKzL2lj+dNw\nhaDplKbIa8auFLaULpdfM2sMSesBXwQOAd4gDbuuiNipA5vZBnghIqZn27yalM3r2ZLljgeuA5zX\nrRmNHAk331y/7X/wATz4IPzxj/Xbhy2hrYr2xyWdWOlxaR5ss2VX898cWYbLr1n38SxwM7BrRLwK\nUFJ+q1Gaues1SlLkShoM/GdE7CTJ6XObUb1btCdPTv2/V165fvuwJbRV0b4IWKmNx2Y9RPPfHFmG\ny69Z93EAqTV7sqTbSd0o6/FD80vSaJMF3eLHrEcZPhxeeQUWLoTllqv99idOhN12q/12raKKFe2I\nqJjGwMyam8uvWfcRETcAN0jqT+ru8R3SVajfAH+KiIlVbGYGsHbR43KZu7YCrla6RLcGsIek+RFx\nU+nGnEI3J/36weqrw4wZsPba7S/fURMnwiUVe/BapgMpdNul7ni/oSTfJ9lA6Td5yWHMG/H+12K/\n5bbR9uNqlmnM6+8ISURETVunJF0M7A20RsQmZZ7fEbgRKFznvD4iyo5i5zLbWFdeeSXHHnsLc+Zc\nCcCAAaOYMmUio0aNqts+2y5rnSsztdrmkttpjvLbXpmVtCrphsiDI+LzVWxvOeA54PPA66SsXV+M\niLI3U2YpBP8cEUvl1Hd5zdkOO8CECVDrk5sZM2CTTeCNN+rTWr4M68oxtpqRIc2sZ7qElMGgLZMj\nYovsz0NFm9VIRMyOiAurqWRnyy8EjgMmAk8DV0fEM5KOkfT1cqvUMFyrpXr10540CXbe2ZXsBvMg\n92ZWVkTcK6m9HL7u42nWJCLiNlL+7eJ5F1RY9ssNCco6rjBoTY1MnzaN348Zw6JJk+g1YgRHTZvG\nMA9W0zDttmhL+lHRtIeCNetGGlB+Py1piqS/SNqwDts3M+tZatiiPX3aNH69yy5898orGf/GG3z3\noYf49S67ML2GFXlrW8UW7WxUqcnAF0gjVQE8AGzRgLjMrAsaVH4fA9aOiA8k7QHcAKxXaWHfXGU9\nWS1vrrJlXA0r2r8fM4bxL71E/+xxf2D8Sy9xxpgxjL3iiprsw9rWVteRZ0k3YoyU9Nfs8eqS1o+I\n5xoSnZl1Vt3Lb0TMKZq+VdJ5klaLiHfKLV9c0TbraUpPLsePd2Igq6BWFe2FC1n05JOLK9kF/YFF\nM2d2fftWlba6jrwLnAK8CIwGzs7mnyTp/jrHZWZdU6vyKyr0w5a0ZtH0NqQsRmUr2WZmVqVBg+D9\n92HOnPaXLeftt+HnP4d11qHXzJnMLXl6LtBr8OCuRmlVaquivRvwF2AUcCbwKWBuRBwdEds1Ijgz\n67Qul19JVwH3A+tJekXS0SUZDL4g6e+SHicNhHFw7V+GmVkPI6WBazraj/rRR+Hoo2HUKJg6Fa69\nlqMeeYSxo0YtrmzPBcaOGsVREybUOGirpK0Ba04BkPQEcDmpb+fHJN0LzI6IfRoTopl1VC3Kb0Qc\n2s7z5wLn1iBcMzMrVug+svHGbS83bx5cey2cey7MmgXf+Aa8+CKssQYAw4DjJ03ijDFjWDRzJr0G\nD+b4CROcdaSBqknvd3tEPAo8KukbEfEZSWvUOzAzqwmXXzOz7qa9ftqvvALnnw8XXwybbQannAJ7\n7VU2R/awESN842OO2q1oR8T3ix4elc17q14BmVntuPyamXUv06dN4/f33cei66+n12OPcVShBToC\n7rwztV5PngyHHw5//SusVzHZkzWBDg1YExFP1CsQM6svl18zs+ZWyHtdSMk398orGXv//Rx/xBEM\nu+YaWH55+Na34PLLYcCAvMO1KnhkSDMzM7MmUDbv9bRpnHHJJYy9/HLYYYd0s6R1G65om5mZmTWB\nRTNmlM97PWoUfPazeYRkXdTuEOxmZmZmVn+9hgxx3utljCvaZmZmZk3gqAkTnPd6GeOuI2ZmZmZN\nYNiIEc57vYxxRdvMzMysSTjv9bLFXUfMzMzMzOrAFW0zMzMzszqoa0Vb0sWSWiU9WTRvVUkTJT0n\n6XZJA4ueO1nSC5KekbRrPWMzMzMzM6unerdoXwLsVjLvJOCOiFgfuAs4GUDShsBBwAbAHsB5krOy\nm5mZmVn3VNeKdkTcC8wumb0fcGk2fSnwn9n0vsDVEbEgIl4GXgC2qWd8ZmZmZmb1kkcf7Y9HRCtA\nRCU8BR8AABACSURBVMwCPp7NHwK8WrTcjGyeWZPpi6TFf4MGDc87IDMzM2tCzZDeLzqz0rhx4xZP\njx49mtGjR9coHLP2zKP4a9va2vgeTi0tLbS0tDR8v2ZmZla9PCrarZLWjIhWSYOAN7L5M4C1ipYb\nms0rq7iibdbTlJ5cjh8/Pr9gzMzMrKxGdB1R9ldwE3BUNn0kcGPR/EMk9ZE0AlgHeLgB8ZmZmZmZ\n1Vy90/tdBdwPrCfpFUlHA6cDu0h6Dvh89piImApcC0wFbgG+GRGd6lZiyyr3jTYzM7Puo65dRyLi\n0ApP7Vxh+dOA0+oXkXVv+feN7kkkXQzsDbRGxCYVlvkVKR3nXOCoiJjSwBDNzMyamkeGNLNKyuXB\nX0zSHsCoiFgXOAY4v1GBmZmZdQeuaJtZWRXy4BfbD7gsW/YhYKCkNRsRm5mZWXfgiraZdZZz35uZ\nmbWhGfJom9XMoEHDaW2dnncYVoZz3zev4nKz5prDmDXr5Ybtr1evFVm06IPFz5U+rizdHF1uvUa8\nho5y7nuznskVbVumpIN3cbIa3zBZR859v4woLjeNuMm4eH+LFoniMrvk47ZiWfLm6OL1mvFGaee+\nN+uZ3HXEzNpSmge/2E3AEQCStgXejYjWRgVmZmbW7NyibWZlZXnwRwOrS3oFGAv0ASIiLoyIWyTt\nKelFUnq/o/OL1szMrPm4om1mZbWRB794meMaEYuZmVl35K4jZmZmZmZ14Iq2mZmZmVkduKJtZma2\nDJC0u6RnJT0v6Qdlnj9U0hPZ372SNs4jTrOexBVty8WgQcORtMTfoEHD8w7LzKxbktQLOAfYDdgI\n+KKkT5Ys9g/gsxGxKfAT4KLGRmnW8/hmSMvF0vmumzP3rZlZN7EN8EJETAeQdDWwH/BsYYGIeLBo\n+QfxSK5mdecWbTMzs+5vCPBq0ePXaLsi/VXg1rpGZGZu0TYzM+tJJO1Eynv/mUrLFI/kWjqqpdmy\nrqWlhZaWlppsyxVtMzOz7m8GsHbR46HZvCVI2gS4ENg9ImZX2lhxRduspyk9uRw/fnynt+WuI2Zm\nZt3fI8A6koZJ6gMcAtxUvICktYE/AofH/2/v/mMsq+szjr8f3RUrrqSrLZtiWRpUqFaLVLb4I6Kt\nVKAtbKy/oDbQVrNtatMmTaqmJa5/NNo/2hiLFmkI2moDWKqiiIW2TLYmKosorC2roIKKsFapG367\nwKd/3LO7l2Fm984w557vzLxfyc2ee+535j45e5+Z7z1zzj1V3xggo7TquEdbkqRlrqoeTvJW4CpG\nO9EurKqbkmwZPVwXAOcC64EPJAmwp6o2DZdaWvmcaEuStAJU1WeBY2at++DY8luAt0w7l7SaeeiI\nJEmS1AMn2pIkSVIPnGhrEQ7xqo6SJEkH4THaWoQH8aqOkiRJBzbYRDvJrcBu4BG6M5+T/CRwCbAR\nuBV4fVXtHiqjJEmStFhDHjryCPCKqnrh2McLvR3496o6BvhP4B2DpdMy8NhDWCRJklox5EQ7czz/\nGcCHu+UPA5unmkjLzN5DWMZvkiRJbRhyol3A1Um2J3lzt+7wqtoFUFV3Aj89WDpplUtySpKdSb6e\n5G1zPH5Skh8lub67/eUQOSVJatWQJ0O+tKruSPJTwFVJvsZjd0nOu4ty69at+5ZnX5NeWulmZmaY\nmZnp7fsneQJwHvCrwPeA7Uk+WVU7Zw3dVlWn9xZEkqRlbLCJdlXd0f37v0k+AWwCdiU5vKp2JdkA\nfH++rx+faEurzew3l+9617uW+ik2ATdX1W0ASS5mdGjX7Im2B8ZLkjSPQQ4dSfKUJE/tlg8Ffg3Y\nAVwOnNMNOxv45BD5JHEE8J2x+9/t1s324iRfSXJFkudOJ5okScvDUHu0Dwc+nqS6DB+tqquSXAdc\nmuT3gNuA1w+UT9LBfQk4sqruS3Iq8AngOQNnkiSpGYNMtKvqW8Bxc6y/C3jV9BNJmuV24Mix+8/s\n1u1TVfeMLV+Z5ANJ1nc9fgzPq9Bq1vd5FZLa5JUhJc1lO/CsJBuBO4A3AmeOD9h7PkW3vAnIfJNs\n8LwKrW5TOK9CUoOcaKshh3jRmUZU1cNJ3gpcxehcjgur6qYkW0YP1wXAa5P8IbAHuB94w3CJJUlq\njxNtNWTvBWj2ctI9pKr6LHDMrHUfHFt+P/D+aeeSJGm5GPKCNZIkSdKK5URbkiRJ6oETbUmSJKkH\nTrQlSZKkHjjRliRJknrgRFuSJEnqgRNtSZIkqQdOtCVJkqQeONGWJEmSeuBEW5IkSeqBE21JkiSp\nB060JUmSpB440ZYkSZJ64ERbkiRJ6oETbS2RQ0iy77Zhw1FDB5IkSRrUmqEDaKV4EKh993btynBR\nJEmSGuAebelxe/TefPfoS5IkcKKtKdmw4ahHTURXlr178/ffdu26bdhIkiRpcB46oqkYTTxrbM1K\nm2xLkiQ9WpN7tJOckmRnkq8nedvQeVablb33WZOapIdJ3pfk5iRfSXLctDNK2s/OSu1pbqKd5AnA\necCrgecBZyY5dthUk5uZmRk6wpzmy/XNb36TmZmZfbdt27aN7X3ee+s93RSeYzFmhg4wp2m8xibp\nYZJTgaOr6tnAFuD83oMtsVb7Cu1mazVXy+zs0mn99ddyvpazQfv5Fqu5iTawCbi5qm6rqj3AxcAZ\nA2eaWKsvlPlyveQlr+L009/B5s1b2bx5K69+9euW6BkPWcBe8bmzDW9m6ABzmtJrbJIengH8I0BV\nfRE4LMnh0wi3VFrtK7SbrdVcLbOzS6f111/L+VrOBu3nW6wWJ9pHAN8Zu//dbp168MADD3D33Zex\ne/cMu3fPsGbNyUv0nWefIKhlZpIezh5z+xxjJE2HnZUa5MmQq9zatWtZt+5skicD8OMfXz9wIkmP\n19q1a3nooRme9rTfBOD+++9kzRp/3EvStKWqrb2NSU4EtlbVKd39twNVVX89Nqat0FIDqmrJzlyd\nsIfnA9dU1SXd/Z3ASVW1a47vZ2elWVrtrH2VHmuxfW1xF8d24FlJNgJ3AG8EzhwfsJQ/nCTN6aA9\nBC4H/gi4pPsl/6O5JtlgZ6UpWLLO2ldp6TQ30a6qh5O8FbiK0THkF1bVTQPHklaV+XqYZMvo4bqg\nqj6T5LQktwD3Ar87ZGZpNbOzUpuaO3REkiRJWgla/NSRfVr98P2D5UpyVpIbutvnkjx/GrkmyTY2\n7oQke5K8ppVcSV6R5MtJvprkmmnkmiRbkqcnubJ7je1Ics6Ucl2YZFeSGw8wppmLT7Ta10myDdXZ\nVvs6abYhOmtfl46d7Sfb2Lip93bSfP6+nTNbPx2uqiZvjN4E3AJsBNYCXwGOnTXmVOCKbvmXgS80\nkutE4LBu+ZRp5Jo029i4/wA+DbymhVzAYcB/A0d095/RyjYD3gm8e28u4IfAmilkexlwHHDjPI9P\n/fX/OLfjIHlb7WyrfV3ANpt6Z+3r1LelnV1EtrFxU+3tAradv2/nztdLh1veo93qh+8fNFdVfaGq\ndnd3v8D0Pqd00ov9/DHwL8D3G8p1FnBZVd0OUFU/aCjbncC6bnkd8MOqeqjvYFX1OeD/DjCkpYtP\ntNrXibIN1NlW+zpptiE6a1+Xjp3tKVtniN5Cu92dNNsg/YX+OtzyRLvVD99f6AV13gxc2Wui/Q6a\nLcnPAJur6u+BaZ1ZPsk2ew6wPsk1SbYn+Z2Gsv0D8Lwk3wNuAP5kStkOpqWLT7Ta17met5XOttrX\nibIxTGft69Kxs4vTcm+h3e5Omq3V/sIi+9Dcp46sJEleyeis7pcNnWXMe4Hx46Ja+RinNcDxwK8A\nhwKfT/L5qrpl2FgAvAO4oapemeRo4OokL6iqe4YOpqXVYGdb7Su021n7uoo02Flou7fQbndhBfa3\n5Yn27cCRY/ef2a2bPeZnDzJmiFwkeQFwAXBKVR3oTxHTzvYi4OIkYXT806lJ9lTV5QPn+i7wg6p6\nAHggyTbgFxkdz9WnSbK9FPgrgKr6RpJvAccC1/Wc7WCGeP0fKEuLfd37vC12ttW+TpptiM7a16Vj\nZ/vLNlRvJ83n79vFWVwfpnGA+WJuwBPZf9D8kxgdNP/zs8acxv4D009kOicwTZLrSOBm4MTWttms\n8RcxnZMhJ9lmxwJXd2OfAuwAnttItr8B3tktH87oT0frp/R/ehSwY57Hpv76f5zbcZC8rXa21b4u\nYJtNvbP2derb0s4uItus8VPr7QK2nb9v58+45B1udo92Nfrh+5PkAs4F1gMf6N7R7qmqTY1ke9SX\n9J1p0lxVtTPJvwE3Ag8DF1TV/7SQDXg3cFGSGxj9CfDPq+quvrMl+WfgFcDTk3yb0dnYT6LBi0+0\n2tdJszFAZ1vt66TZhuisfV06drbXbI/6kr4zLTSfv2/n1leHvWCNJEmS1IOWP3VEkiRJWracaEuS\nJEk9cKItSZIk9cCJtiRJktQDJ9qSJElSD5xoS5IkST1wor1CJXk4yfVJdiS5JMmTF/j1dy9w/EVJ\nXjPH+l9K8t5u+ewk7+uWtyR509j6DQt5PmmlsbPS8mFfNSkn2ivXvVV1fFU9H9gD/MHsAd2H/M9n\nST5gvaq+VFV/Osf6D1bVR7q75wBHLMXzScuYnZWWD/uqiTjRXh3+C3hWko1Jdib5cJIdwDOTnJnk\nxu72nrGvSZK/TfLVJFcneXq38s1Jrk3y5SQfm/Uu/uQk27vn+PVu/ElJPjU7UJJ3JvmzJL8FvAj4\nSLd34LQkHx8b96ok/9rHRpEaZmel5cO+al5OtFeuACRZA5wK7OjWPxs4r3sX/hDwHkaXHD0OOCHJ\n6d24Q4Frq+oXgG3A1m79ZVW1qapeCOwEfn/sOTdW1QnAbwDnJ3lSt36+d+5VVZcB1wFndXsHPgMc\ns/eHDqNLnF64mA0gLTN2Vlo+7Ksm4kR75fqJJNcD1wK3sb9It1bV9m75BOCaqrqrqh4BPgq8vHvs\nEeDSbvkjwEu75Rck2ZbkRuAs4Hljz3kpQFXdAnwDOHYBecf/xPZPwJuSHAacCFy5gO8jLVd2Vlo+\n7KsmsmboAOrNfVV1/PiK7nCxe2eNO9AxZOP2vmO+CDi9qr6a5GzgpDnG7P2+iz0G7UPAp4AHgY91\nP6Cklc7OSsuHfdVE3KO9cs1X7vH11wIvT7I+yROBM4GZ7rEnAK/tln+b0TFoAE8F7kyytls/7nUZ\nORr4OeBrE2a9G3ja3jtVdQfwPeAvGP3QkVYDOystH/ZVE3GP9so17zFb+xaq7kzydvYX/4qq+nS3\nfA+wKcm5wC7gDd36cxn98Pg+8EVg3dj3/nb32DpgS1X9OAc86XqfDzE63uw+4MVV9SCjP7E9o6om\n/UEiLXd2Vlo+7Ksmkqol+YQZaUkl+Tvg+qry3ba0DNhZafmwr9PjRFvNSXIdo3f7J1fVnqHzSDow\nOystH/Z1upxoS5IkST3wZEhJkiSpB060JUmSpB440ZYkSZJ64ERbkiRJ6oETbUmSJKkHTrQlSZKk\nHvw/EJXK5QpErOIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fed58d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DDL.plot_calibration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we used pipeline learning, we can also see the gain in accuracy we got from using features and not just LFs as a collection of rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LF accuracy: 0.680\n",
      "Full model accuracy: 0.700\n"
     ]
    }
   ],
   "source": [
    "idxs, gt = DDL.get_labeled_ground_truth(subset=DDL.holdout())\n",
    "acc_feats = np.mean(DDL.get_predicted(subset=DDL.holdout()) == gt)\n",
    "acc_lfs = np.mean(DDL.get_lf_predicted(subset=DDL.holdout()) == gt)\n",
    "print \"LF accuracy: {:.3f}\\nFull model accuracy: {:.3f}\".format(acc_lfs, acc_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating with labeling functions\n",
    "After analyzing our LFs and obtaining model results, we can revise our LF set. We can see all of the results thus far, and reopen MindTagger to see some mentions that aren't currently covered by LFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td><b>ID</b></td><td><b># LFs</b></td><td><b>Test set size</b></td><td><b>Model</b></td><td><b>Precision</b></td><td><b>Recall</b></td><td><b>F1</b></td></tr><tr><td>0</td><td>20</td><td>25</td><td>Logistic regression</td><td>0.500</td><td>1.000</td><td>0.667</td></tr></table>"
      ],
      "text/plain": [
       "<ddlite.ModelLogger instance at 0x1113e2bd8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DDL.show_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making sure MindTagger is installed. Hang on!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"1200\"\n",
       "            src=\"http://Sen.local:8113/#/mindtagger/19309c32c02a5c28\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x110ad5290>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DDL.open_mindtagger(width='100%', height=1200, abstain=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use LSTM to learn weights, we just just call the following functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training for rate=0.01, mu=1e-07\n",
      "\tLearning epoch = 0\tGradient mag. = 0.094753\n",
      "\tLearning epoch = 250\tGradient mag. = 0.103007\n",
      "Final gradient magnitude for rate=0.01, mu=1e-07: 0.110\n",
      "Epoch #0, Training error: 0.508863\n",
      "Epoch #1, Training error: 0.508863\n",
      "Epoch #2, Training error: 0.508863\n",
      "Epoch #3, Training error: 0.508863\n",
      "Epoch #4, Training error: 0.508863\n",
      "Epoch #5, Training error: 0.508863\n",
      "Epoch #6, Training error: 0.508863\n",
      "Epoch #7, Training error: 0.508863\n",
      "Epoch #8, Training error: 0.508863\n",
      "Epoch #9, Training error: 0.508863\n",
      "Epoch #10, Training error: 0.508863\n",
      "Epoch #11, Training error: 0.508863\n",
      "Epoch #12, Training error: 0.508863\n",
      "Epoch #13, Training error: 0.508863\n",
      "Epoch #14, Training error: 0.508863\n",
      "Epoch #15, Training error: 0.508863\n",
      "Epoch #16, Training error: 0.508863\n",
      "Epoch #17, Training error: 0.508863\n",
      "Epoch #18, Training error: 0.508863\n",
      "Epoch #19, Training error: 0.508863\n",
      "Epoch #20, Training error: 0.508863\n",
      "Epoch #21, Training error: 0.508863\n",
      "Epoch #22, Training error: 0.508863\n",
      "Epoch #23, Training error: 0.508863\n",
      "Epoch #24, Training error: 0.508863\n",
      "Epoch #25, Training error: 0.508863\n",
      "Epoch #26, Training error: 0.508863\n",
      "Epoch #27, Training error: 0.508863\n",
      "Epoch #28, Training error: 0.508863\n",
      "Epoch #29, Training error: 0.508863\n",
      "Epoch #30, Training error: 0.508863\n",
      "Epoch #31, Training error: 0.508863\n",
      "Epoch #32, Training error: 0.508863\n",
      "Epoch #33, Training error: 0.508863\n",
      "Epoch #34, Training error: 0.508863\n",
      "Epoch #35, Training error: 0.508863\n",
      "Epoch #36, Training error: 0.508863\n",
      "Epoch #37, Training error: 0.508863\n",
      "Epoch #38, Training error: 0.508863\n",
      "Epoch #39, Training error: 0.508863\n",
      "Epoch #40, Training error: 0.508863\n",
      "Epoch #41, Training error: 0.508863\n",
      "Epoch #42, Training error: 0.508863\n",
      "Epoch #43, Training error: 0.508863\n",
      "Epoch #44, Training error: 0.508863\n",
      "Epoch #45, Training error: 0.508863\n",
      "Epoch #46, Training error: 0.508863\n",
      "Epoch #47, Training error: 0.508863\n",
      "Epoch #48, Training error: 0.508863\n",
      "Epoch #49, Training error: 0.508863\n",
      "Epoch #50, Training error: 0.508863\n",
      "Epoch #51, Training error: 0.508863\n",
      "Epoch #52, Training error: 0.508863\n",
      "Epoch #53, Training error: 0.508863\n",
      "Epoch #54, Training error: 0.508863\n",
      "Epoch #55, Training error: 0.508863\n",
      "Epoch #56, Training error: 0.508863\n",
      "Epoch #57, Training error: 0.508863\n",
      "Epoch #58, Training error: 0.508863\n",
      "Epoch #59, Training error: 0.508863\n",
      "Epoch #60, Training error: 0.508863\n",
      "Epoch #61, Training error: 0.508863\n",
      "Epoch #62, Training error: 0.508863\n",
      "Epoch #63, Training error: 0.508863\n",
      "Epoch #64, Training error: 0.508863\n",
      "Epoch #65, Training error: 0.508863\n",
      "Epoch #66, Training error: 0.508863\n",
      "Epoch #67, Training error: 0.508863\n",
      "Epoch #68, Training error: 0.508863\n",
      "Epoch #69, Training error: 0.508863\n",
      "Epoch #70, Training error: 0.508863\n",
      "Epoch #71, Training error: 0.508863\n",
      "Epoch #72, Training error: 0.508863\n",
      "Epoch #73, Training error: 0.508863\n",
      "Epoch #74, Training error: 0.508863\n",
      "Epoch #75, Training error: 0.508863\n",
      "Epoch #76, Training error: 0.508863\n",
      "Epoch #77, Training error: 0.508863\n",
      "Epoch #78, Training error: 0.508863\n",
      "Epoch #79, Training error: 0.508863\n",
      "Epoch #80, Training error: 0.508863\n",
      "Epoch #81, Training error: 0.508863\n",
      "Epoch #82, Training error: 0.508863\n",
      "Epoch #83, Training error: 0.508863\n",
      "Epoch #84, Training error: 0.508863\n",
      "Epoch #85, Training error: 0.508863\n",
      "Epoch #86, Training error: 0.508863\n",
      "Epoch #87, Training error: 0.508863\n",
      "Epoch #88, Training error: 0.508863\n",
      "Epoch #89, Training error: 0.508863\n",
      "Epoch #90, Training error: 0.508863\n",
      "Epoch #91, Training error: 0.508863\n",
      "Epoch #92, Training error: 0.508863\n",
      "Epoch #93, Training error: 0.508863\n",
      "Epoch #94, Training error: 0.508863\n",
      "Epoch #95, Training error: 0.508863\n",
      "Epoch #96, Training error: 0.508863\n",
      "Epoch #97, Training error: 0.508863\n",
      "Epoch #98, Training error: 0.508863\n",
      "Epoch #99, Training error: 0.508863\n",
      "Epoch #100, Training error: 0.508863\n",
      "Epoch #101, Training error: 0.508863\n",
      "Epoch #102, Training error: 0.508863\n",
      "Epoch #103, Training error: 0.508863\n",
      "Epoch #104, Training error: 0.508863\n",
      "Epoch #105, Training error: 0.508863\n",
      "Epoch #106, Training error: 0.508863\n",
      "Epoch #107, Training error: 0.508863\n",
      "Epoch #108, Training error: 0.508863\n",
      "Epoch #109, Training error: 0.508863\n",
      "Epoch #110, Training error: 0.508863\n",
      "Epoch #111, Training error: 0.508863\n",
      "Epoch #112, Training error: 0.508863\n",
      "Epoch #113, Training error: 0.508863\n",
      "Epoch #114, Training error: 0.508863\n",
      "Epoch #115, Training error: 0.508863\n",
      "Epoch #116, Training error: 0.508863\n",
      "Epoch #117, Training error: 0.508863\n",
      "Epoch #118, Training error: 0.508863\n",
      "Epoch #119, Training error: 0.508863\n",
      "Epoch #120, Training error: 0.508863\n",
      "Epoch #121, Training error: 0.508863\n",
      "Epoch #122, Training error: 0.508863\n",
      "Epoch #123, Training error: 0.508863\n",
      "Epoch #124, Training error: 0.508863\n",
      "Epoch #125, Training error: 0.508863\n",
      "Epoch #126, Training error: 0.508863\n",
      "Epoch #127, Training error: 0.508863\n",
      "Epoch #128, Training error: 0.508863\n",
      "Epoch #129, Training error: 0.508863\n",
      "Epoch #130, Training error: 0.508863\n",
      "Epoch #131, Training error: 0.508863\n",
      "Epoch #132, Training error: 0.508863\n",
      "Epoch #133, Training error: 0.508863\n",
      "Epoch #134, Training error: 0.508863\n",
      "Epoch #135, Training error: 0.508863\n",
      "Epoch #136, Training error: 0.508863\n",
      "Epoch #137, Training error: 0.508863\n",
      "Epoch #138, Training error: 0.508863\n",
      "Epoch #139, Training error: 0.508863\n",
      "Epoch #140, Training error: 0.508863\n",
      "Epoch #141, Training error: 0.508863\n",
      "Epoch #142, Training error: 0.508863\n",
      "Epoch #143, Training error: 0.508863\n",
      "Epoch #144, Training error: 0.508863\n",
      "Epoch #145, Training error: 0.508863\n",
      "Epoch #146, Training error: 0.508863\n",
      "Epoch #147, Training error: 0.508863\n",
      "Epoch #148, Training error: 0.508863\n",
      "Epoch #149, Training error: 0.508863\n",
      "Epoch #150, Training error: 0.508863\n",
      "Epoch #151, Training error: 0.508863\n",
      "Epoch #152, Training error: 0.508863\n",
      "Epoch #153, Training error: 0.508863\n",
      "Epoch #154, Training error: 0.508863\n",
      "Epoch #155, Training error: 0.508863\n",
      "Epoch #156, Training error: 0.508863\n",
      "Epoch #157, Training error: 0.508863\n",
      "Epoch #158, Training error: 0.508863\n",
      "Epoch #159, Training error: 0.508863\n",
      "Epoch #160, Training error: 0.508863\n",
      "Epoch #161, Training error: 0.508863\n",
      "Epoch #162, Training error: 0.508863\n",
      "Epoch #163, Training error: 0.508863\n",
      "Epoch #164, Training error: 0.508863\n",
      "Epoch #165, Training error: 0.508863\n",
      "Epoch #166, Training error: 0.493222\n",
      "Epoch #167, Training error: 0.493222\n",
      "Epoch #168, Training error: 0.493222\n",
      "Epoch #169, Training error: 0.493222\n",
      "Epoch #170, Training error: 0.493222\n",
      "Epoch #171, Training error: 0.493222\n",
      "Epoch #172, Training error: 0.493222\n",
      "Epoch #173, Training error: 0.490615\n",
      "Epoch #174, Training error: 0.493222\n",
      "Epoch #175, Training error: 0.493222\n",
      "Epoch #176, Training error: 0.484880\n",
      "Epoch #177, Training error: 0.415537\n",
      "Epoch #178, Training error: 0.486444\n",
      "Epoch #179, Training error: 0.437435\n",
      "Epoch #180, Training error: 0.460897\n",
      "Epoch #181, Training error: 0.449426\n",
      "Epoch #182, Training error: 0.434828\n",
      "Epoch #183, Training error: 0.465589\n",
      "Epoch #184, Training error: 0.392596\n",
      "Epoch #185, Training error: 0.481230\n",
      "Epoch #186, Training error: 0.465589\n",
      "Epoch #187, Training error: 0.424400\n",
      "Epoch #188, Training error: 0.464025\n",
      "Epoch #189, Training error: 0.402503\n",
      "Epoch #190, Training error: 0.270073\n",
      "Epoch #191, Training error: 0.399374\n",
      "Epoch #192, Training error: 0.460897\n",
      "Epoch #193, Training error: 0.447341\n",
      "Epoch #194, Training error: 0.382169\n",
      "Epoch #195, Training error: 0.322211\n",
      "Epoch #196, Training error: 0.342023\n",
      "Epoch #197, Training error: 0.270594\n",
      "Epoch #198, Training error: 0.362357\n",
      "Epoch #199, Training error: 0.418665\n",
      "Epoch #200, Training error: 0.429614\n",
      "Epoch #201, Training error: 0.359750\n",
      "Epoch #202, Training error: 0.419708\n",
      "Epoch #203, Training error: 0.341502\n",
      "Epoch #204, Training error: 0.353493\n",
      "Epoch #205, Training error: 0.376955\n",
      "Epoch #206, Training error: 0.295620\n",
      "Epoch #207, Training error: 0.380083\n",
      "Epoch #208, Training error: 0.259124\n",
      "Epoch #209, Training error: 0.259645\n",
      "Epoch #210, Training error: 0.263295\n",
      "Epoch #211, Training error: 0.376434\n",
      "Epoch #212, Training error: 0.311262\n",
      "Epoch #213, Training error: 0.375912\n",
      "Epoch #214, Training error: 0.343587\n",
      "Epoch #215, Training error: 0.268509\n",
      "Epoch #216, Training error: 0.267466\n",
      "Epoch #217, Training error: 0.375391\n",
      "Epoch #218, Training error: 0.375391\n",
      "Epoch #219, Training error: 0.371741\n",
      "Epoch #220, Training error: 0.401460\n",
      "Epoch #221, Training error: 0.274765\n",
      "Epoch #222, Training error: 0.417101\n",
      "Epoch #223, Training error: 0.375391\n",
      "Epoch #224, Training error: 0.375391\n",
      "Epoch #225, Training error: 0.367049\n",
      "Epoch #226, Training error: 0.375912\n",
      "Epoch #227, Training error: 0.407195\n",
      "Epoch #228, Training error: 0.374348\n",
      "Epoch #229, Training error: 0.375391\n",
      "Epoch #230, Training error: 0.392075\n",
      "Epoch #231, Training error: 0.374870\n",
      "Epoch #232, Training error: 0.287278\n",
      "Epoch #233, Training error: 0.293014\n",
      "Epoch #234, Training error: 0.391554\n",
      "Epoch #235, Training error: 0.269030\n",
      "Epoch #236, Training error: 0.375391\n",
      "Epoch #237, Training error: 0.375912\n",
      "Epoch #238, Training error: 0.375912\n",
      "Epoch #239, Training error: 0.379041\n",
      "Epoch #240, Training error: 0.269030\n",
      "Epoch #241, Training error: 0.388425\n",
      "Epoch #242, Training error: 0.293014\n",
      "Epoch #243, Training error: 0.386861\n",
      "Epoch #244, Training error: 0.267987\n",
      "Epoch #245, Training error: 0.283107\n",
      "Epoch #246, Training error: 0.276851\n",
      "Epoch #247, Training error: 0.325339\n",
      "Epoch #248, Training error: 0.376434\n",
      "Epoch #249, Training error: 0.349322\n",
      "Epoch #250, Training error: 0.271637\n",
      "Epoch #251, Training error: 0.269552\n",
      "Epoch #252, Training error: 0.273201\n",
      "Epoch #253, Training error: 0.366528\n",
      "Epoch #254, Training error: 0.370177\n",
      "Epoch #255, Training error: 0.391554\n",
      "Epoch #256, Training error: 0.263816\n",
      "Epoch #257, Training error: 0.325860\n",
      "Epoch #258, Training error: 0.374870\n",
      "Epoch #259, Training error: 0.386340\n",
      "Epoch #260, Training error: 0.294578\n",
      "Epoch #261, Training error: 0.374870\n",
      "Epoch #262, Training error: 0.395203\n",
      "Epoch #263, Training error: 0.374348\n",
      "Epoch #264, Training error: 0.386861\n",
      "Epoch #265, Training error: 0.374870\n",
      "Epoch #266, Training error: 0.386861\n",
      "Epoch #267, Training error: 0.269030\n",
      "Epoch #268, Training error: 0.294578\n",
      "Epoch #269, Training error: 0.267466\n",
      "Epoch #270, Training error: 0.294578\n",
      "Epoch #271, Training error: 0.268509\n",
      "Epoch #272, Training error: 0.267987\n",
      "Epoch #273, Training error: 0.375912\n",
      "Epoch #274, Training error: 0.265902\n",
      "Epoch #275, Training error: 0.386861\n",
      "Epoch #276, Training error: 0.307612\n",
      "Epoch #277, Training error: 0.385297\n",
      "Epoch #278, Training error: 0.352972\n",
      "Epoch #279, Training error: 0.276851\n",
      "Epoch #280, Training error: 0.262774\n",
      "Epoch #281, Training error: 0.378519\n",
      "Epoch #282, Training error: 0.378519\n",
      "Epoch #283, Training error: 0.378519\n",
      "Epoch #284, Training error: 0.272680\n",
      "Epoch #285, Training error: 0.271637\n",
      "Epoch #286, Training error: 0.397289\n",
      "Epoch #287, Training error: 0.373827\n",
      "Epoch #288, Training error: 0.267987\n",
      "Epoch #289, Training error: 0.365485\n",
      "Epoch #290, Training error: 0.342023\n",
      "Epoch #291, Training error: 0.386861\n",
      "Epoch #292, Training error: 0.285714\n",
      "Epoch #293, Training error: 0.263816\n",
      "Epoch #294, Training error: 0.398332\n",
      "Epoch #295, Training error: 0.373827\n",
      "Epoch #296, Training error: 0.374348\n",
      "Epoch #297, Training error: 0.263816\n",
      "Epoch #298, Training error: 0.374870\n",
      "Epoch #299, Training error: 0.373827\n",
      "CPU times: user 1min 59s, sys: 6.35 s, total: 2min 5s\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "lf_opts = {'sample': False, 'verbose': True}\n",
    "model_opts = {'n_iter': 300, 'verbose': True, 'contain_mention': True, 'word_window_length': 0, 'ignore_case': False}\n",
    "%time DDL.train_model(method='lstm', lf_opts=lf_opts, model_opts=model_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full model accuracy: 0.720\n"
     ]
    }
   ],
   "source": [
    "idxs, gt = DDL.get_labeled_ground_truth(subset=DDL.holdout())\n",
    "acc_feats = np.mean(DDL.get_predicted(subset=DDL.holdout()) == gt)\n",
    "print \"Full model accuracy: {:.3f}\".format(acc_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
